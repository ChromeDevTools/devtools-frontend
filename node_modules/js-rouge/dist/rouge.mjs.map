{
  "version": 3,
  "sources": ["../src/constants.ts", "../src/utils.ts", "../src/rouge.ts"],
  "sourcesContent": ["export const TREEBANK_CONTRACTIONS: RegExp[] = [\n  /\\b(can)(not)\\b/i,\n  /\\b(d)('ye)\\b/i,\n  /\\b(gim)(me)\\b/i,\n  /\\b(gon)(na)\\b/i,\n  /\\b(got)(ta)\\b/i,\n  /\\b(lem)(me)\\b/i,\n  /\\b(more)('n)\\b/i,\n  /\\b(wan)(na) /i,\n  / ('t)(is)\\b/i,\n  / ('t)(was)\\b/i,\n];\n\nexport const HONORIFICS: string[] = [\n  'jr',\n  'mr',\n  'mrs',\n  'ms',\n  'dr',\n  'prof',\n  'sr',\n  'sen',\n  'corp',\n  'rep',\n  'gov',\n  'atty',\n  'supt',\n  'det',\n  'rev',\n  'col',\n  'gen',\n  'lt',\n  'cmdr',\n  'adm',\n  'capt',\n  'sgt',\n  'cpl',\n  'maj',\n  'miss',\n  'misses',\n  'mister',\n  'sir',\n  'esq',\n  'mstr',\n  'phd',\n  'adj',\n  'adv',\n  'asst',\n  'bldg',\n  'brig',\n  'comdr',\n  'hon',\n  'messrs',\n  'mlle',\n  'mme',\n  'op',\n  'ord',\n  'pvt',\n  'reps',\n  'res',\n  'sens',\n  'sfc',\n  'surg',\n];\n\nexport const ABBR_COMMON: string[] = [\n  'arc',\n  'al',\n  'exp',\n  'rd',\n  'st',\n  'dist',\n  'mt',\n  'fy',\n  'pd',\n  'pl',\n  'plz',\n  'tce',\n  'llb',\n  'md',\n  'bl',\n  'ma',\n  'ba',\n  'lit',\n  'ex',\n  'e.g',\n  'i.e',\n  'circa',\n  'ca',\n  'cca',\n  'v.s',\n  'etc',\n  'esp',\n  'ft',\n  'b.c',\n  'a.d',\n];\n\nexport const ABBR_ORGANIZATIONS: string[] = [\n  'co',\n  'corp',\n  'yahoo',\n  'joomla',\n  'jeopardy',\n  'dept',\n  'univ',\n  'assn',\n  'bros',\n  'inc',\n  'ltd',\n];\n\nexport const ABBR_PLACES: string[] = [\n  'ala',\n  'ariz',\n  'ark',\n  'cal',\n  'calif',\n  'col',\n  'colo',\n  'conn',\n  'del',\n  'fed',\n  'fla',\n  'fl',\n  'ga',\n  'ida',\n  'ind',\n  'ia',\n  'la',\n  'kan',\n  'kans',\n  'ken',\n  'ky',\n  'la',\n  'md',\n  'mich',\n  'minn',\n  'mont',\n  'neb',\n  'nebr',\n  'nev',\n  'okla',\n  'penna',\n  'penn',\n  'pa',\n  'dak',\n  'tenn',\n  'tex',\n  'ut',\n  'vt',\n  'va',\n  'wash',\n  'wis',\n  'wisc',\n  'wy',\n  'wyo',\n  'usafa',\n  'alta',\n  'ont',\n  'que',\n  'sask',\n  'yuk',\n  'ave',\n  'blvd',\n  'cl',\n  'ct',\n  'cres',\n  'hwy',\n  'U.S',\n  'U.S.A',\n  'E.U',\n  'N\u00B0',\n];\n\nexport const ABBR_TIME: string[] = ['a.m', 'p.m'];\n\nexport const ABBR_DATES: string[] = [\n  'jan',\n  'feb',\n  'mar',\n  'apr',\n  'jun',\n  'jul',\n  'aug',\n  'sep',\n  'sept',\n  'oct',\n  'nov',\n  'dec',\n];\n\nexport const GATE_EXCEPTIONS: string[] = [\n  'ex',\n  'e.g',\n  'i.e',\n  'circa',\n  'ca',\n  'cca',\n  'v.s',\n  'esp',\n  'ft',\n  'st',\n  'mt',\n  ...HONORIFICS,\n];\n\nexport const GATE_SUBSTITUTIONS: string[] = [\n  ...ABBR_COMMON,\n  ...ABBR_DATES,\n  ...ABBR_ORGANIZATIONS,\n  ...ABBR_PLACES,\n  ...ABBR_TIME,\n  ...HONORIFICS,\n];\n", "import { GATE_EXCEPTIONS, GATE_SUBSTITUTIONS, TREEBANK_CONTRACTIONS } from './constants';\n\n/**\n * Splits a sentence into an array of word tokens\n * in accordance with the Penn Treebank guidelines.\n *\n * NOTE: This method assumes that the input is a single\n * sentence only. Providing multiple sentences within a\n * single string can trigger edge cases which have not\n * been accounted for.\n *\n * Adapted from Titus Wormer's port of the Penn Treebank Tokenizer\n * found at https://gist.github.com/wooorm/8504606\n *\n *\n * @method treeBankTokenize\n * @param  {string}           input     The sentence to be tokenized\n * @return {Array<string>}              An array of word tokens\n */\nexport function treeBankTokenize(input: string): string[] {\n  if (input.length === 0) {\n    return [];\n  }\n\n  // Does the following things in order of appearance by line:\n  // 1. Replace quotes at the sentence start position with double ticks\n  // 2. Wrap spaces around a double quote preceded by opening brackets\n  // 3. Wrap spaces around a non-unicode ellipsis\n  // 4. Wrap spaces around some punctuation signs (,;@#$%&)\n  // 5. Wrap spaces around a period and zero or more closing brackets\n  //    (or quotes), when not preceded by a period and when followed\n  //    by the end of the string. Only splits final periods because\n  //    sentence tokenization is assumed as a preprocessing step\n  // 6. Wrap spaces around all exclamation marks and question marks\n  // 7. Wrap spaces around opening and closing brackets\n  // 8. Wrap spaces around en and em-dashes\n  let parse = input\n    .replace(/^\"/, ' `` ')\n    .replace(/([ ([{<])\"/g, '$1 `` ')\n    .replace(/\\.\\.\\.*/g, ' ... ')\n    .replace(/[;@#$%&]/g, ' $& ')\n    .replace(/([^.])(\\.)([\\])}>\"']*)\\s*$/g, '$1 $2$3 ')\n    .replace(/[,?!]/g, ' $& ')\n    .replace(/[\\][(){}<>]/g, ' $& ')\n    .replace(/---*/g, ' -- ');\n\n  // Wrap spaces at the start and end of the sentence for consistency\n  // i.e. reduce the number of Regex matches required\n  parse = ` ${parse} `;\n\n  // Does the following things in order of appearance by line:\n  // 1. Replace double quotes with a pair of single quotes wrapped with spaces\n  // 2. Wrap possessive or closing single quotes\n  // 3. Add a space before single quotes followed by `s`, `m`, or `d` and a space\n  // 4. Add a space before occurrences of `'ll`, `'re`, `'ve` or `n't`\n  parse = parse\n    .replace(/\"/g, \" '' \")\n    .replace(/([^'])' /g, \"$1 ' \")\n    .replace(/'([sSmMdD]) /g, \" '$1 \")\n    .replace(/('ll|'LL|'re|'RE|'ve|'VE|n't|N'T) /g, ' $1 ');\n\n  for (const contraction of TREEBANK_CONTRACTIONS) {\n    // Break uncommon contractions with a space and wrap-in spaces\n    parse = parse.replace(contraction, ' $1 $2 ');\n  }\n\n  // Concatenate double spaces and remove start/end spaces\n  parse = parse.replace(/ {2,}/g, ' ').replace(/^ | $/g, '');\n\n  // Split on spaces (original and inserted) to return the tokenized result\n  return parse.split(' ');\n}\n\n/**\n * Splits a body of text into an array of sentences\n * using a rule-based segmentation approach.\n *\n * Adapted from Spencer Mountain's nlp_compromise library\n * found at https://github.com/spencermountain/nlp_compromise/\n *\n * @method sentenceSegment\n * @param  {string}         input     The document to be segmented\n * @return {Array<string>}            An array of sentences\n */\n// biome-ignore lint/complexity/noExcessiveCognitiveComplexity: Sentence segmentation requires complex NLP logic\nexport function sentenceSegment(input: string): string[] {\n  if (input.length === 0) {\n    return [];\n  }\n\n  const abbrvReg = new RegExp(`\\\\b(${GATE_SUBSTITUTIONS.join('|')})[.!?] ?$`, 'i');\n  const acronymReg = new RegExp(/[ |.][A-Z].?$/, 'i');\n  const breakReg = new RegExp(/[\\r\\n]+/, 'g');\n  // Match 2-10 dots at end of string (ellipsis pattern)\n  // Using bounded {2,10} quantifier to avoid ReDoS with extremely long dot sequences\n  const ellipseReg = /\\.{2,10}$/;\n  const excepReg = new RegExp(`\\\\b(${GATE_EXCEPTIONS.join('|')})[.!?] ?$`, 'i');\n\n  // Split sentences naively based on common terminals (.?!\")\n  // Pattern uses a \"tempered greedy token\" to avoid ReDoS:\n  // - (?:[^.?!\\r\\n]|[.?!](?!\\s|$|\"))* matches any char except newlines, OR a terminator NOT at a boundary\n  // - [^.?!\\r\\n] excludes newlines to match original behavior (JS regex . doesn't match newlines)\n  // - This allows matching through \"U.S.A.\" and \"$100.00\" without polynomial backtracking\n  // - [.?!]{1,3} limits consecutive terminators (e.g., \"!!\", \"?!\", \"...\") to prevent ReDoS\n  const chunks = input.split(/(\\S(?:[^.?!\\r\\n]|[.?!](?!\\s|$|\"))*[.?!]{1,3})(?=\\s|$|\")/g);\n\n  const acc: string[] = [];\n  for (let idx = 0; idx < chunks.length; idx++) {\n    if (chunks[idx]) {\n      // Trim only spaces (i.e. preserve line breaks/carriage feeds)\n      // Note: Using separate replacements instead of alternation to avoid ReDoS\n      chunks[idx] = chunks[idx].replace(/^ +/, '').replace(/ +$/, '');\n\n      if (breakReg.test(chunks[idx])) {\n        if (chunks[idx + 1] && strIsTitleCase(chunks[idx])) {\n          // Catch line breaks embedded within valid sentences\n          // i.e. sentences that start with a capital letter\n          // and merge them with a delimiting space\n          chunks[idx + 1] = `${chunks[idx].trim()} ${chunks[idx + 1].replace(/ +/g, ' ')}`;\n        } else {\n          // Assume that all other embedded line breaks are\n          // valid sentence breakpoints\n          acc.push(...chunks[idx].trim().split('\\n'));\n        }\n      } else if (chunks[idx + 1] && abbrvReg.test(chunks[idx])) {\n        const nextChunk = chunks[idx + 1];\n        if (nextChunk.trim() && strIsTitleCase(nextChunk) && !excepReg.test(chunks[idx])) {\n          // Catch abbreviations followed by a capital letter and treat as a boundary.\n          // FIXME: This causes named entities like `Mt. Fuji` or `U.S. Government` to fail.\n          acc.push(chunks[idx]);\n          chunks[idx] = '';\n        } else {\n          // Catch common abbreviations and merge them with a delimiting space\n          chunks[idx + 1] = `${chunks[idx]} ${nextChunk.replace(/ +/g, ' ')}`;\n        }\n      } else if (chunks[idx].length > 1 && chunks[idx + 1] && acronymReg.test(chunks[idx])) {\n        const words = chunks[idx].split(' ');\n        const lastWord = words.at(-1)!;\n\n        if (lastWord === lastWord.toLowerCase()) {\n          // Catch small-letter abbreviations and merge them.\n          chunks[idx + 1] = `${chunks[idx]} ${chunks[idx + 1].replace(/ +/g, ' ')}`;\n        } else if (chunks[idx + 2]) {\n          if (strIsTitleCase(words.at(-2)!) && strIsTitleCase(chunks[idx + 2])) {\n            // Catch name abbreviations (e.g. Albert I. Jones) by checking if\n            // the previous and next words are all capitalized.\n            chunks[idx + 2] = chunks[idx] + chunks[idx + 1].replace(/ +/g, ' ') + chunks[idx + 2];\n          } else {\n            // Assume that remaining entities are indeed end-of-sentence markers.\n            acc.push(chunks[idx]);\n            chunks[idx] = '';\n          }\n        }\n      } else if (chunks[idx + 1] && ellipseReg.test(chunks[idx])) {\n        // Catch mid-sentence ellipses (and their derivatives) and merge them\n        chunks[idx + 1] = chunks[idx] + chunks[idx + 1].replace(/ +/g, ' ');\n      } else if (chunks[idx] && chunks[idx].length > 0) {\n        acc.push(chunks[idx]);\n        chunks[idx] = '';\n      }\n    }\n  }\n\n  // If no matches were found, return the input treated as a single sentence\n  return acc.length === 0 ? [input] : acc;\n}\n\n/**\n * Checks if a string is titlecase\n * @method strIsTitleCase\n * @param  {string}   input       The string to be checked\n * @return {boolean}              True if the string is titlecase and false otherwise\n */\nexport function strIsTitleCase(input: string): boolean {\n  const firstChar = input.trim().slice(0, 1);\n  return charIsUpperCase(firstChar);\n}\n\n/**\n * Checks if a character is uppercase (i18n-compatible)\n * @method charIsUpperCase\n * @param  {string}   input     The character to be tested\n * @return {boolean}            True if the character is uppercase and false otherwise.\n */\nexport function charIsUpperCase(input: string): boolean {\n  if (input.length !== 1) {\n    throw new RangeError('Input should be a single character');\n  }\n\n  // Use locale-aware comparison to support international characters\n  return input.toUpperCase() === input && input.toLowerCase() !== input;\n}\n\n/**\n * Memoizes a function using a Map\n *\n * **Memory Warning**: The cache is unbounded and will grow indefinitely for unique inputs.\n * In long-running processes with many unique inputs, consider using a bounded cache\n * implementation (e.g., LRU cache) or periodically clearing the memoized function.\n *\n * @method memoize\n * @param  {Function} func    The function to be memoized\n * @param  {Function} Store   The data store constructor. Defaults to the ES6-inbuilt Map function.\n *                            A store should implement `has`, `get`, and `set` methods.\n * @return {Function}         A closure of the memoization cache and the original function\n */\nfunction memoize<T, R>(func: (arg: T) => R, Store: new () => Map<T, R> = Map): (arg: T) => R {\n  return (() => {\n    const cache = new Store();\n\n    return (n: T) => {\n      if (cache.has(n)) {\n        const cachedResult = cache.get(n);\n        if (cachedResult !== undefined) {\n          return cachedResult;\n        }\n      }\n      const result = func(n);\n      cache.set(n, result);\n      return result;\n    };\n  })();\n}\n\n/**\n * Computes the factorial of a number.\n *\n * This function uses a tail-recursive call to avoid\n * blowing the stack when computing inputs with a large\n * recursion depth.\n *\n * @method factRec\n * @param  {number} x     The number for which the factorial is to be computed\n * @param  {number} acc   The starting value for the computation. Defaults to 1.\n * @return {number}       The factorial result\n */\nfunction factRec(x: number, acc = 1): number {\n  if (x < 0) {\n    throw new RangeError('Input must be a positive number');\n  }\n  return x < 2 ? acc : factRec(x - 1, x * acc);\n}\n\n/**\n * Memoized factorial function.\n *\n * **Memory Note**: Results are cached indefinitely. In typical ROUGE usage,\n * factorial is called with small values (\u226420) so memory impact is negligible.\n * The cache size is bounded by the range of valid factorial inputs that don't\n * overflow JavaScript's number type (approximately n \u2264 170).\n */\nexport const fact = memoize(factRec);\n\n/**\n * Returns the skip bigrams for an array of word tokens.\n *\n * @method skipBigram\n * @param  {Array<string>}    tokens      An array of word tokens\n * @param  {number}           maxSkip     Maximum skip distance between words. Defaults to Infinity (all pairs).\n * @return {Array<string>}                An array of skip bigram strings\n */\nexport function skipBigram(tokens: string[], maxSkip: number = Number.POSITIVE_INFINITY): string[] {\n  if (tokens.length < 2) {\n    throw new RangeError('Input must have at least two words');\n  }\n\n  const acc: string[] = [];\n  for (let baseIdx = 0; baseIdx < tokens.length - 1; baseIdx++) {\n    const maxIdx = Math.min(baseIdx + 1 + maxSkip, tokens.length);\n    for (let sweepIdx = baseIdx + 1; sweepIdx < maxIdx; sweepIdx++) {\n      acc.push(`${tokens[baseIdx]} ${tokens[sweepIdx]}`);\n    }\n  }\n\n  return acc;\n}\n\ninterface NGramOptions {\n  start: boolean;\n  end: boolean;\n  val: string;\n}\n\nexport const NGRAM_DEFAULT_OPTS: NGramOptions = {\n  start: false,\n  end: false,\n  val: '<S>',\n};\n\n/**\n * Returns n-grams for an array of word tokens.\n *\n * @method nGram\n * @param  {Array<string>}          tokens    An array of word tokens\n * @param  {number}                 n         The size of the n-gram. Defaults to 2.\n * @param  {Object}                 pad       String padding options. See example.\n * @return {Array<string>}                    An array of n-gram strings\n */\nexport function nGram(tokens: string[], n = 2, pad: Partial<NGramOptions> = {}): string[] {\n  if (n < 1) {\n    throw new RangeError('ngram size cannot be smaller than 1');\n  }\n\n  if (tokens.length < n) {\n    throw new RangeError('ngram size cannot be larger than the number of tokens available');\n  }\n\n  let workingTokens = tokens;\n\n  if (Object.keys(pad).length > 0) {\n    const config = { ...NGRAM_DEFAULT_OPTS, ...pad };\n\n    // Clone the input token array to avoid mutating the source data\n    const tempTokens = tokens.slice(0);\n\n    if (config.start) {\n      for (let i = 0; i < n - 1; i++) {\n        tempTokens.unshift(config.val);\n      }\n    }\n    if (config.end) {\n      for (let i = 0; i < n - 1; i++) {\n        tempTokens.push(config.val);\n      }\n    }\n\n    workingTokens = tempTokens;\n  }\n\n  const acc: string[] = [];\n  for (let idx = 0; idx < workingTokens.length - n + 1; idx++) {\n    acc.push(workingTokens.slice(idx, idx + n).join(' '));\n  }\n\n  return acc;\n}\n\n/**\n * Calculates C(val, 2), i.e. the number of ways 2\n * items can be chosen from `val` items.\n *\n * @method comb2\n * @param  {number} val     The total number of items to choose from\n * @return {number}         The number of ways in which 2 items can be chosen from `val`\n */\nexport function comb2(val: number): number {\n  if (val < 2) {\n    throw new RangeError('Input must be greater than 2');\n  }\n  return 0.5 * val * (val - 1);\n}\n\n/**\n * Computes the arithmetic mean of an array\n * @method arithmeticMean\n * @param  {Array<number>}   input    Data distribution\n * @return {number}                   The mean of the distribution\n */\nexport function arithmeticMean(input: number[]): number {\n  if (input.length === 0) {\n    throw new RangeError('Input array must have at least 1 element');\n  }\n  return input.reduce((x, y) => x + y) / input.length;\n}\n\n/**\n * Evaluates the jackknife resampling result for a set of\n * candidate summaries vs. a reference summary.\n *\n * @method jackKnife\n * @param  {Array<string>}  cands      An array of candidate summaries to be evaluated\n * @param  {string}         ref        The reference summary to be evaluated against\n * @param  {Function}       func       The function used to evaluate a candidate against a reference.\n *                                     Should be of the type signature (string, string) => number\n * @param  {Function}       test       The function used to compute the test statistic.\n *                                     Defaults to the arithmetic mean.\n *                                     Should be of the type signature (Array<number>) => number\n * @return {number}                    The result computed by applying `test` to the resampled data\n */\nexport function jackKnife(\n  cands: string[],\n  ref: string,\n  func: (x: string, y: string) => number,\n  test: (x: number[]) => number = arithmeticMean,\n): number {\n  if (cands.length < 2) {\n    throw new RangeError('Candidate array must contain more than one element');\n  }\n\n  const pairs: number[] = cands.map((c) => func(c, ref));\n\n  const acc: number[] = [];\n  for (let idx = 0; idx < pairs.length; idx++) {\n    // Clone the array and remove one element\n    const leaveOneOut = pairs.slice(0);\n    leaveOneOut.splice(idx, 1);\n\n    acc.push(Math.max(...leaveOneOut));\n  }\n\n  return test(acc);\n}\n\n/**\n * Calculates the ROUGE f-measure for a given precision\n * and recall score.\n *\n * Uses the standard F-beta formula:\n * F_\u03B2 = ((1 + \u03B2\u00B2) \u00D7 P \u00D7 R) / (\u03B2\u00B2 \u00D7 P + R)\n *\n * Beta controls the tradeoff between precision and recall:\n * - beta = 0: Pure precision (F\u2080 = P)\n * - beta = 1: F1 score (harmonic mean, equal weight)\n * - beta = 2: F2 score (weighs recall twice as much as precision)\n * - beta = Infinity: Pure recall\n *\n * @method fMeasure\n * @param  {number}     p       Precision score (0 to 1)\n * @param  {number}     r       Recall score (0 to 1)\n * @param  {number}     beta    Weighing value (precision vs. recall). Defaults to 1.0 (F1).\n * @return {number}             Computed f-score\n */\nexport function fMeasure(p: number, r: number, beta = 1.0): number {\n  if (p < 0 || p > 1) {\n    throw new RangeError('Precision value p must have bounds 0 \u2264 p \u2264 1');\n  }\n  if (r < 0 || r > 1) {\n    throw new RangeError('Recall value r must have bounds 0 \u2264 r \u2264 1');\n  }\n  if (beta < 0) {\n    throw new RangeError('beta value must be >= 0');\n  }\n\n  // Handle special cases\n  if (p === 0 && r === 0) {\n    return 0;\n  }\n  if (!Number.isFinite(beta)) {\n    return r; // \u03B2 \u2192 \u221E means pure recall\n  }\n\n  const betaSq = beta * beta;\n  const denominator = betaSq * p + r;\n  if (denominator === 0) {\n    return 0;\n  }\n\n  return ((1 + betaSq) * p * r) / denominator;\n}\n\n/**\n * Computes the set intersection of two arrays\n *\n * @method intersection\n * @template T\n * @param  {Array<T>}    a     The first array\n * @param  {Array<T>}    b     The second array\n * @return {Array<T>}          Elements common to both the first and second array\n */\nexport function intersection<T>(a: T[], b: T[]): T[] {\n  const test = new Set(a);\n  const ref = new Set(b);\n\n  return Array.from(test).filter((elem): elem is T => ref.has(elem));\n}\n\n/**\n * Computes the longest common subsequence for two arrays.\n * This function returns the elements from the two arrays\n * that form the LCS, in order of their appearance.\n *\n * For speed, the search-space is pruned by eliminating\n * common entities at the start and end of both input arrays.\n *\n * @method lcs\n * @param  {Array<string>}    a     The first array\n * @param  {Array<string>}    b     The second array\n * @return {Array<string>}          The longest common subsequence between the first and second array\n */\nexport function lcs(a: string[], b: string[]): string[] {\n  if (a.length === 0 || b.length === 0) {\n    return [];\n  }\n\n  const dp: number[][] = new Array(a.length + 1).fill(0).map(() => new Array(b.length + 1).fill(0));\n\n  for (let i = 1; i <= a.length; i++) {\n    for (let j = 1; j <= b.length; j++) {\n      if (a[i - 1] === b[j - 1]) {\n        dp[i][j] = dp[i - 1][j - 1] + 1;\n      } else {\n        dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n      }\n    }\n  }\n\n  const lcsResult: string[] = [];\n  let i = a.length;\n  let j = b.length;\n\n  while (i > 0 && j > 0) {\n    if (a[i - 1] === b[j - 1]) {\n      lcsResult.unshift(a[i - 1]);\n      i--;\n      j--;\n    } else if (dp[i - 1][j] > dp[i][j - 1]) {\n      i--;\n    } else {\n      j--;\n    }\n  }\n\n  return lcsResult;\n}\n", "import * as utils from './utils';\n\nexport * from './utils';\n\n/** Options for ROUGE-N evaluation */\nexport interface RougeNOptions {\n  /** The size of the ngram used (default: 1) */\n  n?: number;\n  /** The beta value used for the f-measure (default: 1.0) */\n  beta?: number;\n  /** Whether comparison is case-sensitive (default: true) */\n  caseSensitive?: boolean;\n  /** Custom ngram generator function */\n  nGram?: (tokens: string[], n: number) => string[];\n  /** Custom string tokenizer */\n  tokenizer?: (input: string) => string[];\n}\n\n/** Options for ROUGE-S (skip-bigram) evaluation */\nexport interface RougeSOptions {\n  /** The beta value used for the f-measure (default: 1.0) */\n  beta?: number;\n  /** Whether comparison is case-sensitive (default: true) */\n  caseSensitive?: boolean;\n  /** Maximum skip distance between words (default: Infinity) */\n  maxSkip?: number;\n  /** Custom skip-bigram generator function */\n  skipBigram?: (tokens: string[], maxSkip?: number) => string[];\n  /** Custom string tokenizer */\n  tokenizer?: (input: string) => string[];\n}\n\n/** Options for ROUGE-L (LCS) evaluation */\nexport interface RougeLOptions {\n  /** The beta value used for the f-measure (default: 1.0) */\n  beta?: number;\n  /** Whether comparison is case-sensitive (default: true) */\n  caseSensitive?: boolean;\n  /** Custom LCS function */\n  lcs?: (a: string[], b: string[]) => string[];\n  /** Custom sentence segmenter */\n  segmenter?: (input: string) => string[];\n  /** Custom string tokenizer */\n  tokenizer?: (input: string) => string[];\n}\n\n/**\n * Computes the ROUGE-N score for a candidate summary.\n *\n * Configuration object schema and defaults:\n * ```\n * {\n * \tn: 1                            // The size of the ngram used\n * \tbeta: 1.0                       // The beta value used for the f-measure\n * \tcaseSensitive: true             // Whether comparison is case-sensitive\n * \tnGram: <inbuilt function>,      // The ngram generator function\n * \ttokenizer: <inbuilt function>   // The string tokenizer\n * }\n * ```\n *\n * `nGram` has a type signature of ((Array<string>, number) => Array<string>)\n * `tokenizer` has a type signature of ((string) => Array<string)\n *\n * @method n\n * @param  {string}     cand        The candidate summary to be evaluated\n * @param  {string}     ref         The reference summary to be evaluated against\n * @param  {Object}     opts        Configuration options (see example)\n * @return {number}                 The ROUGE-N F-score\n */\nexport function n(cand: string, ref: string, opts?: RougeNOptions): number {\n  if (cand.length === 0) {\n    throw new RangeError('Candidate cannot be an empty string');\n  }\n  if (ref.length === 0) {\n    throw new RangeError('Reference cannot be an empty string');\n  }\n\n  // Merge user-provided configuration with defaults\n  const options = {\n    n: 1,\n    beta: 1.0,\n    caseSensitive: true,\n    nGram: utils.nGram,\n    tokenizer: utils.treeBankTokenize,\n    ...opts,\n  };\n\n  const candText = options.caseSensitive ? cand : cand.toLowerCase();\n  const refText = options.caseSensitive ? ref : ref.toLowerCase();\n\n  const candGrams = options.nGram(options.tokenizer(candText), options.n);\n  const refGrams = options.nGram(options.tokenizer(refText), options.n);\n\n  const match = utils.intersection(candGrams, refGrams);\n\n  if (match.length === 0) {\n    return 0;\n  }\n\n  const precision = match.length / candGrams.length;\n  const recall = match.length / refGrams.length;\n\n  return utils.fMeasure(precision, recall, options.beta);\n}\n\n/**\n * Computes the ROUGE-S score for a candidate summary.\n *\n * Configuration object schema and defaults:\n * ```\n * {\n * \tbeta: 1.0                           // The beta value used for the f-measure\n * \tcaseSensitive: true                 // Whether comparison is case-sensitive\n * \tmaxSkip: Infinity                   // Maximum skip distance between words\n * \tskipBigram: <inbuilt function>,     // The skip-bigram generator function\n * \ttokenizer: <inbuilt function>       // The string tokenizer\n * }\n * ```\n *\n * `skipBigram` has a type signature of ((Array<string>, number) => Array<string>)\n * `tokenizer` has a type signature of ((string) => Array<string)\n *\n * @method s\n * @param  {string}     cand        The candidate summary to be evaluated\n * @param  {string}     ref         The reference summary to be evaluated against\n * @param  {Object}     opts        Configuration options (see example)\n * @return {number}                 The ROUGE-S score\n */\nexport function s(cand: string, ref: string, opts?: RougeSOptions): number {\n  if (cand.length === 0) {\n    throw new RangeError('Candidate cannot be an empty string');\n  }\n  if (ref.length === 0) {\n    throw new RangeError('Reference cannot be an empty string');\n  }\n\n  // Merge user-provided configuration with defaults\n  const options = {\n    beta: 1.0,\n    caseSensitive: true,\n    maxSkip: Number.POSITIVE_INFINITY,\n    skipBigram: utils.skipBigram,\n    tokenizer: utils.treeBankTokenize,\n    ...opts,\n  };\n\n  const candText = options.caseSensitive ? cand : cand.toLowerCase();\n  const refText = options.caseSensitive ? ref : ref.toLowerCase();\n\n  const candGrams = options.skipBigram(options.tokenizer(candText), options.maxSkip);\n  const refGrams = options.skipBigram(options.tokenizer(refText), options.maxSkip);\n\n  const skip2 = utils.intersection(candGrams, refGrams).length;\n\n  if (skip2 === 0) {\n    return 0;\n  }\n  const skip2Recall = skip2 / refGrams.length;\n  const skip2Prec = skip2 / candGrams.length;\n\n  return utils.fMeasure(skip2Prec, skip2Recall, options.beta);\n}\n\n/**\n * Computes the ROUGE-L score for a candidate summary\n *\n * Configuration object schema and defaults:\n * ```\n * {\n * \tbeta: 1.0                           // The beta value used for the f-measure\n * \tcaseSensitive: true                 // Whether comparison is case-sensitive\n * \tlcs: <inbuilt function>             // The least common subsequence function\n * \tsegmenter: <inbuilt function>,      // The sentence segmenter\n * \ttokenizer: <inbuilt function>       // The string tokenizer\n * }\n * ```\n *\n * `lcs` has a type signature of ((Array<string>, Array<string>) => Array<string>)\n * `segmenter` has a type signature of ((string) => Array<string)\n * `tokenizer` has a type signature of ((string) => Array<string)\n *\n * @method l\n * @param  {string}     cand        The candidate summary to be evaluated\n * @param  {string}     ref         The reference summary to be evaluated against\n * @param  {Object}     opts        Configuration options (see example)\n * @return {number}                 The ROUGE-L score\n */\nexport function l(cand: string, ref: string, opts?: RougeLOptions): number {\n  if (cand.length === 0) {\n    throw new RangeError('Candidate cannot be an empty string');\n  }\n  if (ref.length === 0) {\n    throw new RangeError('Reference cannot be an empty string');\n  }\n\n  // Merge user-provided configuration with defaults\n  const options = {\n    beta: 1.0,\n    caseSensitive: true,\n    lcs: utils.lcs,\n    segmenter: utils.sentenceSegment,\n    tokenizer: utils.treeBankTokenize,\n    ...opts,\n  };\n\n  const candText = options.caseSensitive ? cand : cand.toLowerCase();\n  const refText = options.caseSensitive ? ref : ref.toLowerCase();\n\n  const candSents = options.segmenter(candText);\n  const refSents = options.segmenter(refText);\n\n  const candWords = options.tokenizer(candText);\n  const refWords = options.tokenizer(refText);\n\n  const lcsAcc = refSents.map((r) => {\n    const rTokens = options.tokenizer(r);\n    const lcsUnion = new Set(candSents.flatMap((c) => options.lcs(options.tokenizer(c), rTokens)));\n\n    return lcsUnion.size;\n  });\n\n  // Sum the array as quickly as we can\n  let lcsSum = 0;\n  while (lcsAcc.length > 0) {\n    lcsSum += lcsAcc.pop() || 0;\n  }\n\n  if (lcsSum === 0) {\n    return 0;\n  }\n\n  // Recall = LCS / |reference| (how much of reference is captured)\n  // Precision = LCS / |candidate| (how precise is the candidate)\n  const lcsRecall = lcsSum / refWords.length;\n  const lcsPrec = lcsSum / candWords.length;\n\n  return utils.fMeasure(lcsPrec, lcsRecall, options.beta);\n}\n"],
  "mappings": "AAAO,IAAMA,EAAkC,CAC7C,kBACA,gBACA,iBACA,iBACA,iBACA,iBACA,kBACA,gBACA,eACA,eACF,EAEaC,EAAuB,CAClC,KACA,KACA,MACA,KACA,KACA,OACA,KACA,MACA,OACA,MACA,MACA,OACA,OACA,MACA,MACA,MACA,MACA,KACA,OACA,MACA,OACA,MACA,MACA,MACA,OACA,SACA,SACA,MACA,MACA,OACA,MACA,MACA,MACA,OACA,OACA,OACA,QACA,MACA,SACA,OACA,MACA,KACA,MACA,MACA,OACA,MACA,OACA,MACA,MACF,EAEaC,EAAwB,CACnC,MACA,KACA,MACA,KACA,KACA,OACA,KACA,KACA,KACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,KACA,MACA,KACA,MACA,MACA,QACA,KACA,MACA,MACA,MACA,MACA,KACA,MACA,KACF,EAEaC,EAA+B,CAC1C,KACA,OACA,QACA,SACA,WACA,OACA,OACA,OACA,OACA,MACA,KACF,EAEaC,EAAwB,CACnC,MACA,OACA,MACA,MACA,QACA,MACA,OACA,OACA,MACA,MACA,MACA,KACA,KACA,MACA,MACA,KACA,KACA,MACA,OACA,MACA,KACA,KACA,KACA,OACA,OACA,OACA,MACA,OACA,MACA,OACA,QACA,OACA,KACA,MACA,OACA,MACA,KACA,KACA,KACA,OACA,MACA,OACA,KACA,MACA,QACA,OACA,MACA,MACA,OACA,MACA,MACA,OACA,KACA,KACA,OACA,MACA,MACA,QACA,MACA,OACF,EAEaC,EAAsB,CAAC,MAAO,KAAK,EAEnCC,EAAuB,CAClC,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OACA,MACA,MACA,KACF,EAEaC,EAA4B,CACvC,KACA,MACA,MACA,QACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,GAAGN,CACL,EAEaO,EAA+B,CAC1C,GAAGN,EACH,GAAGI,EACH,GAAGH,EACH,GAAGC,EACH,GAAGC,EACH,GAAGJ,CACL,ECnMO,SAASQ,EAAiBC,EAAyB,CACxD,GAAIA,EAAM,SAAW,EACnB,MAAO,CAAC,EAeV,IAAIC,EAAQD,EACT,QAAQ,KAAM,MAAM,EACpB,QAAQ,cAAe,QAAQ,EAC/B,QAAQ,WAAY,OAAO,EAC3B,QAAQ,YAAa,MAAM,EAC3B,QAAQ,8BAA+B,UAAU,EACjD,QAAQ,SAAU,MAAM,EACxB,QAAQ,eAAgB,MAAM,EAC9B,QAAQ,QAAS,MAAM,EAI1BC,EAAQ,IAAIA,CAAK,IAOjBA,EAAQA,EACL,QAAQ,KAAM,MAAM,EACpB,QAAQ,YAAa,OAAO,EAC5B,QAAQ,gBAAiB,OAAO,EAChC,QAAQ,sCAAuC,MAAM,EAExD,QAAWC,KAAeC,EAExBF,EAAQA,EAAM,QAAQC,EAAa,SAAS,EAI9C,OAAAD,EAAQA,EAAM,QAAQ,SAAU,GAAG,EAAE,QAAQ,SAAU,EAAE,EAGlDA,EAAM,MAAM,GAAG,CACxB,CAcO,SAASG,EAAgBJ,EAAyB,CACvD,GAAIA,EAAM,SAAW,EACnB,MAAO,CAAC,EAGV,IAAMK,EAAW,IAAI,OAAO,OAAOC,EAAmB,KAAK,GAAG,CAAC,YAAa,GAAG,EACzEC,EAAa,IAAI,OAAO,gBAAiB,GAAG,EAC5CC,EAAW,IAAI,OAAO,UAAW,GAAG,EAGpCC,EAAa,YACbC,EAAW,IAAI,OAAO,OAAOC,EAAgB,KAAK,GAAG,CAAC,YAAa,GAAG,EAQtEC,EAASZ,EAAM,MAAM,0DAA0D,EAE/Ea,EAAgB,CAAC,EACvB,QAASC,EAAM,EAAGA,EAAMF,EAAO,OAAQE,IACrC,GAAIF,EAAOE,CAAG,EAKZ,GAFAF,EAAOE,CAAG,EAAIF,EAAOE,CAAG,EAAE,QAAQ,MAAO,EAAE,EAAE,QAAQ,MAAO,EAAE,EAE1DN,EAAS,KAAKI,EAAOE,CAAG,CAAC,EACvBF,EAAOE,EAAM,CAAC,GAAKC,EAAeH,EAAOE,CAAG,CAAC,EAI/CF,EAAOE,EAAM,CAAC,EAAI,GAAGF,EAAOE,CAAG,EAAE,KAAK,CAAC,IAAIF,EAAOE,EAAM,CAAC,EAAE,QAAQ,MAAO,GAAG,CAAC,GAI9ED,EAAI,KAAK,GAAGD,EAAOE,CAAG,EAAE,KAAK,EAAE,MAAM;AAAA,CAAI,CAAC,UAEnCF,EAAOE,EAAM,CAAC,GAAKT,EAAS,KAAKO,EAAOE,CAAG,CAAC,EAAG,CACxD,IAAME,EAAYJ,EAAOE,EAAM,CAAC,EAC5BE,EAAU,KAAK,GAAKD,EAAeC,CAAS,GAAK,CAACN,EAAS,KAAKE,EAAOE,CAAG,CAAC,GAG7ED,EAAI,KAAKD,EAAOE,CAAG,CAAC,EACpBF,EAAOE,CAAG,EAAI,IAGdF,EAAOE,EAAM,CAAC,EAAI,GAAGF,EAAOE,CAAG,CAAC,IAAIE,EAAU,QAAQ,MAAO,GAAG,CAAC,EAErE,SAAWJ,EAAOE,CAAG,EAAE,OAAS,GAAKF,EAAOE,EAAM,CAAC,GAAKP,EAAW,KAAKK,EAAOE,CAAG,CAAC,EAAG,CACpF,IAAMG,EAAQL,EAAOE,CAAG,EAAE,MAAM,GAAG,EAC7BI,EAAWD,EAAM,GAAG,EAAE,EAExBC,IAAaA,EAAS,YAAY,EAEpCN,EAAOE,EAAM,CAAC,EAAI,GAAGF,EAAOE,CAAG,CAAC,IAAIF,EAAOE,EAAM,CAAC,EAAE,QAAQ,MAAO,GAAG,CAAC,GAC9DF,EAAOE,EAAM,CAAC,IACnBC,EAAeE,EAAM,GAAG,EAAE,CAAE,GAAKF,EAAeH,EAAOE,EAAM,CAAC,CAAC,EAGjEF,EAAOE,EAAM,CAAC,EAAIF,EAAOE,CAAG,EAAIF,EAAOE,EAAM,CAAC,EAAE,QAAQ,MAAO,GAAG,EAAIF,EAAOE,EAAM,CAAC,GAGpFD,EAAI,KAAKD,EAAOE,CAAG,CAAC,EACpBF,EAAOE,CAAG,EAAI,IAGpB,MAAWF,EAAOE,EAAM,CAAC,GAAKL,EAAW,KAAKG,EAAOE,CAAG,CAAC,EAEvDF,EAAOE,EAAM,CAAC,EAAIF,EAAOE,CAAG,EAAIF,EAAOE,EAAM,CAAC,EAAE,QAAQ,MAAO,GAAG,EACzDF,EAAOE,CAAG,GAAKF,EAAOE,CAAG,EAAE,OAAS,IAC7CD,EAAI,KAAKD,EAAOE,CAAG,CAAC,EACpBF,EAAOE,CAAG,EAAI,IAMpB,OAAOD,EAAI,SAAW,EAAI,CAACb,CAAK,EAAIa,CACtC,CAQO,SAASE,EAAef,EAAwB,CACrD,IAAMmB,EAAYnB,EAAM,KAAK,EAAE,MAAM,EAAG,CAAC,EACzC,OAAOoB,EAAgBD,CAAS,CAClC,CAQO,SAASC,EAAgBpB,EAAwB,CACtD,GAAIA,EAAM,SAAW,EACnB,MAAM,IAAI,WAAW,oCAAoC,EAI3D,OAAOA,EAAM,YAAY,IAAMA,GAASA,EAAM,YAAY,IAAMA,CAClE,CAeA,SAASqB,EAAcC,EAAqBC,EAA6B,IAAoB,CAC3F,OAAQ,IAAM,CACZ,IAAMC,EAAQ,IAAID,EAElB,OAAQE,GAAS,CACf,GAAID,EAAM,IAAIC,CAAC,EAAG,CAChB,IAAMC,EAAeF,EAAM,IAAIC,CAAC,EAChC,GAAIC,IAAiB,OACnB,OAAOA,CAEX,CACA,IAAMC,EAASL,EAAKG,CAAC,EACrB,OAAAD,EAAM,IAAIC,EAAGE,CAAM,EACZA,CACT,CACF,GAAG,CACL,CAcA,SAASC,EAAQC,EAAWhB,EAAM,EAAW,CAC3C,GAAIgB,EAAI,EACN,MAAM,IAAI,WAAW,iCAAiC,EAExD,OAAOA,EAAI,EAAIhB,EAAMe,EAAQC,EAAI,EAAGA,EAAIhB,CAAG,CAC7C,CAUO,IAAMiB,EAAOT,EAAQO,CAAO,EAU5B,SAASG,EAAWC,EAAkBC,EAAkB,OAAO,kBAA6B,CACjG,GAAID,EAAO,OAAS,EAClB,MAAM,IAAI,WAAW,oCAAoC,EAG3D,IAAMnB,EAAgB,CAAC,EACvB,QAASqB,EAAU,EAAGA,EAAUF,EAAO,OAAS,EAAGE,IAAW,CAC5D,IAAMC,EAAS,KAAK,IAAID,EAAU,EAAID,EAASD,EAAO,MAAM,EAC5D,QAASI,EAAWF,EAAU,EAAGE,EAAWD,EAAQC,IAClDvB,EAAI,KAAK,GAAGmB,EAAOE,CAAO,CAAC,IAAIF,EAAOI,CAAQ,CAAC,EAAE,CAErD,CAEA,OAAOvB,CACT,CAQO,IAAMwB,EAAmC,CAC9C,MAAO,GACP,IAAK,GACL,IAAK,KACP,EAWO,SAASC,EAAMN,EAAkB,EAAI,EAAGO,EAA6B,CAAC,EAAa,CACxF,GAAI,EAAI,EACN,MAAM,IAAI,WAAW,qCAAqC,EAG5D,GAAIP,EAAO,OAAS,EAClB,MAAM,IAAI,WAAW,iEAAiE,EAGxF,IAAIQ,EAAgBR,EAEpB,GAAI,OAAO,KAAKO,CAAG,EAAE,OAAS,EAAG,CAC/B,IAAME,EAAS,CAAE,GAAGJ,EAAoB,GAAGE,CAAI,EAGzCG,EAAaV,EAAO,MAAM,CAAC,EAEjC,GAAIS,EAAO,MACT,QAASE,EAAI,EAAGA,EAAI,EAAI,EAAGA,IACzBD,EAAW,QAAQD,EAAO,GAAG,EAGjC,GAAIA,EAAO,IACT,QAASE,EAAI,EAAGA,EAAI,EAAI,EAAGA,IACzBD,EAAW,KAAKD,EAAO,GAAG,EAI9BD,EAAgBE,CAClB,CAEA,IAAM7B,EAAgB,CAAC,EACvB,QAASC,EAAM,EAAGA,EAAM0B,EAAc,OAAS,EAAI,EAAG1B,IACpDD,EAAI,KAAK2B,EAAc,MAAM1B,EAAKA,EAAM,CAAC,EAAE,KAAK,GAAG,CAAC,EAGtD,OAAOD,CACT,CAUO,SAAS+B,EAAMC,EAAqB,CACzC,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,8BAA8B,EAErD,MAAO,IAAMA,GAAOA,EAAM,EAC5B,CAQO,SAASC,EAAe9C,EAAyB,CACtD,GAAIA,EAAM,SAAW,EACnB,MAAM,IAAI,WAAW,0CAA0C,EAEjE,OAAOA,EAAM,OAAO,CAAC6B,EAAGkB,IAAMlB,EAAIkB,CAAC,EAAI/C,EAAM,MAC/C,CAgBO,SAASgD,EACdC,EACAC,EACA5B,EACA6B,EAAgCL,EACxB,CACR,GAAIG,EAAM,OAAS,EACjB,MAAM,IAAI,WAAW,oDAAoD,EAG3E,IAAMG,EAAkBH,EAAM,IAAKI,GAAM/B,EAAK+B,EAAGH,CAAG,CAAC,EAE/CrC,EAAgB,CAAC,EACvB,QAASC,EAAM,EAAGA,EAAMsC,EAAM,OAAQtC,IAAO,CAE3C,IAAMwC,EAAcF,EAAM,MAAM,CAAC,EACjCE,EAAY,OAAOxC,EAAK,CAAC,EAEzBD,EAAI,KAAK,KAAK,IAAI,GAAGyC,CAAW,CAAC,CACnC,CAEA,OAAOH,EAAKtC,CAAG,CACjB,CAqBO,SAAS0C,EAASC,EAAWC,EAAWC,EAAO,EAAa,CACjE,GAAIF,EAAI,GAAKA,EAAI,EACf,MAAM,IAAI,WAAW,wDAA8C,EAErE,GAAIC,EAAI,GAAKA,EAAI,EACf,MAAM,IAAI,WAAW,qDAA2C,EAElE,GAAIC,EAAO,EACT,MAAM,IAAI,WAAW,yBAAyB,EAIhD,GAAIF,IAAM,GAAKC,IAAM,EACnB,MAAO,GAET,GAAI,CAAC,OAAO,SAASC,CAAI,EACvB,OAAOD,EAGT,IAAME,EAASD,EAAOA,EAChBE,EAAcD,EAASH,EAAIC,EACjC,OAAIG,IAAgB,EACX,GAGA,EAAID,GAAUH,EAAIC,EAAKG,CAClC,CAWO,SAASC,EAAgBC,EAAQC,EAAa,CACnD,IAAMZ,EAAO,IAAI,IAAIW,CAAC,EAChBZ,EAAM,IAAI,IAAIa,CAAC,EAErB,OAAO,MAAM,KAAKZ,CAAI,EAAE,OAAQa,GAAoBd,EAAI,IAAIc,CAAI,CAAC,CACnE,CAeO,SAASC,EAAIH,EAAaC,EAAuB,CACtD,GAAID,EAAE,SAAW,GAAKC,EAAE,SAAW,EACjC,MAAO,CAAC,EAGV,IAAMG,EAAiB,IAAI,MAAMJ,EAAE,OAAS,CAAC,EAAE,KAAK,CAAC,EAAE,IAAI,IAAM,IAAI,MAAMC,EAAE,OAAS,CAAC,EAAE,KAAK,CAAC,CAAC,EAEhG,QAASpB,EAAI,EAAGA,GAAKmB,EAAE,OAAQnB,IAC7B,QAASwB,EAAI,EAAGA,GAAKJ,EAAE,OAAQI,IACzBL,EAAEnB,EAAI,CAAC,IAAMoB,EAAEI,EAAI,CAAC,EACtBD,EAAGvB,CAAC,EAAEwB,CAAC,EAAID,EAAGvB,EAAI,CAAC,EAAEwB,EAAI,CAAC,EAAI,EAE9BD,EAAGvB,CAAC,EAAEwB,CAAC,EAAI,KAAK,IAAID,EAAGvB,EAAI,CAAC,EAAEwB,CAAC,EAAGD,EAAGvB,CAAC,EAAEwB,EAAI,CAAC,CAAC,EAKpD,IAAMC,EAAsB,CAAC,EACzBzB,EAAImB,EAAE,OACNK,EAAIJ,EAAE,OAEV,KAAOpB,EAAI,GAAKwB,EAAI,GACdL,EAAEnB,EAAI,CAAC,IAAMoB,EAAEI,EAAI,CAAC,GACtBC,EAAU,QAAQN,EAAEnB,EAAI,CAAC,CAAC,EAC1BA,IACAwB,KACSD,EAAGvB,EAAI,CAAC,EAAEwB,CAAC,EAAID,EAAGvB,CAAC,EAAEwB,EAAI,CAAC,EACnCxB,IAEAwB,IAIJ,OAAOC,CACT,CC5bO,SAASC,EAAEC,EAAcC,EAAaC,EAA8B,CACzE,GAAIF,EAAK,SAAW,EAClB,MAAM,IAAI,WAAW,qCAAqC,EAE5D,GAAIC,EAAI,SAAW,EACjB,MAAM,IAAI,WAAW,qCAAqC,EAI5D,IAAME,EAAU,CACd,EAAG,EACH,KAAM,EACN,cAAe,GACf,MAAaC,EACb,UAAiBC,EACjB,GAAGH,CACL,EAEMI,EAAWH,EAAQ,cAAgBH,EAAOA,EAAK,YAAY,EAC3DO,EAAUJ,EAAQ,cAAgBF,EAAMA,EAAI,YAAY,EAExDO,EAAYL,EAAQ,MAAMA,EAAQ,UAAUG,CAAQ,EAAGH,EAAQ,CAAC,EAChEM,EAAWN,EAAQ,MAAMA,EAAQ,UAAUI,CAAO,EAAGJ,EAAQ,CAAC,EAE9DO,EAAcC,EAAaH,EAAWC,CAAQ,EAEpD,GAAIC,EAAM,SAAW,EACnB,MAAO,GAGT,IAAME,EAAYF,EAAM,OAASF,EAAU,OACrCK,EAASH,EAAM,OAASD,EAAS,OAEvC,OAAaK,EAASF,EAAWC,EAAQV,EAAQ,IAAI,CACvD,CAyBO,SAASY,EAAEf,EAAcC,EAAaC,EAA8B,CACzE,GAAIF,EAAK,SAAW,EAClB,MAAM,IAAI,WAAW,qCAAqC,EAE5D,GAAIC,EAAI,SAAW,EACjB,MAAM,IAAI,WAAW,qCAAqC,EAI5D,IAAME,EAAU,CACd,KAAM,EACN,cAAe,GACf,QAAS,OAAO,kBAChB,WAAkBa,EAClB,UAAiBX,EACjB,GAAGH,CACL,EAEMI,EAAWH,EAAQ,cAAgBH,EAAOA,EAAK,YAAY,EAC3DO,EAAUJ,EAAQ,cAAgBF,EAAMA,EAAI,YAAY,EAExDO,EAAYL,EAAQ,WAAWA,EAAQ,UAAUG,CAAQ,EAAGH,EAAQ,OAAO,EAC3EM,EAAWN,EAAQ,WAAWA,EAAQ,UAAUI,CAAO,EAAGJ,EAAQ,OAAO,EAEzEc,EAAcN,EAAaH,EAAWC,CAAQ,EAAE,OAEtD,GAAIQ,IAAU,EACZ,MAAO,GAET,IAAMC,EAAcD,EAAQR,EAAS,OAC/BU,EAAYF,EAAQT,EAAU,OAEpC,OAAaM,EAASK,EAAWD,EAAaf,EAAQ,IAAI,CAC5D,CA0BO,SAASiB,EAAEpB,EAAcC,EAAaC,EAA8B,CACzE,GAAIF,EAAK,SAAW,EAClB,MAAM,IAAI,WAAW,qCAAqC,EAE5D,GAAIC,EAAI,SAAW,EACjB,MAAM,IAAI,WAAW,qCAAqC,EAI5D,IAAME,EAAU,CACd,KAAM,EACN,cAAe,GACf,IAAWkB,EACX,UAAiBC,EACjB,UAAiBjB,EACjB,GAAGH,CACL,EAEMI,EAAWH,EAAQ,cAAgBH,EAAOA,EAAK,YAAY,EAC3DO,EAAUJ,EAAQ,cAAgBF,EAAMA,EAAI,YAAY,EAExDsB,EAAYpB,EAAQ,UAAUG,CAAQ,EACtCkB,EAAWrB,EAAQ,UAAUI,CAAO,EAEpCkB,EAAYtB,EAAQ,UAAUG,CAAQ,EACtCoB,EAAWvB,EAAQ,UAAUI,CAAO,EAEpCoB,EAASH,EAAS,IAAKI,GAAM,CACjC,IAAMC,EAAU1B,EAAQ,UAAUyB,CAAC,EAGnC,OAFiB,IAAI,IAAIL,EAAU,QAASO,GAAM3B,EAAQ,IAAIA,EAAQ,UAAU2B,CAAC,EAAGD,CAAO,CAAC,CAAC,EAE7E,IAClB,CAAC,EAGGE,EAAS,EACb,KAAOJ,EAAO,OAAS,GACrBI,GAAUJ,EAAO,IAAI,GAAK,EAG5B,GAAII,IAAW,EACb,MAAO,GAKT,IAAMC,EAAYD,EAASL,EAAS,OAC9BO,EAAUF,EAASN,EAAU,OAEnC,OAAaX,EAASmB,EAASD,EAAW7B,EAAQ,IAAI,CACxD",
  "names": ["TREEBANK_CONTRACTIONS", "HONORIFICS", "ABBR_COMMON", "ABBR_ORGANIZATIONS", "ABBR_PLACES", "ABBR_TIME", "ABBR_DATES", "GATE_EXCEPTIONS", "GATE_SUBSTITUTIONS", "treeBankTokenize", "input", "parse", "contraction", "TREEBANK_CONTRACTIONS", "sentenceSegment", "abbrvReg", "GATE_SUBSTITUTIONS", "acronymReg", "breakReg", "ellipseReg", "excepReg", "GATE_EXCEPTIONS", "chunks", "acc", "idx", "strIsTitleCase", "nextChunk", "words", "lastWord", "firstChar", "charIsUpperCase", "memoize", "func", "Store", "cache", "n", "cachedResult", "result", "factRec", "x", "fact", "skipBigram", "tokens", "maxSkip", "baseIdx", "maxIdx", "sweepIdx", "NGRAM_DEFAULT_OPTS", "nGram", "pad", "workingTokens", "config", "tempTokens", "i", "comb2", "val", "arithmeticMean", "y", "jackKnife", "cands", "ref", "test", "pairs", "c", "leaveOneOut", "fMeasure", "p", "r", "beta", "betaSq", "denominator", "intersection", "a", "b", "elem", "lcs", "dp", "j", "lcsResult", "n", "cand", "ref", "opts", "options", "nGram", "treeBankTokenize", "candText", "refText", "candGrams", "refGrams", "match", "intersection", "precision", "recall", "fMeasure", "s", "skipBigram", "skip2", "skip2Recall", "skip2Prec", "l", "lcs", "sentenceSegment", "candSents", "refSents", "candWords", "refWords", "lcsAcc", "r", "rTokens", "c", "lcsSum", "lcsRecall", "lcsPrec"]
}
