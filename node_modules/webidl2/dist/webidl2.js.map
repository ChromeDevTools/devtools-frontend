{"version":3,"file":"webidl2.js","mappings":"CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,GAAIH,GACe,iBAAZC,QACdA,QAAiB,QAAID,IAErBD,EAAc,QAAIC,GACnB,CATD,CASGK,YAAY,I,mBCRf,IAAIC,EAAsB,CCA1BA,EAAwB,CAACL,EAASM,KACjC,IAAI,IAAIC,KAAOD,EACXD,EAAoBG,EAAEF,EAAYC,KAASF,EAAoBG,EAAER,EAASO,IAC5EE,OAAOC,eAAeV,EAASO,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,IAE1E,ECNDF,EAAwB,CAACQ,EAAKC,IAAUL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,GCClFT,EAAyBL,IACH,oBAAXkB,QAA0BA,OAAOC,aAC1CV,OAAOC,eAAeV,EAASkB,OAAOC,YAAa,CAAEC,MAAO,WAE7DX,OAAOC,eAAeV,EAAS,aAAc,CAAEoB,OAAO,GAAO,G,KCoC9D,SAASC,EACPC,EACAC,EACAC,EACAC,EACAC,GACA,MAAEC,EAAQ,QAAO,QAAEC,EAAO,SAAEC,GAAa,CAAC,GAK1C,SAASC,EAAYC,GACnB,OAAOA,EAAQ,EACXT,EAAOU,MAAMT,EAAUA,EAAWQ,GAClCT,EAAOU,MAAMC,KAAKC,IAAIX,EAAWQ,EAAO,GAAIR,EAClD,CAQA,SAASY,EAAaC,GAAQ,SAAEC,GAAa,CAAC,GAC5C,MAAMC,EAAOF,EAAOG,KAAKC,GAAMA,EAAEC,OAASD,EAAEpB,QAAOsB,KAAK,IAClDC,EAAYrB,EAAOC,GACzB,MAAuB,QAAnBoB,EAAUC,KACLN,EAELD,EACKC,EAAOK,EAAUF,OAEnBH,EAAKN,MAAMW,EAAUF,OAAOI,OACrC,CAEA,MACMC,EACsB,QAA1BxB,EAAOC,GAAUqB,KACbtB,EAAOC,GAAUuB,KACjBxB,EAAOuB,OAAS,EAChBvB,EAAOC,EAAW,GAAGuB,KACrB,EAEAC,EAjFR,SAAkBT,GAChB,MAAMU,EAAWV,EAAKW,MAAM,MAC5B,OAAOD,EAASA,EAASH,OAAS,EACpC,CA8E4BK,CACxBf,EAAaL,GATG,GASsB,CAAEO,UAAU,KAG9Cc,EAAmBrB,EAZP,GAaZsB,EAAiBjB,EAAagB,GAI9BE,EAAgBN,EAHMK,EAAeH,MAAM,MAAM,GAGS,MADjD,IAAIK,OAAOP,EAAkBF,QAAU,KAGhDU,EAAuB,WAAT7B,EAAoB,QAAU,SAQ5C8B,EAAU,GAAG9B,mBAAsBoB,IAPpBxB,EAAOmC,KAAO,OAAOnC,EAAOmC,OAAS,KAExDjC,GAAWA,EAAQiC,KACf,KAAKF,OAAiB/B,EAAQkC,QAAU,WAAa,KAnF7D,SAAuBC,GACrB,MAAMC,EAAY,CAACD,GACnB,KAAOA,GAAQA,EAAKE,QAAQ,CAC1B,MAAM,OAAEA,GAAWF,EACnBC,EAAUE,QAAQD,GAClBF,EAAOE,CACT,CACA,OAAOD,EAAUrB,KAAKwB,GAfxB,SAAuBC,EAAMC,GAC3B,IAAIC,EAASF,EAIb,OAHIC,IACFC,GAAU,IAAID,KAETC,CACT,CAS8BC,CAAcJ,EAAEnB,KAAMmB,EAAEN,QAAOf,KAAK,OAClE,CA2EkE0B,CACxD5C,OAEF,QACiF6B,IACvF,MAAO,CACL5B,QAAS,GAAG+B,KAAW/B,IACvB4C,YAAa5C,EACb+B,UACAV,OACAwB,WAAYhD,EAAOmC,KACnB9B,QACAE,WACAD,UACA2C,MAAOnB,EACPoB,OAAQrB,EAEZ,CAKO,SAASsB,EAAYnD,EAAQC,EAAUC,EAASC,GACrD,OAAOJ,EAAMC,EAAQC,EAAUC,EAASC,EAAS,SACnD,CAMO,SAASiD,EACdC,EACAnD,EACAK,EACAJ,EACAmD,EAAU,CAAC,GAGX,OADAA,EAAQ/C,SAAWA,EACZR,EACLG,EAAQF,OACRqD,EAAME,MACNrD,EACAC,EACA,aACAmD,EAEJ,C,6FCjJO,MAAME,KAMXC,aAAY,OAAEzD,EAAM,OAAEkD,IACpB/D,OAAOuE,iBAAiBC,KAAM,CAC5B3D,OAAQ,CAAEF,MAAOE,GACjBkD,OAAQ,CAAEpD,MAAOoD,EAAQU,UAAU,GACnCrB,OAAQ,CAAEzC,MAAO,KAAM8D,UAAU,GACjCD,KAAM,CAAE7D,MAAO6D,OAEnB,CAEAE,SACE,MAAMC,EAAO,CAAExC,UAAMyC,EAAW5B,UAAM4B,EAAWC,iBAAaD,GAC9D,IAAIE,EAAQN,KACZ,KAAOM,IAAU9E,OAAOM,WAAW,CACjC,MAAMyE,EAAU/E,OAAOgF,0BAA0BF,GACjD,IAAK,MAAOhF,EAAKa,KAAUX,OAAOiF,QAAQF,IACpCpE,EAAMT,YAAcS,EAAMR,OAE5BwE,EAAK7E,GAAO0E,KAAK1E,IAGrBgF,EAAQ9E,OAAOkF,eAAeJ,EAChC,CACA,OAAOH,CACT,EClBK,SAASQ,EACdC,EACAC,GACA,iBAAEC,GAAqB,CAAC,GAExB,IAAKF,EAAQG,MAAO,CAClB,MAAMC,EAAMH,EAAKI,OAAOtF,IAAIiF,EAAQA,SACpC,IAAKI,EACH,OAEF,GAAiB,YAAbA,EAAIrD,KAAoB,CAC1B,MAAM,0BAAEuD,GAA8BL,EAAKM,MAC3C,GAAID,EAA0BE,IAAIJ,GAGhC,OAAOE,EAA0BvF,IAAIqF,GAEvCH,EAAKM,MAAMD,0BAA0BG,IAAIL,OAAKZ,GAC9C,MAAMnB,EAAS0B,EAA0BK,EAAIJ,QAASC,GAEtD,GADAA,EAAKM,MAAMD,0BAA0BG,IAAIL,EAAK/B,GAC1CA,EACF,MAAO,CACLqC,UAAWV,EACXW,WAAYtC,EAAOsC,WAGzB,CACA,GAAiB,eAAbP,EAAIrD,OAA0BmD,IAAqBF,EAAQY,UAC7D,MAAO,CACLF,UAAWV,EACXW,WAAYP,EAGlB,CACA,IAAK,MAAMS,KAAWb,EAAQa,QAAS,CACrC,MAAMxC,EAAS0B,EAA0Bc,EAASZ,GAClD,GAAI5B,EACF,OAAIwC,EAAQV,MACH9B,EAEF,CACLqC,UAAWG,EACXF,WAAYtC,EAAOsC,WAGzB,CACF,CAOO,SAASG,EAAgCC,EAAMd,GACpD,GAAIA,EAAKM,MAAMO,gCAAgCN,IAAIO,GACjD,OAAOd,EAAKM,MAAMO,gCAAgC/F,IAAIgG,GAIxDd,EAAKM,MAAMO,gCAAgCL,IAAIM,OAAMvB,GACrD,IAAInB,EAAS0C,EAAKC,QAAQC,MAAMC,GAAUA,EAAMC,WAChD,IAAK9C,GAAU0C,EAAKtB,YAAa,CAC/B,MAAM2B,EAAYnB,EAAKI,OAAOtF,IAAIgG,EAAKtB,aAClC2B,EAGMN,EAAgCM,EAAWnB,KACpD5B,GAAS,GAFTA,GAAS,CAIb,CAEA,OADA4B,EAAKM,MAAMO,gCAAgCL,IAAIM,EAAM1C,GAC9CA,CACT,CCnFO,MAAMgD,kBAAkBC,MAC7BpC,aAAY,OAAEzD,EAAM,OAAEkD,IACpB4C,QACA3G,OAAOuE,iBAAiBC,KAAM,CAC5B3D,OAAQ,CAAEF,MAAOE,GACjBkD,OAAQ,CAAEpD,MAAOoD,GACjBX,OAAQ,CAAEzC,MAAO,KAAM8D,UAAU,IAErC,ECLK,MAAMmC,qBAAqBvC,KAKhCwC,cAAcC,EAAW3E,GACvB,MAAO,KACL,MAAMxB,EAAQmG,EAAUC,YAAY5E,GACpC,GAAIxB,EACF,OAAO,IAAIiG,aAAa,CACtB/F,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAEpD,UAEd,CAEJ,CAEIA,YACF,OAAO,EAAS6D,KAAKT,OAAOpD,MAAMA,MACpC,CAGAqG,MAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOpD,OACpBsG,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAGK,MAAMC,YAAYT,aAIvBC,aAAaC,GACX,MAAMnG,EAAQmG,EAAUC,YAAY,OACpC,GAAIpG,EACF,OAAO,IAAI0G,IAAI,CAAExG,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAEpD,UAEzD,CAEIwB,WACF,MAAO,KACT,ECpCF,SAAS4B,EAAO+C,EAAWQ,GACzB,OAAOC,EAAKT,EAAW,CACrBU,OAAQZ,aAAaY,OAAOV,EAAWQ,GACvCG,SAAUH,EAAY,SAE1B,CAEA,MAAMI,EAAqB,CAAC,aAAc,UAAW,UAAW,UAU1DC,EAAkB,IAAIC,IAAI,IARD,CAC7B,oBACA,gBACA,cACA,uBACA,eAKyB9F,KAAKkB,GAAS,CAACA,EAAM,SAASA,OAEvD,CAAC,mBAAoB,yBACrB,CAAC,mBAAoB,0BACrB,CAAC,cAAe,6BAOlB,SAAS6E,EAAiBf,GACxB,IAAK,MAAMgB,KAAUJ,EAAoB,CACvC,MAAMK,EAAOhE,EAAO+C,EAAWgB,GAC/B,GAAIC,EAAK3F,OACP,OAAO2F,CAEX,CACAjB,EAAUlG,MACR,sEAEJ,CAEO,MAAMoH,oCAAoC3D,KAI/CwC,aAAaC,GACX,MAAM/C,EAAS,CAAEkE,OAAQnB,EAAUoB,QAAQ,MACrCC,EAAMC,EACV,IAAIJ,4BAA4B,CAAEnH,OAAQiG,EAAUjG,OAAQkD,YAG9D,GADAoE,EAAIZ,KAAO,GACPxD,EAAOkE,OAAQ,CAEjB,GADAlE,EAAOsE,SAAWvB,EAAUoB,QAAQ,KAChCnE,EAAOsE,SACT,OAAOF,EAAI3D,KAEbT,EAAOuE,cAAgBxB,EAAUC,eAAeW,EAClD,CAcA,OAbA3D,EAAOwE,KAAOzB,EAAUoB,QAAQ,KAC5BnE,EAAOwE,MACTJ,EAAIZ,KAAOY,EAAIK,UAEXX,EAAiBf,GAEjB2B,EAAc3B,GAClB/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,yDACTmD,EAAOkE,SAAWlE,EAAOuE,eAClCxB,EAAUlG,MAAM,uDAEXuH,EAAI3D,IACb,CAEIgE,gBACF,OACEhE,KAAKT,OAAOkE,SAAWzD,KAAKT,OAAOsE,WAAa7D,KAAKT,OAAOuE,aAEhE,CAEIK,cACF,OAAInE,KAAKgE,UACAhE,KAAK+C,KAAK,GAAGxD,OAAOpD,MAAMwB,KAAO,QAEtCqC,KAAKT,OAAOsE,SACP,IAEL7D,KAAKT,OAAOuE,cACP9D,KAAKT,OAAOuE,cAAcnG,KAE5B,IACT,CAGA6E,MAAMC,GACJ,MAAM,QAAE0B,GAAYnE,KACpB,OAAOyC,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOkE,QACpBhB,EAAE/C,MAAMM,KAAKT,OAAOsE,UACpBpB,EAAE2B,gBAAgBpE,KAAKT,OAAOuE,cAAe9D,KAAKpB,QAClD6D,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAK+C,KAAKzF,KAAK+G,GACG,oBAAZF,EACH1B,EAAE6B,WAAWD,EAAGrE,KAAKpB,QACrByF,EAAE7B,MAAMC,KAEdA,EAAE/C,MAAMM,KAAKT,OAAO2E,QAExB,EAGK,MAAMK,gCAAgC1E,KAI3CwC,aAAaC,GACX,MAAM9D,EAAO8D,EAAUC,YAAY,cACnC,GAAI/D,EACF,OAAO,IAAI+F,wBAAwB,CACjClI,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAEf,QACVgG,OAAQhB,4BAA4BiB,MAAMnC,IAGhD,CAEAxC,aAAY,OAAEzD,EAAM,OAAEkD,EAAM,OAAEiF,IAC5BrC,MAAM,CAAE9F,SAAQkD,WAChBiF,EAAO5F,OAASoB,KAChBxE,OAAOC,eAAeuE,KAAM,SAAU,CAAE7D,MAAOqI,GACjD,CAEI7G,WACF,MAAO,oBACT,CACIa,WACF,OAAOwB,KAAKT,OAAOf,KAAKrC,KAC1B,CACIuI,UACF,MAAQP,QAASxG,EAAI,OAAE4B,EAAM,KAAEwD,GAAS/C,KAAKwE,OAC7C,IAAK7G,EACH,OAAO,KAOT,MAAO,CAAEA,OAAMxB,MALD6D,KAAKwE,OAAOR,UACtBjB,EACA/C,KAAKwE,OAAOjF,OAAOuE,cACnB,EAASvE,EAAOuE,cAAc3H,OAC9B,KAEN,CACIwI,gBACF,MAAM,UAAEX,EAAS,KAAEjB,GAAS/C,KAAKwE,OACjC,OAAKzB,GAAQiB,EACJ,GAEFjB,CACT,CAEA,UAAUlC,GACR,MAAM,KAAErC,GAASwB,KACjB,GAAa,4BAATxB,EAAoC,CACtC,MAAMhC,EAAU,sOAIViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,uBACAxD,EACA,CAAEE,MAAO,WAEb,MAAO,GAAIyG,EAAgB/B,IAAI5C,GAAO,CACpC,MAAMhC,EAAU,MAAMgC,yEACA2E,EAAgBxH,IAAI6C,oHAGpCiB,EAAgBO,KAAKT,OAAOf,KAAMwB,KAAM,iBAAkBxD,EAAS,CACvEE,MAAO,UACPC,SA0B+BiI,EA1BQ5E,KA2BtC,KACL,MAAM,KAAExB,GAASoG,EACjBA,EAAQrF,OAAOf,KAAKrC,MAAQgH,EAAgBxH,IAAI6C,GACnC,gBAATA,IACFoG,EAAQJ,OAAOjF,OAAS,CAAC,EAC3B,IA9BA,CAwBJ,IAAuCqF,EAvBnC,IAAK,MAAMC,KAAO7E,KAAK2E,gBACdE,EAAIC,SAASjE,EAExB,CAGA2B,MAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACfF,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOf,KAAKhB,QAC7BiF,EAAEC,GAAGqC,kBACHtC,EAAEC,GAAGC,KAAK,CACRF,EAAEC,GAAGsC,2BAA2BhF,KAAKxB,MACrCwB,KAAKwE,OAAOhC,MAAMC,MAGtBA,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAkBK,MAAMqC,2BAA2BhD,UAItCI,aAAaC,GACX,MAAM/C,EAAS,CAAC,EAChBA,EAAOwE,KAAOzB,EAAUoB,QAAQ,KAChC,MAAMC,EAAM,IAAIsB,mBAAmB,CAAE5I,OAAQiG,EAAUjG,OAAQkD,WAC/D,OAAKA,EAAOwE,MACZJ,EAAIuB,QACCnC,EAAKT,EAAW,CACjBU,OAAQuB,wBAAwBE,MAChCxB,SAAU,wBAGd1D,EAAO2E,MACL5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MACR,4DAECuH,EAAI/F,SACP0E,EAAU6C,UAAU5F,EAAO2E,MAAMtE,OACjC0C,EAAUlG,MAAM,iDAEdkG,EAAU8C,MAAM,MAClB9C,EAAUlG,MACR,kEAGGuH,GArBkBA,CAsB3B,CAEA,UAAU9C,GACR,IAAK,MAAM+D,KAAW5E,WACb4E,EAAQE,SAASjE,EAE5B,CAGA2B,MAAMC,GACJ,OAAKzC,KAAKpC,OACH6E,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAK1C,KAAK+H,GAAOA,EAAG7C,MAAMC,KAC7BA,EAAE/C,MAAMM,KAAKT,OAAO2E,SAJG,EAM3B,EC9LF,SAASoB,EAAYhD,EAAW1G,GAC9B,MAAM4F,EAAWc,EAAUoB,QAAQ,KAC/BlC,IACF5F,EAAI2D,OAAOiC,SAAWA,GAEpBc,EAAU8C,MAAM,MAAM9C,EAAUlG,MAAM,gCAC5C,CAMA,SAASmJ,EAAYjD,EAAWkD,GAC9B,IAAI7B,EAhFN,SAAsBrB,EAAWkD,GAC/B,MAAMzG,EAAOuD,EAAUoB,QACrB,cACA,kBACA,UACA,WACA,UAEF,IAAK3E,EACH,OAEF,MAAM4E,EAAMC,EACV,IAAI6B,KAAK,CAAEpJ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAER,WAKjD,OAHA4E,EAAIpE,OAAOwE,KACTzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,4BAA4B2C,EAAK5C,SAC3C4C,EAAK5C,OACX,IAAK,UAAW,CACVmG,EAAU8C,MAAM,MAClB9C,EAAUlG,MAAM,+CAClB,MAAMqF,EACJiE,EAAYpD,EAAWkD,IACvBlD,EAAUlG,MAAM,2BAClBuH,EAAIlC,QAAQyD,KAAKzD,GACjB,KACF,CACA,IAAK,WACL,IAAK,cACL,IAAK,kBAAmB,CACtB,MAAMA,EACJkE,EAA8BrD,EAAWkD,IACzClD,EAAUlG,MAAM,WAAW2C,EAAK5C,iBAClCwH,EAAIlC,QAAQyD,KAAKzD,GACjB,KACF,CACA,IAAK,SAAU,CACTa,EAAU8C,MAAM,MAClB9C,EAAUlG,MAAM,6CAClB,MAAMwJ,EACJtD,EAAUoB,WAAWmC,IACrBvD,EAAUlG,MAAM,8BAA8ByJ,EAAYpI,KAAK,SAC3DqI,EAAa,IAAIL,KAAK,CAC1BpJ,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAER,KAAM6G,KAElBE,EAAWvG,OAAOqD,UAChBN,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,uCAClB0J,EAAWnI,KAAO6H,EAClB,MAAMO,EACJJ,EAA8BrD,EAAWkD,IACzClD,EAAUlG,MAAM,qCAClBuH,EAAIlC,QAAQyD,KAAKY,EAAYC,GAC7B,KACF,EAMF,OAJKpC,EAAI/C,SAAS0B,EAAUlG,MAAM,8BAA8B2C,EAAK5C,SACrEwH,EAAIpE,OAAO2E,MACT5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,iCAAiC2C,EAAK5C,SACjDwH,EAAI3D,IACb,CAkBYgG,CAAa1D,EAAWkD,IAAaS,EAAe3D,GAC9D,IAAKqB,EAAK,CACR,MAAM5E,EACJuD,EAAUC,YAAY,eACtBD,EAAUoB,WAAWmC,KAAgBK,GACvC,IAAKnH,EACH,OAEF4E,EAAM,IAAI8B,KAAK,CAAEpJ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAER,UACjDuD,EAAU8C,MAAM,MAClB9C,EAAUlG,MAAM,4BAA4B2C,EAAK5C,QACrD,CAQA,MAPoB,YAAhBwH,EAAIwC,SAAyB7D,EAAU8C,MAAM,MAC/C9C,EAAUlG,MAAM,mCAElBuH,EAAIhG,KAAO6H,GAAY,KACvBF,EAAYhD,EAAWqB,GACnBA,EAAInC,UAA4B,QAAhBmC,EAAI/C,SACtB0B,EAAUlG,MAAM,sCACXuH,CACT,CAqCO,MAAM8B,aAAa5F,KAKxBwC,aAAaC,EAAWkD,GACtB,OAAOD,EAAYjD,EAAWkD,IArClC,SAAoBlD,EAAW3E,GAC7B,MAAM4B,EAAS,CAAC,EAEhB,GADAA,EAAOwE,KAAOzB,EAAUoB,QAAQ,MAC3BnE,EAAOwE,KAAM,OAClB,MAAMJ,EAAMC,EAAa,IAAI6B,KAAK,CAAEpJ,OAAQiG,EAAUjG,OAAQkD,YAE9D,IADAoE,EAAIhG,KAAOA,GAAQ,OACN,CACX,MAAMyI,EACJT,EAA8BrD,EAAW3E,IACzC2E,EAAUlG,MAAM,wDACE,QAAhBgK,EAAIxF,SACN0B,EAAUlG,MAAM,iDACE,YAAhBgK,EAAID,SACN7D,EAAUlG,MAAM,qDAClBuH,EAAIlC,QAAQyD,KAAKkB,GACjB,MAAMC,EAAK/D,EAAUoB,QAAQ,MAC7B,IAAI2C,EAEG,MADLD,EAAI7G,OAAOqD,UAAYyD,CAE3B,CASA,OARI1C,EAAI/C,QAAQhD,OAAS,GACvB0E,EAAUlG,MACR,kEAGJmD,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,2BAC5CkJ,EAAYhD,EAAWqB,GAChBA,EAAI3D,IACb,CAQ+CsG,CAAWhE,EAAWkD,EACnE,CAEA1F,aAAY,OAAEzD,EAAM,OAAEkD,IACpB4C,MAAM,CAAE9F,SAAQkD,WAChB/D,OAAOC,eAAeuE,KAAM,UAAW,CAAE7D,MAAO,GAAI8D,UAAU,IAC9DD,KAAKuG,SAAW,IAAItB,mBAAmB,CAAE5I,SAAQkD,OAAQ,CAAC,GAC5D,CAEI4G,cACF,OAAInG,KAAKyB,QAAQ7D,QAAUoC,KAAKT,OAAOR,KAC9BiB,KAAKT,OAAOR,KAAK5C,MAEnB,EACT,CACIqF,eACF,OAAOgF,QAAQxG,KAAKT,OAAOiC,SAC7B,CACIT,YACF,OAAOyF,QAAQxG,KAAKyB,QAAQ7D,UAAYoC,KAAKT,OAAOR,IACtD,CACI6B,cACF,GAAIZ,KAAKyB,QAAQ7D,OACf,OAAOoC,KAAKyB,QAOd,OAAO,EAJM,CAACzB,KAAKT,OAAOkH,OAAQzG,KAAKT,OAAOR,KAAMiB,KAAKT,OAAOmH,SAC7DC,QAAQpJ,GAAMA,IACdD,KAAKC,GAAMA,EAAEpB,QACbsB,KAAK,KAEV,CAEA,UAAUoD,GAGR,SAFOb,KAAKuG,SAASzB,SAASjE,GAET,iBAAjBb,KAAKY,QAGP,IAAK,MAAM2F,IAAY,CAACvG,KAAKuG,SAAUvG,KAAKpB,QAAQ2H,UAClD,IAAK,MAAM3B,KAAW2B,EAAU,CAC9B,GAAqB,gBAAjB3B,EAAQpG,KACV,SAEF,MAAMhC,EAAU,mFACViD,EACJO,KAAKT,OAAOR,KACZiB,KACA,sBACAxD,EACA,CAAEG,QAASiK,EAAmB5G,KAAM4E,EAAS2B,IAEjD,CAIJ,GAAqB,SAAjBvG,KAAKY,QAAoB,CAC3B,MAAMpE,EAAU,sJAGViD,EAAgBO,KAAKT,OAAOR,KAAMiB,KAAM,eAAgBxD,EAAS,CACrEG,SA8FagB,EA9FQqC,KA+FpB,KACLrC,EAAK4B,OAAOR,KAAK5C,MAAQ,WAAW,IA9FpC,CA4FJ,IAAqBwB,EAtFjB,MAAMkJ,GAAW7G,KAAKe,OAASF,EAAKI,OAAOtF,IAAIqE,KAAKY,SAC9C5B,EAASgB,KAAKe,MAChBf,KACA6G,GAA4B,YAAjBA,EAAQlJ,KACnBkJ,EAAQjG,aACRR,EACJ,GAAIpB,GAAUgB,KAAKwB,SAAU,CAE3B,MAAM,UAAEF,GAAcX,EAA0B3B,EAAQ6B,IAAS,CAAC,EAClE,GAAIS,EAAW,CACb,MAAMwF,GAAe9G,KAAKe,MAAQO,EAAYtB,MAAMT,OAAOR,KACrDvC,EAAU,yDACViD,EACJqH,EACA9G,KACA,yBACAxD,EAEJ,CACF,MAEE,IAAK,MAAMiF,KAAWzB,KAAKyB,cAClBA,EAAQqD,SAASjE,EAG9B,CAGA2B,MAAMC,GA6BJ,OAAOA,EAAEC,GAAGC,KAAK,CACf3C,KAAKuG,SAAS/D,MAAMC,GA7BJ,MAChB,GAAIzC,KAAKe,OAASf,KAAKmG,QACrB,OAAO1D,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOR,KAAM0D,EAAEC,GAAGyD,SAC/B1D,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAKyB,QAAQnE,KAAKC,GAAMA,EAAEiF,MAAMC,KACnCA,EAAE/C,MAAMM,KAAKT,OAAO2E,SAGxB,MAAM6C,EAAa/G,KAAKT,OAAOkH,QAAUzG,KAAKT,OAAOR,KAC/C0H,EAASzG,KAAKT,OAAOkH,OACvB,CAACzG,KAAKT,OAAOkH,OAAOtK,MAAOsG,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOR,KAAKvB,SACxD,GACEwJ,EAAMvE,EAAEnB,UACZmB,EAAEC,GAAGC,KAAK,IACL8D,EACHzG,KAAKT,OAAOR,KAAK5C,MACjBsG,EAAE/C,MAAMM,KAAKT,OAAOmH,WAEtB,CACEO,UACEjH,KACF,QACAzB,QAASyB,OAGb,OAAOyC,EAAEC,GAAGC,KAAK,CAACF,EAAEC,GAAGlF,OAAOuJ,EAAWvJ,QAASwJ,GAAK,EAIvDE,GACAzE,EAAE/C,MAAMM,KAAKT,OAAOiC,UACpBiB,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAQF,SAASgE,EAAmBjJ,EAAMiH,EAAS2B,GACzC,MAAO,KACL,MAAM3G,EAAQ2G,EAASY,QAAQvC,GAC/B2B,EAASa,OAAOxH,EAAO,IAClB2G,EAAS3I,QAAUD,EAAK4B,OAAOR,KAAKvB,OAAO6J,MAAM,UACpD1J,EAAK4B,OAAOR,KAAKvB,OAAS,IAG5BG,EAAK4B,OAAOR,KAAK5C,MAAQ,yBAAyB,CAEtD,CCnTO,MAAMmL,gBAAgBzH,KAI3BwC,aAAaC,GACX,MAAMmB,EAASnB,EAAUoB,QAAQ,KACjC,IAAKD,EACH,OAAO,KAET,MAAMzC,EACJuG,EAAYjF,IACZA,EAAUC,YAAY,WACtBD,EAAUoB,QAAQ,OAAQ,IAAK,MAC/BpB,EAAUlG,MAAM,wBACZoL,EAAa,CAACxG,GACpB,GAAkB,MAAdA,EAAI7E,MAAe,CACrB,MAAM+H,EACJ5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,wCAClBoL,EAAWtC,KAAKhB,EAClB,MAAO,GAAkB,MAAdlD,EAAI7E,MAAe,CAC5B,MAAM+H,EACJ5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,0CAClBoL,EAAWtC,KAAKhB,EAClB,CACA,OAAO,IAAIoD,QAAQ,CACjBjL,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAEkE,UACV+D,cAEJ,CAEA1H,aAAY,OAAEzD,EAAM,OAAEkD,EAAM,WAAEiI,IAC5BrF,MAAM,CAAE9F,SAAQkD,WAChBiI,EAAW5I,OAASoB,KACpBxE,OAAOC,eAAeuE,KAAM,aAAc,CAAE7D,MAAOqL,GACrD,CAEI7J,WACF,OAAO8J,EAAWzH,KAAKwH,WAAW,IAAI7J,IACxC,CACIxB,YACF,OAAOsL,EAAWzH,KAAKwH,WAAW,IAAIrL,KACxC,CACIuL,eACF,OAAOD,EAAWzH,KAAKwH,WAAW,IAAIE,QACxC,CAGAlF,MAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOkE,WACjBzD,KAAKwH,WAAWlK,KAAKC,GAAMkF,EAAE/C,MAAMnC,MAE1C,EC1CK,MAAMoK,iBAAiB9H,KAI5BwC,aAAaC,GACX,MAAMsF,EAAiBtF,EAAUhG,SAE3BiD,EAAS,CAAC,EACVoE,EAAMC,EACV,IAAI+D,SAAS,CAAEtL,OAAQiG,EAAUjG,OAAQkD,YAK3C,OAHAoE,EAAI4C,SAAWtB,mBAAmBR,MAAMnC,GACxC/C,EAAOsI,SAAWvF,EAAUoB,QAAQ,YACpCC,EAAI/C,QAAU+E,EAA8BrD,EAAW,iBAClDqB,EAAI/C,SAGJrB,EAAOsI,WACVtI,EAAOuI,SAAWxF,EAAUoB,QAAQ,QAEtCnE,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUoB,WAAWqE,GAClBxI,EAAOf,MAGZmF,EAAIqE,QAAUzI,EAAOsI,SAAWP,QAAQ7C,MAAMnC,GAAa,KACpDqB,EAAI3D,MAHFsC,EAAU6C,UAAUyC,IATpBtF,EAAU6C,UAAUyC,EAa/B,CAEIjK,WACF,MAAO,UACT,CACIkK,eACF,QAAS7H,KAAKT,OAAOsI,QACvB,CACIC,eACF,QAAS9H,KAAKT,OAAOuI,QACvB,CACItJ,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAKA,UAAU0E,SACDb,KAAKuG,SAASzB,SAASjE,SACvBb,KAAKY,QAAQkE,SAASjE,GAC7B,MAAM5B,EAAS0B,EAA0BX,KAAKY,QAASC,EAAM,CAC3DC,kBAAkB,IAEpB,GAAI7B,EACF,GAAIe,KAAKY,QAAQY,SAAU,CACzB,MAAMhF,EAAU,iDACViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,uBACAxD,EAEJ,MAAO,GAAKwD,KAAK6H,UAiBV,IAAK7H,KAAKgI,QAAS,CACxB,MAAMxL,EAAU,yEACViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,mBACAxD,EACA,CACEG,QAASsL,EAAsCjI,OAGrD,OA3BE,GACEA,KAAKpB,SACJ8C,EAAgCzC,EAAOsC,WAAYV,IA8C9D,SAAgCgE,GAC9B,MAAM9B,EAAO8B,EAAIjG,OAAO+F,WAAaE,EAAIjG,OAAOmE,KAC1CnD,EAAQmD,EAAKoE,QAAQtC,GACrBqD,EAAiBnF,EAAKhG,MAAM6C,EAAQ,GAAGiC,MAAMsG,IAAOA,EAAEN,WAC5D,OAAQK,CACV,CAlDUE,CAAuBpI,MACvB,CACA,MAAMxD,EAAU,0EACViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,oBACAxD,EACA,CACEG,SA8CgCkI,EA9Cc7E,KA+CnD,KACL,MAAM+G,EAAasB,EAAcxD,EAAIjE,SACrCiE,EAAItF,OAAOsI,SAAW,IACjBd,EACHpJ,KAAM,WACNxB,MAAO,YAET4K,EAAWvJ,OAAS,IACpByK,EAAsCpD,EAAtCoD,EAA4C,IApDxC,CA2CR,IAA8CpD,CA7B5C,CAGArC,MAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACf3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOsI,UACpBpF,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE/C,MAAMM,KAAKT,OAAOuI,UACpBrF,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,OACvCA,KAAKgI,QAAUhI,KAAKgI,QAAQxF,MAAMC,GAAK,GACvCA,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAgCF,SAASqF,EAAsCpD,GAC7C,MAAO,KACLA,EAAImD,QAAUV,QAAQ7C,MAAM,IAAI+D,UAAU,SAAS,CAEvD,CCnJO,MAAMC,kBAAkB5I,KAO7BwC,aAAaC,GAAW,QAAEoG,EAAO,QAAEC,GAAY,CAAC,GAC9C,MAAMpJ,EAAS,CAAEmJ,WACX/E,EAAMC,EACV,IAAI6E,UAAU,CAAEpM,OAAQiG,EAAUjG,OAAQkD,YAE5C,OAAImJ,GAA6B,gBAAlBA,EAAQvM,QACrBoD,EAAOqJ,YAActG,EAAUoB,QAAQ,KACnCnE,EAAOqJ,cACTjF,EAAIgB,UAAY,GACThB,IAGN+E,GAAYC,IACfpJ,EAAOmJ,QAAUpG,EAAUoB,QAAQ,SAAU,SAAU,YAEzDC,EAAI/C,QACF8E,EAAYpD,IAAcA,EAAUlG,MAAM,uBAC5CmD,EAAOf,KACL8D,EAAUC,YAAY,eAAiBD,EAAUoB,QAAQ,YAC3DnE,EAAOwE,KACLzB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,qBAC5CuH,EAAIgB,UAAYV,EAAc3B,GAC9B/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,0BAC5CmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,wCACXuH,EAAI3D,KACb,CAEIrC,WACF,MAAO,WACT,CACIa,WACF,MAAM,KAAEA,GAASwB,KAAKT,OACtB,OAAKf,EAGE,EAASA,EAAKrC,OAFZ,EAGX,CACIuM,cACF,OAAK1I,KAAKT,OAAOmJ,QAGV1I,KAAKT,OAAOmJ,QAAQvM,MAFlB,EAGX,CAEA,UAAU0E,GAER,SADOb,KAAKuG,SAASzB,SAASjE,IACzBb,KAAKxB,MAAQ,CAAC,GAAI,UAAUqK,SAAS7I,KAAK0I,SAAU,CACvD,MAAMlM,EAAU,qFACViD,EAAgBO,KAAKT,OAAOwE,KAAM/D,KAAM,gBAAiBxD,EACjE,CACIwD,KAAKY,gBACAZ,KAAKY,QAAQkE,SAASjE,IAE/B,IAAK,MAAMiI,KAAY9I,KAAK2E,gBACnBmE,EAAShE,SAASjE,EAE7B,CAGA2B,MAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACb+I,EAAO/I,KAAKY,QACd,CACE6B,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,KAAMpB,WAC7C6D,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAK2E,UAAUrH,KAAKuH,GAAQA,EAAIrC,MAAMC,MAChDA,EAAE/C,MAAMM,KAAKT,OAAO2E,QAEtB,GACJ,OAAOzB,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBzC,KAAKT,OAAOf,KACRiE,EAAE/C,MAAMM,KAAKT,OAAOmJ,SACpBjG,EAAE/C,MAAMM,KAAKT,OAAOmJ,QAASjG,EAAEC,GAAGsG,SAAU,CAAET,KAAMvI,KAAMpB,cAC3DmK,EACHtG,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,KAAMpB,UAElB,ECxFK,MAAMqK,kBAAkBpJ,KAQ7BwC,aACEC,GACA,QAAEoG,EAAO,UAAEQ,GAAY,EAAK,SAAEC,GAAW,GAAU,CAAC,GAEpD,MAAMvB,EAAiBtF,EAAUhG,SAC3BiD,EAAS,CAAEmJ,WACX/E,EAAMC,EACV,IAAIqF,UAAU,CAAE5M,OAAQiG,EAAUjG,OAAQkD,YAa5C,GAXKmJ,GAAYQ,IACf3J,EAAOmJ,QAAUpG,EAAUoB,QAAQ,YAEjB,YAAhBC,EAAI+E,SAAyBpG,EAAU8C,MAAM,aAC/C9C,EAAUlG,MAAM,4CAElBmD,EAAO4J,SAAW7G,EAAUoB,QAAQ,YAChCyF,IAAa5J,EAAO4J,UAAY7G,EAAU8C,MAAM,cAClD9C,EAAUlG,MAAM,+CAElBmD,EAAOR,KAAOuD,EAAUoB,QAAQ,aAC3BnE,EAAOR,KAcZ,OAVA4E,EAAI/C,QACF+E,EAA8BrD,EAAW,mBACzCA,EAAUlG,MAAM,0BAClBmD,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUoB,QAAQ,QAAS,aAC3BpB,EAAUlG,MAAM,0BAClBmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,wCACXuH,EAAI3D,KAbTsC,EAAU6C,UAAUyC,EAcxB,CAEIjK,WACF,MAAO,WACT,CACI+K,cACF,OAAK1I,KAAKT,OAAOmJ,QAGV1I,KAAKT,OAAOmJ,QAAQvM,MAFlB,EAGX,CACIgN,eACF,QAASnJ,KAAKT,OAAO4J,QACvB,CACI3K,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAEA,UAAU0E,GAIR,SAHOb,KAAKuG,SAASzB,SAASjE,SACvBb,KAAKY,QAAQkE,SAASjE,GAEzB,CAAC,WAAY,UAAUgI,SAAS7I,KAAKY,QAAQuF,SAAU,CACzD,MAAM3J,EAAU,4BAA4BwD,KAAKY,QAAQuF,uBACnD1G,EACJO,KAAKT,OAAOf,KACZwB,KACA,oBACAxD,EAEJ,CAEA,CACE,MAAM,UAAE8E,GAAcX,EAA0BX,KAAKY,QAASC,IAAS,CAAC,EACxE,GAAIS,EAAW,CACb,MAAMwF,GAAe9G,KAAKY,QAAQG,MAAQO,EAAYtB,KAAKY,SACxDrB,OAAOR,KACJvC,EAAU,mDACViD,EAAgBqH,EAAa9G,KAAM,oBAAqBxD,EAChE,CACF,CAEA,GAAIwD,KAAKmJ,URFN,SAAqCvI,EAASC,GACnD,GAAID,EAAQG,MAEV,OAAO,EAGT,GAAIH,EAAQ2F,SAAS1E,MAAMuH,GAAiB,iBAAXA,EAAE5K,OACjC,OAAO,EAGT,MAAMwC,EAAMH,EAAKI,OAAOtF,IAAIiF,EAAQA,SACpC,MAAkB,YAAdI,GAAKrD,MAIFqD,EAAIJ,QAAQ2F,SAAS1E,MAAMuH,GAAiB,iBAAXA,EAAE5K,MAC5C,CQbU6K,CAA4BrJ,KAAKY,QAASC,GAAO,CACnD,MAAMiG,EAAc9G,KAAKY,QAAQrB,OAAOR,KAClCvC,EACJ,6EACIiD,EAAgBqH,EAAa9G,KAAM,oBAAqBxD,EAChE,CAEJ,CAGAgG,MAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOmJ,SACpBjG,EAAE/C,MAAMM,KAAKT,OAAO4J,UACpB1G,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,KAAMpB,WAC7C6D,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,KAAMpB,UAElB,EC7GK,SAAS,EAAS0F,GACvB,OAAOA,EAAWgF,WAAW,KAAOhF,EAAWvH,MAAM,GAAKuH,CAC5D,CAUO,SAASvB,EAAKT,GAAW,OAAEU,EAAM,aAAEuG,EAAY,SAAEtG,EAAW,SACjE,MAAMuG,EAAQxG,EAAOV,GACrB,IAAKkH,EACH,MAAO,GAETA,EAAMjK,OAAOqD,UAAYN,EAAUoB,QAAQ,KAC3C,MAAM+F,EAAQ,CAACD,GACf,KAAOA,EAAMjK,OAAOqD,WAAW,CAC7B,MAAM8G,EAAO1G,EAAOV,GACpB,IAAKoH,EAAM,CACJH,GACHjH,EAAUlG,MAAM,qBAAqB6G,KAEvC,KACF,CAGA,GAFAyG,EAAKnK,OAAOqD,UAAYN,EAAUoB,QAAQ,KAC1C+F,EAAMvE,KAAKwE,IACNA,EAAKnK,OAAOqD,UAAW,KAC9B,CACA,OAAO6G,CACT,CAKO,SAASlC,EAAYjF,GAC1B,OACEA,EAAUC,YAAY,UAAW,YACjCD,EAAUoB,QAAQ,OAAQ,QAAS,WAAY,YAAa,MAEhE,CAOO,SAAS+D,GAAW,KAAE9J,EAAI,MAAExB,IACjC,OAAQwB,GACN,IAAK,UACL,IAAK,UACH,MAAO,CAAEA,KAAM,SAAUxB,SAC3B,IAAK,SACH,MAAO,CAAEwB,KAAM,SAAUxB,MAAOA,EAAMY,MAAM,GAAI,IAGpD,OAAQZ,GACN,IAAK,OACL,IAAK,QACH,MAAO,CAAEwB,KAAM,UAAWxB,MAAiB,SAAVA,GACnC,IAAK,WACL,IAAK,YACH,MAAO,CAAEwB,KAAM,WAAY+J,SAAUvL,EAAMmN,WAAW,MACxD,IAAK,IACH,MAAO,CAAE3L,KAAM,WAAYxB,MAAO,IACpC,IAAK,IACH,MAAO,CAAEwB,KAAM,cACjB,QACE,MAAO,CAAEA,KAAMxB,GAErB,CAKO,SAAS8J,EAAe3D,GAoB7B,MAAM,OAAEjG,GAAWiG,EACbqH,EApBN,WACE,MAAMlD,EAASnE,EAAUoB,QAAQ,YAC3B3E,EAAOuD,EAAUoB,QAAQ,QAAS,QACxC,GAAI3E,EAAM,CACR,MAAM2H,EAAUpE,EAAUoB,QAAQ,QAClC,OAAO,IAAI+B,KAAK,CAAEpJ,SAAQkD,OAAQ,CAAEkH,SAAQ1H,OAAM2H,YACpD,CACID,GAAQnE,EAAUlG,MAAM,+BAC9B,CAYiBwN,IAVjB,WACE,MAAMnD,EAASnE,EAAUoB,QAAQ,gBAC3B3E,EAAOuD,EAAUoB,QAAQ,QAAS,UACxC,GAAI3E,EACF,OAAO,IAAI0G,KAAK,CAAEpJ,SAAQkD,OAAQ,CAAEkH,SAAQ1H,UAE1C0H,GAAQnE,EAAUlG,MAAM,6BAC9B,CAGmCyN,GACnC,GAAIF,EAAU,OAAOA,EACrB,MAAM5K,EAAOuD,EAAUoB,QACrB,SACA,UACA,OACA,QACA,aAEF,OAAI3E,EACK,IAAI0G,KAAK,CAAEpJ,SAAQkD,OAAQ,CAAER,eADtC,CAGF,CAKO,SAASkF,EAAc3B,GAC5B,OAAOS,EAAKT,EAAW,CACrBU,OAAQ2E,SAASlD,MACjBxB,SAAU,kBAEd,CAMO,SAAS0C,EAA8BrD,EAAWkD,GACvD,MAAMe,EAAWtB,mBAAmBR,MAAMnC,GACpCqB,EAAM8B,KAAKhB,MAAMnC,EAAWkD,GAElC,OADI7B,IAAKC,EAAaD,GAAK4C,SAAWA,GAC/B5C,CACT,CAMO,SAAS+B,EAAYpD,EAAWkD,GACrC,MAAMY,EAAMX,KAAKhB,MAAMnC,EAAWkD,GAAY,eAC9C,GAAIY,EACF,OAAOA,EAET,MAAM0D,EAAYxH,EAAUoB,QAAQ,QACpC,GAAIoG,EAAW,CACb,MAAMnG,EAAM,IAAI8B,KAAK,CACnBpJ,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAER,KAAM+K,KAGlB,OADAnG,EAAIhG,KAAO,cACJgG,CACT,CACF,CAKO,SAASoG,EAAYzH,GAC1B,MAAMoG,EAAUpG,EAAUoB,QAAQ,eAClC,IAAKgF,EAAS,OAKd,OAHEO,UAAUxE,MAAMnC,EAAW,CAAEoG,aAC7BD,UAAUhE,MAAMnC,EAAW,CAAEoG,aAC7BpG,EAAUlG,MAAM,2BAEpB,CAKO,SAAS4N,EAAmBC,GACjC,MAAMC,EAAQD,EAAIjM,MAAM,MAExB,GAAIkM,EAAMtM,OAAQ,CAChB,MAAMyJ,EAAQ6C,EAAMA,EAAMtM,OAAS,GAAGyJ,MAAM,QAC5C,GAAIA,EACF,OAAOA,EAAM,EAEjB,CACA,MAAO,EACT,CAcO,SAAS8C,EAAwBnJ,GACtC,MAAO,KACL,GAAIA,EAAIuF,SAAS3I,OAAQ,CACvB,MAAM0E,EAAY,IAAIkG,UAAU,mBAC1B4B,EAAU7F,wBAAwBE,MAAMnC,GAC9C8H,EAAQ7K,OAAOqD,UAAYN,EAAUoB,QAAQ,KAC7C,MAAM2G,EAAWrJ,EAAIuF,SAAS,GACzB,MAAM+D,KAAKD,EAAS9K,OAAOf,KAAKhB,UACnC6M,EAAS9K,OAAOf,KAAKhB,OAAS,IAAI6M,EAAS9K,OAAOf,KAAKhB,UAEzDwD,EAAIuF,SAAS1H,QAAQuL,EACvB,KAAO,CACLxG,EAAa5C,GAAKuF,SAAWtB,mBAAmBR,MAC9C,IAAI+D,UAAU,qBAEhB,MAAMhL,EAASwD,EAAIzB,OAAOR,KAAKvB,OAC/BwD,EAAIuF,SAAShH,OAAOwE,KAAKvG,OAASA,EAClCwD,EAAIzB,OAAOR,KAAKvB,OAAS,KAAKwM,EAAmBxM,IACnD,EAEJ,CAMO,SAAS6K,EAAcE,GAC5B,GAAIA,EAAKhC,SAAS3I,OAChB,OAAO2K,EAAKhC,SAAShH,OAAOwE,KAE9B,GAAkB,cAAdwE,EAAK5K,OAAyB4K,EAAKG,QACrC,OAAOL,EAAcE,EAAK3H,SAG5B,OADepF,OAAO+O,OAAOhC,EAAKhJ,QAAQiL,MAAK,CAACC,EAAGC,IAAMD,EAAE7K,MAAQ8K,EAAE9K,QACvD,EAChB,CAuBO,SAASgE,EAAa2E,EAAM3J,GAKjC,GAJKA,IAEHA,EAAS2J,IAENA,EAGH,OAAOA,EA8BT,OA5Bc,IAAIoC,MAAMpC,EAAM,CAC5B5M,IAAIqD,EAAQqF,GACV,MAAMlI,EAAQ6C,EAAOqF,GACrB,OAAInC,MAAM0I,QAAQzO,IAAgB,WAANkI,EAGnBT,EAAazH,EAAO6C,GAEtB7C,CACT,EACAkF,IAAIrC,EAAQqF,EAAGlI,GAGb,GADA6C,EAAOqF,GAAKlI,GACPA,EACH,OAAO,EACF,GAAI+F,MAAM0I,QAAQzO,GAEvB,IAAK,MAAMuN,KAAQvN,OACU,IAAhBuN,EAAK9K,SACd8K,EAAK9K,OAASA,aAGe,IAAjBzC,EAAMyC,SACtBzC,EAAMyC,OAASA,GAEjB,OAAO,CACT,GAGJ,CC1SA,MAAMiM,EAAU,CAGdC,QACE,sGACFC,QAAS,8CACTzG,WAAY,+BACZ0G,OAAQ,WACRC,WAAY,cACZC,QAAS,2BACTC,MAAO,wBAGIjF,EAAmB,CAC9B,cACA,oBACA,WACA,YACA,aACA,aACA,aACA,cACA,cACA,oBACA,gBACA,iBACA,eACA,eACA,MACA,SACA,UAGWL,EAAc,CAAC,aAAc,YAAa,aAE1CkC,EAAuB,CAClC,QACA,YACA,WACA,QACA,cACA,UACA,aACA,OACA,SACA,WACA,UACA,YACA,WACA,UACA,YACA,UACA,WACA,UACA,SACA,SACA,cACA,UACA,gBAGIqD,EAAoB,CACxB,YACA,cACA,WACA,MACA,kBACA,UACA,SACA,UACA,OACA,SACA,QACA,QACA,OACA,QACA,OACA,QACA,WACA,KACA,WACA,SACA,WACA,QACA,OACA,YACA,WACA,QACAC,OAAOtD,EAAsBlC,EAAaK,GAEtCoF,EAAe,CACnB,IACA,IACA,IACA,MACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAGIC,EAAW,CAEf,eACA,WACA,aAgHK,MAAM/C,UAIX1I,YAAY0L,GACVxL,KAAK3D,OA9GT,SAAkB4N,GAChB,MAAM1K,EAAS,GACf,IAAIkM,EAAgB,EAChBjO,EAAS,GACTK,EAAO,EACP+B,EAAQ,EACZ,KAAO6L,EAAgBxB,EAAIrM,QAAQ,CACjC,MAAM8N,EAAWzB,EAAI0B,OAAOF,GAC5B,IAAIxM,GAAU,EAQd,GANI,YAAYqL,KAAKoB,GACnBzM,EAAS2M,EAAkB,aAAc,CAAEC,eAAe,IACpC,MAAbH,IACTzM,EAAS2M,EAAkB,UAAW,CAAEC,eAAe,MAGzC,IAAZ5M,EAAe,CACjB,MAAM6M,EAAgBvM,EAAOwM,MAAM5P,MACnC0B,IAASiO,EAAczE,MAAM,QAAU,IAAIzJ,OAC3CJ,GAAUsO,EACVlM,GAAS,CACX,MAAO,GAAI,iBAAiB0K,KAAKoB,IAK/B,GAJAzM,EAAS2M,EAAkB,YACX,IAAZ3M,IACFA,EAAS2M,EAAkB,aAEb,IAAZ3M,EAAe,CACjBA,EAAS2M,EAAkB,cAC3B,MAAMI,EAAYzM,EAAO3B,OAAS,EAC5B8B,EAAQH,EAAOyM,GACrB,IAAgB,IAAZ/M,EAAe,CACjB,GAAIsM,EAAS1C,SAASnJ,EAAMvD,OAAQ,CAClC,MAAMK,EAAU,GAAG,EACjBkD,EAAMvD,wDAER,MAAM,IAAI8P,iBACRzM,EAAYD,EAAQyM,EAAW,KAAMxP,GAEzC,CAAW4O,EAAkBvC,SAASnJ,EAAMvD,SAC1CuD,EAAM/B,KAAO,SAEjB,CACF,MACsB,MAAb+N,IACTzM,EAAS2M,EAAkB,WAG7B,IAAK,MAAMM,KAAeZ,EACxB,GAAIrB,EAAIX,WAAW4C,EAAaT,GAAgB,CAC9ClM,EAAO2F,KAAK,CACVvH,KAAM,SACNxB,MAAO+P,EACP1O,SACAK,OACA+B,UAEFpC,EAAS,GACTiO,GAAiBS,EAAYtO,OAC7BqB,EAASwM,EACT,KACF,CAOF,IAHgB,IAAZxM,IACFA,EAAS2M,EAAkB,WAEb,IAAZ3M,EACF,MAAM,IAAIkN,MAAM,gCAElBV,EAAgBxM,EAChBW,GAAS,CACX,CAWA,OARAL,EAAO2F,KAAK,CACVvH,KAAM,MACNxB,MAAO,GACPqB,SACAK,OACA+B,UAGKL,EAOP,SAASqM,EAAkBjO,GAAM,cAAEkO,GAAkB,CAAC,GACpD,MAAMO,EAAKvB,EAAQlN,GACnByO,EAAGJ,UAAYP,EACf,MAAMxM,EAASmN,EAAGC,KAAKpC,GACvB,OAAIhL,GACFM,EAAO2F,KAAK,CAAEvH,OAAMxB,MAAO8C,EAAO,GAAIzB,SAAQK,OAAM+B,UAC/CiM,IACHrO,EAAS,IAEJ4O,EAAGJ,YAEJ,CACV,CACF,CAOkBM,CAASd,GACvBxL,KAAK1D,SAAW,CAClB,CAMAF,MAAMI,GACJ,MAAM,IAAIyP,iBACRzM,EAAYQ,KAAK3D,OAAQ2D,KAAK1D,SAAU0D,KAAKzD,QAASC,GAE1D,CAKA+P,UAAU5O,GACR,OACEqC,KAAK3D,OAAOuB,OAASoC,KAAK1D,UAC1B0D,KAAK3D,OAAO2D,KAAK1D,UAAUqB,OAASA,CAExC,CAKAyH,MAAMjJ,GACJ,OACE6D,KAAKuM,UAAU,WAAavM,KAAK3D,OAAO2D,KAAK1D,UAAUH,QAAUA,CAErE,CAKAoG,eAAeiK,GACb,IAAK,MAAM7O,KAAQ6O,EAAY,CAC7B,IAAKxM,KAAKuM,UAAU5O,GAAO,SAC3B,MAAM+B,EAAQM,KAAK3D,OAAO2D,KAAK1D,UAE/B,OADA0D,KAAK1D,WACEoD,CACT,CACF,CAKAgE,WAAW8I,GACT,IAAKxM,KAAKuM,UAAU,UAAW,OAC/B,MAAM7M,EAAQM,KAAK3D,OAAO2D,KAAK1D,UAC/B,IAAK,MAAMH,KAASqQ,EAClB,GAAI9M,EAAMvD,QAAUA,EAEpB,OADA6D,KAAK1D,WACEoD,CAEX,CAKA+M,kBAAkBtQ,GAChB,GAAK6D,KAAKuM,UAAU,eAGhBvM,KAAK3D,OAAO2D,KAAK1D,UAAUH,QAAUA,EAGzC,OAAO6D,KAAKuC,YAAY,aAC1B,CAKA4C,UAAU7I,GACR0D,KAAK1D,SAAWA,CAClB,EAGK,MAAM2P,yBAAyBE,MAWpCrM,aAAY,QACVtD,EAAO,YACP4C,EAAW,QACXb,EAAO,KACPV,EAAI,WACJwB,EAAU,MACVC,EAAK,OACLC,IAEA4C,MAAM3F,GAENwD,KAAKxB,KAAO,mBACZwB,KAAKZ,YAAcA,EACnBY,KAAKzB,QAAUA,EACfyB,KAAKnC,KAAOA,EACZmC,KAAKX,WAAaA,EAClBW,KAAKV,MAAQA,EACbU,KAAKT,OAASA,CAChB,EClVK,MAAMmN,kBAAkBtK,aAI7BC,aAAaC,GACX,MAAMnG,EAAQmG,EAAUC,YAAY,UACpC,GAAIpG,EACF,OAAO,IAAIuQ,UAAU,CAAErQ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAEpD,UAE/D,CAEIwB,WACF,MAAO,YACT,CACIxB,YACF,OAAOgG,MAAMhG,MAAMY,MAAM,GAAI,EAC/B,CAGAyF,MAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGC,KAAK,CACfF,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOpD,MAAMqB,QAC9BiF,EAAEC,GAAGrH,WACHoH,EAAEC,GAAGC,KAAK,CAAC,IAAKF,EAAEC,GAAGlE,KAAKwB,KAAK7D,MAAO,CAAEoM,KAAMvI,KAAMpB,WAAW,MAC/D,CAAE2J,KAAMvI,KAAMpB,WAEhB6D,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAGK,MAAM+J,aAAa9M,KAIxBwC,aAAaC,GAEX,MAAM/C,EAAS,CAAC,EAEhB,GADAA,EAAOR,KAAOuD,EAAUoB,QAAQ,SAC3BnE,EAAOR,KACV,OAEFQ,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,oBAClB,MAAMuH,EAAMC,EAAa,IAAI+I,KAAK,CAAEtQ,OAAQiG,EAAUjG,OAAQkD,YAkB9D,OAjBA+C,EAAU/F,QAAUoH,EAAI3D,KACxBT,EAAOwE,KAAOzB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,iBACxDuH,EAAI4G,OAASxH,EAAKT,EAAW,CAC3BU,OAAQ0J,UAAUjI,MAClB8E,cAAc,EACdtG,SAAU,gBAERX,EAAUiK,UAAU,WACtBjK,EAAUlG,MAAM,gCAElBmD,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,4BACvCuH,EAAI4G,OAAO3M,QACd0E,EAAUlG,MAAM,oBAElBmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,2BACrCuH,EAAI3D,IACb,CAEIrC,WACF,MAAO,MACT,CACIa,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAGAqG,MAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,OACvCyC,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAKuK,OAAOjN,KAAKsP,GAAMA,EAAEpK,MAAMC,MACzCA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,MAEZ,ECzFK,MAAM6M,iBAAiBhN,KAI5BwC,aAAaC,GACX,MAAMtD,EAASsD,EAAUC,YAAY,cACrC,IAAKvD,EACH,OAEF,MAAMO,EAAS,CAAEP,UAEjB,GADAO,EAAOsJ,SAAWvG,EAAUoB,QAAQ,YAC/BnE,EAAOsJ,SAUZ,OANAtJ,EAAOuN,MACLxK,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,iCAClBmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,2CACX,IAAIyQ,SAAS,CAAExQ,OAAQiG,EAAUjG,OAAQkD,WAT9C+C,EAAU6C,UAAUnG,EAAOY,MAU/B,CAEIjC,WACF,MAAO,UACT,CACIqB,aACF,OAAO,EAASgB,KAAKT,OAAOP,OAAO7C,MACrC,CACI0M,eACF,OAAO,EAAS7I,KAAKT,OAAOuN,MAAM3Q,MACpC,CAGAqG,MAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE2B,gBAAgBpE,KAAKT,OAAOP,OAAQgB,MACtCyC,EAAE/C,MAAMM,KAAKT,OAAOsJ,UACpBpG,EAAE2B,gBAAgBpE,KAAKT,OAAOuN,MAAO9M,MACrCyC,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,MAEZ,EC1CK,MAAM+M,gBAAgBlN,KAI3BwC,aAAaC,GAEX,MAAM/C,EAAS,CAAC,EACVoE,EAAMC,EAAa,IAAImJ,QAAQ,CAAE1Q,OAAQiG,EAAUjG,OAAQkD,YAEjE,GADAA,EAAOR,KAAOuD,EAAUoB,QAAQ,WAC3BnE,EAAOR,KAaZ,OAVA4E,EAAI/C,QACF+E,EAA8BrD,EAAW,iBACzCA,EAAUlG,MAAM,wBAClBmD,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,wBAClBkG,EAAU/F,QAAUoH,EAAI3D,KACxBT,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,sCACXuH,EAAI3D,IACb,CAEIrC,WACF,MAAO,SACT,CACIa,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAEA,UAAU0E,SACDb,KAAKY,QAAQkE,SAASjE,EAC/B,CAGA2B,MAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,OACvCyC,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,MAEZ,EC/CK,MAAMgN,yBAAyBnN,KAIpCwC,aAAaC,EAAWvD,GACtB,MAAMQ,EAAS,CAAER,QACX4E,EAAMC,EACV,IAAIoJ,iBAAiB,CAAE3Q,OAAQiG,EAAUjG,OAAQkD,YAmBnD,OAjBAA,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,yBAClBkG,EAAU/F,QAAUoH,EAAI3D,KACxBT,EAAOkE,OACLnB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,gCAC5CuH,EAAI/C,QACF8E,EAAYpD,IAAcA,EAAUlG,MAAM,gCAC5CmD,EAAOwE,KACLzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,4CAClBuH,EAAIgB,UAAYV,EAAc3B,GAC9B/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,yBAC5CmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,uCACXuH,EAAI3D,IACb,CAEIrC,WACF,MAAO,UACT,CACIa,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAEA,UAAU0E,SACDb,KAAKuG,SAASzB,SAASjE,SACvBb,KAAKY,QAAQkE,SAASjE,EAC/B,CAGA2B,MAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,OACvCyC,EAAE/C,MAAMM,KAAKT,OAAOkE,QACpBhB,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAK2E,UAAUrH,KAAKuH,GAAQA,EAAIrC,MAAMC,KACzCA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,MAEZ,EClCK,MAAMiN,kBAAkBpN,KAM7BwC,aAAaC,EAAW4K,GAAU,YAAEC,EAAW,eAAEC,IAC/C,MAAM,OAAE7N,EAAM,KAAE5B,GAASuP,EAWzB,IAVA3N,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,mBAAmBuB,KACrC2E,EAAU/F,QAAU2Q,EACpBA,EAAWtJ,EAAasJ,GACpBC,GACF3R,OAAOiI,OAAOlE,EAtCpB,SAAqB+C,GACnB,MAAM+K,EAAQ/K,EAAUoB,QAAQ,KAChC,OAAK2J,EAME,CAAEA,QAAOhN,YAFdiC,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,6BAJT,CAAC,CAMZ,CA6B4BiE,CAAYiC,IAEpC/C,EAAOwE,KAAOzB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,YAAYuB,KACpEuP,EAAStL,QAAU,KACN,CAEX,GADArC,EAAO2E,MAAQ5B,EAAUoB,QAAQ,KAC7BnE,EAAO2E,MAIT,OAHA3E,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,2BAA2BuB,KACtCuP,EAASlN,KAElB,MAAMqF,EAAKJ,mBAAmBR,MAAMnC,GACpC,IAAIgL,EACJ,IAAK,MAAOtK,KAAWuK,KAASH,EAE9B,GADAE,EAAM1J,EAAaZ,EAAOV,KAAciL,IACpCD,EACF,MAGCA,GACHhL,EAAUlG,MAAM,kBAElBkR,EAAI/G,SAAWlB,EACf6H,EAAStL,QAAQsD,KAAKoI,EAAItN,KAC5B,CACF,CAEIvB,cACF,QAASuB,KAAKT,OAAOd,OACvB,CACID,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CACIkE,kBACF,OAAKL,KAAKT,OAAOc,YAGV,EAASL,KAAKT,OAAOc,YAAYlE,OAF/B,IAGX,CAEA,UAAU0E,GACR,IAAK,MAAM2M,KAAUxN,KAAK4B,QACpB4L,EAAO1I,iBACF0I,EAAO1I,SAASjE,GAG7B,CAGA2B,MAAMC,GAcJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOkO,UACpBhL,EAAE/C,MAAMM,KAAKT,OAAOd,SACpBgE,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAE/C,MAAMM,KAAKT,OAAOuN,OACpBrK,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,OApBvB,KACbA,KAAKT,OAAOc,YAGVoC,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAO8N,OACpB5K,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOc,YAAY7C,QACpCiF,EAAEC,GAAGrC,YACHoC,EAAEnB,UAAUtB,KAAKT,OAAOc,YAAYlE,MAAO,CAAEoC,QAASyB,UANjD,GAmBPK,GACAoC,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAK4B,QAAQtE,KAAKoQ,GAAMA,EAAElL,MAAMC,MAC1CA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,MAEZ,ECnHK,MAAM2N,iBAAiB9N,KAI5BwC,aAAaC,GAEX,MAAM/C,EAAS,CAAC,EAEhB,GADAA,EAAOR,KAAOuD,EAAUoB,QAAQ,UAC3BnE,EAAOR,KACV,OAEF,IAAI6B,EAAUqF,EAAe3D,GAC7B,IAAK1B,EAAS,CACZ,MAAM7B,EACJuD,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,sBAClBwE,EAAU,IAAI6E,KAAK,CAAEpJ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAER,SAC3D,CACIuD,EAAU8C,MAAM,MAClB9C,EAAUlG,MAAM,qCAElBwE,EAAQjD,KAAO,aACf4B,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,sBAClBmD,EAAOkE,OACLnB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,gCAC5CmD,EAAOpD,MACLoL,EAAYjF,IAAcA,EAAUlG,MAAM,uBAC5CmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,oCAClB,MAAMuH,EAAM,IAAIgK,SAAS,CAAEtR,OAAQiG,EAAUjG,OAAQkD,WAErD,OADAqE,EAAaD,GAAK/C,QAAUA,EACrB+C,CACT,CAEIhG,WACF,MAAO,OACT,CACIa,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CACIA,YACF,OAAOsL,EAAWzH,KAAKT,OAAOpD,MAChC,CAGAqG,MAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,KAAMpB,WAC7C6D,EAAE/C,MAAMM,KAAKT,OAAOkE,QACpBhB,EAAE/C,MAAMM,KAAKT,OAAOpD,OACpBsG,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,KAAMpB,UAElB,ECjEK,MAAMgP,qBAAqB/N,KAIhCwC,aAAaC,GACX,MAAMsF,EAAiBtF,EAAUhG,SAC3BqH,EAAMC,EACV,IAAIgK,aAAa,CAAEvR,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAC,MAElD,OAAEA,GAAWoE,EAUnB,GATApE,EAAO4J,SAAW7G,EAAUoB,QAAQ,YAC/BnE,EAAO4J,WACV5J,EAAOsO,MAAQvL,EAAUoB,QAAQ,UAEnCnE,EAAOR,KAAOQ,EAAO4J,SACjB7G,EAAUoB,QAAQ,UAAW,WAC7BnE,EAAOsO,MACPvL,EAAUoB,QAAQ,YAClBpB,EAAUoB,QAAQ,WAAY,UAAW,YACxCnE,EAAOR,KAEV,YADAuD,EAAU6C,UAAUyC,GAItB,MAAM,KAAEjK,GAASgG,EACXmK,EAA8B,YAATnQ,EACrBoQ,EAAoBD,GAA+B,aAATnQ,EAC1CqQ,EAAkBrK,EAAIkK,OAAkB,aAATlQ,EAErC4B,EAAOwE,KACLzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,mCAAmCuB,iBACrD,MAAM6L,EACJ7D,EAA8BrD,IAC9BA,EAAUlG,MAAM,8BAA8BuB,iBAiChD,OAhCAgG,EAAI/C,QAAU,CAAC4I,GACf7F,EAAIgB,UAAY,GAEZoJ,IACFvE,EAAMjK,OAAOqD,UAAYN,EAAUoB,QAAQ,KACvC8F,EAAMjK,OAAOqD,UACfe,EAAI/C,QAAQsE,KAAKS,EAA8BrD,IACtCwL,GACTxL,EAAUlG,MAAM,mCAAmCuB,kBAIvD4B,EAAO2E,MACL5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,sCAAsCuB,iBAEpD2E,EAAU8C,MAAM,OACd4I,GACFzO,EAAO0O,SAAW3L,EAAUoB,QAAQ,KACpCC,EAAIgB,UAAUO,QAAQjB,EAAc3B,IACpC/C,EAAO2O,UACL5L,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,8CAElBkG,EAAUlG,MAAM,oDAIpBmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,2BAA2BuB,iBAEtCgG,EAAI3D,IACb,CAEIrC,WACF,OAAOqC,KAAKT,OAAOR,KAAK5C,KAC1B,CACIgN,eACF,QAASnJ,KAAKT,OAAO4J,QACvB,CACI0E,YACF,QAAS7N,KAAKT,OAAOsO,KACvB,CAEA,UAAUhN,GACR,IAAK,MAAMlD,KAAQqC,KAAKY,cACfjD,EAAKmH,SAASjE,GAEvB,IAAK,MAAMiI,KAAY9I,KAAK2E,gBACnBmE,EAAShE,SAASjE,EAE7B,CAGA2B,MAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAO4J,UACpB1G,EAAE/C,MAAMM,KAAKT,OAAOsO,OACpBpL,EAAE/C,MAAMM,KAAKT,OAAOR,KAAM0D,EAAEC,GAAGyD,SAC/B1D,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAKY,QAAQtD,KAAKC,GAAMA,EAAEiF,MAAMC,MAC1CA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAO0O,UACpBxL,EAAEC,GAAGC,KAAK3C,KAAK2E,UAAUrH,KAAKuH,GAAQA,EAAIrC,MAAMC,MAChDA,EAAE/C,MAAMM,KAAKT,OAAO2O,WACpBzL,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,KAAMpB,OAAQoB,KAAKpB,QAE/B,EC/GK,MAAMuP,oBAAoBtO,KAI/BwC,aAAaC,GACX,MAAMvD,EAAOuD,EAAUoB,QAAQ,eAC/B,IAAK3E,EACH,OAGF,MAAMQ,EAAS,CAAER,QACjBQ,EAAOwE,KACLzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,mCAClB,MAAMmR,EAAOtJ,EAAc3B,GAC3B/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,4BAC5CmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,kCAClB,MAAMuH,EAAM,IAAIwK,YAAY,CAAE9R,OAAQiG,EAAUjG,OAAQkD,WAExD,OADAqE,EAAaD,GAAKgB,UAAY4I,EACvB5J,CACT,CAEIhG,WACF,MAAO,aACT,CAEA,UAAUkD,GACR,IAAK,MAAMiI,KAAY9I,KAAK2E,gBACnBmE,EAAShE,SAASjE,EAE7B,CAGA2B,MAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,KAAM0D,EAAEC,GAAGsG,SAAU,CAAET,KAAMvI,KAAMpB,WACvD6D,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAK2E,UAAUrH,KAAKuH,GAAQA,EAAIrC,MAAMC,MAChDA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,KAAMpB,UAElB,EC7BF,SAASwP,EAAc9L,GACrB,MAAMoG,EAAUpG,EAAUoB,QAAQ,UAClC,IAAKgF,EAAS,OAKd,OAHEO,UAAUxE,MAAMnC,EAAW,CAAEoG,aAC7BD,UAAUhE,MAAMnC,EAAW,CAAEoG,aAC7BpG,EAAUlG,MAAM,2BAEpB,CAEO,MAAMiS,kBAAkBpB,UAQ7B5K,aAAaC,EAAWvD,GAAM,WAAEuP,EAAa,GAAE,QAAE7P,EAAU,MAAS,CAAC,GACnE,MAAMc,EAAS,CAAEd,UAASM,QAC1B,OAAOkO,UAAUxI,MACfnC,EACA,IAAI+L,UAAU,CAAEhS,OAAQiG,EAAUjG,OAAQkD,WAC1C,CACE4N,aAAc1O,EACd2O,eAAgB,IACXkB,EACH,CAACX,SAASlJ,OACV,CAAC0J,YAAY1J,OACb,CAAC2J,GACD,CAACrE,GACD,CAAC6D,aAAanJ,OACd,CAACwE,UAAUxE,OACX,CAACgE,UAAUhE,SAInB,CAEI9G,WACF,MAAO,WACT,CAEA,UAAUkD,GAER,SADOb,KAAKuG,SAASzB,SAASjE,IAE3Bb,KAAKvB,SACNuB,KAAKuG,SAASgI,OAAO3J,GAA6B,YAAjBA,EAAQpG,OACzC,CACA,MAAMhC,EAAU,oTAKViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,kBACAxD,EACA,CACEG,QAASwN,EAAwBnK,OAGvC,CACA,MAAMwO,EAAkBxO,KAAKuG,SAASI,QACnC/B,GAA6B,gBAAjBA,EAAQpG,OAEvB,IAAK,MAAMsB,KAAe0O,EAAiB,CACzC,MAAMhS,EAAU,oRAIViD,EACJK,EAAYP,OAAOf,KACnBwB,KACA,qBACAxD,EACA,CACEG,QAAS8R,EAAmBzO,KAAMF,IAGxC,CAGA,GADiBE,KAAKuG,SAAS1E,MAAM+C,GAA6B,WAAjBA,EAAQpG,OAC3C,CACZ,MAAMkQ,EAAmB1O,KAAKuG,SAASI,QACpC/B,GAA6B,0BAAjBA,EAAQpG,OAEvB,IAAK,MAAMmQ,KAASD,EAAkB,CACpC,MAAMlS,EAAU,uEACViD,EACJkP,EAAMpP,OAAOf,KACbwB,KACA,0BACAxD,EAEJ,CAEA,MAAMoS,EAAe5O,KAAK4B,QAAQ+E,QAC/B6G,GAA2B,gBAAhBA,EAAO7P,OAErB,IAAK,MAAMgR,KAASC,EAAc,CAChC,MAAMpS,EAAU,kEACViD,EACJkP,EAAMpP,OAAOR,KACbiB,KACA,0BACAxD,EAEJ,CACF,OAEO2F,MAAM2C,SAASjE,GACjBb,KAAKvB,gBClIP,UAA0CoC,EAAMgO,GACrD,MAAMC,EA8CN,SAA6BD,GAC3B,MAAME,EAAMC,EAAcH,GAC1B,MAAO,CACLI,QAAS,IAAIC,IACXH,EAAIpI,QAAQwI,GAAsB,WAAfA,EAAGzG,UAAsBpL,KAAK6R,GAAOA,EAAG3Q,QAE7D4Q,WAAY,IAAIF,IACdH,EAAIpI,QAAQwI,GAAsB,WAAfA,EAAGzG,UAAsBpL,KAAK6R,GAAOA,EAAG3Q,QAGjE,CAxDgB6Q,CAAoBR,GAC9BS,EAAWzO,EAAKyO,SAAS3T,IAAIkT,EAAErQ,OAAS,GACxC+Q,EAAS1O,EAAK2O,SAAS7T,IAAIkT,EAAErQ,OAAS,GAC5C,IAAK,MAAMiR,IAAO,IAAIH,KAAaC,GAAS,CAC1C,MAAMG,EAAYV,EAAcS,GAC1BR,EAAUS,EAAU/I,QAAQwB,GAAoB,WAAdA,EAAEO,UACpC0G,EAAaM,EAAU/I,QAAQwB,GAAoB,WAAdA,EAAEO,gBACtCiH,EAAeV,EAASH,EAAQG,QAASQ,EAAKZ,SAC9Cc,EAAeP,EAAYN,EAAQM,WAAYK,EAAKZ,GAC3DI,EAAQW,SAAST,GAAOL,EAAQG,QAAQY,IAAIV,EAAG3Q,QAC/C4Q,EAAWQ,SAAST,GAAOL,EAAQM,WAAWS,IAAIV,EAAG3Q,OACvD,CAQA,SAAUmR,EAAeD,EAAWI,EAAWL,EAAK1Q,GAClD,IAAK,MAAMgR,KAAYL,EAAW,CAChC,MAAM,KAAElR,GAASuR,EACjB,GAAIvR,GAAQsR,EAAU1O,IAAI5C,GAAO,CAC/B,MACMhC,EAAU,OADsB,WAArBuT,EAASrH,QAAuB,UAAY,gBAChBlK,uDAA0DO,EAAKP,6CACtGiB,EACJsQ,EAASxQ,OAAOf,KAChBiR,EACA,oBACAjT,EAEJ,CACF,CACF,CAMA,SAASwS,EAAcH,GACrB,OAAOA,EAAEjN,QAAQ+E,QAAO,EAAGhJ,UAAoB,cAATA,GACxC,CAgBF,CDyEaqS,CAAgCnP,EAAMb,MAEjD,EAGF,SAASyO,EAAmBwB,EAAcC,GAExC,OADAD,EAAerM,EAAaqM,GACrB,KACL,MAAME,EAAcnG,EAClBiG,EAAa1J,SAAShH,OAAOwE,KAAKvG,QAE9B4S,EAAeH,EAAarO,QAAQhE,OACtCoM,EAAmB3B,EAAc4H,EAAarO,QAAQ,IAAIpE,QVgD3D,SAA8B6S,GACnC,MAAMF,EAAcnG,EAAmBqG,GACjCC,EAAWH,EAAYtH,SAAS,MAAQ,KAAO,KACrD,OAAOsH,EAAcG,CACvB,CUnDQC,CAAqBJ,GACnBK,EAAgBrC,YAAY1J,MAChC,IAAI+D,UAAU,KAAK4H,oBAErBI,EAAcjK,SAAW,IAAItB,mBAAmB,CAC9C5I,OAAQ4T,EAAa5T,OACrBkD,OAAQ,CAAC,IAEXqE,EAAa4M,GAAe7L,UAAYuL,EAAmBvL,UAE3D,MAAM8L,EVwFH,SAAuBC,EAAOC,GACnC,MAAM/Q,EAAQ8Q,EAAM3T,QAAQ6T,UAAUC,UAAUF,GAChD,OAAe,IAAX/Q,EACKA,EAEF8Q,EAAM9S,OAASgC,EAAQ,CAChC,CU9F0BkR,CACpBb,EAAarO,SACZ8L,GAAiB,gBAAXA,EAAE/P,OAEXsS,EAAarO,QAAQwF,OAAOqJ,EAAgB,EAAG,EAAGD,GAElD,MAAM,MAAEtM,GAAU+L,EAAa1Q,OAC1B2E,EAAM1G,OAAOqL,SAAS,QACzB3E,EAAM1G,QAAU,KAAK2S,KAGvB,MAAM,SAAE5J,GAAa0J,EACfrQ,EAAQ2G,EAASY,QAAQ+I,GACzBa,EAAUxK,EAASa,OAAOxH,EAAO,GAClC2G,EAAS3I,OAEH2I,EAAS3I,SAAWgC,EAC7B2G,EAAS3G,EAAQ,GAAGL,OAAOqD,eAAYxC,EAC7BmG,EAAS3G,GAAOL,OAAOf,KAAKhB,OAAOwT,SAC7CzK,EAAS3G,GAAOL,OAAOf,KAAKhB,OAASuT,EAAQ,GAAGxR,OAAOf,KAAKhB,QAJ5D+I,EAAShH,OAAOwE,KAAOwC,EAAShH,OAAO2E,WAAQ9D,CAKjD,CAEJ,CEhLO,MAAM6Q,cAAchE,UAQzB5K,aAAaC,EAAWvD,GAAM,WAAEuP,EAAa,GAAE,QAAE7P,GAAY,CAAC,GAC5D,MAAMc,EAAS,CAAEd,UAASM,QAE1B,GADAQ,EAAOuN,MAAQxK,EAAUoB,QAAQ,SAC5BnE,EAAOuN,MAGZ,OAAOG,UAAUxI,MACfnC,EACA,IAAI2O,MAAM,CAAE5U,OAAQiG,EAAUjG,OAAQkD,WACtC,CACE6N,eAAgB,IACXkB,EACH,CAACX,SAASlJ,OACV,CAACsF,GACD,CAACd,UAAUxE,MAAO,CAAEyE,WAAW,IAC/B,CAACT,UAAUhE,MAAO,CAAEkE,SAAS,MAIrC,CAEIhL,WACF,MAAO,iBACT,EC5BK,MAAMuT,cAAcrR,KAIzBwC,aAAaC,GAEX,MAAM/C,EAAS,CAAC,EACVoE,EAAMC,EAAa,IAAIsN,MAAM,CAAE7U,OAAQiG,EAAUjG,OAAQkD,YAe/D,OAdAoE,EAAI4C,SAAWtB,mBAAmBR,MAAMnC,GACxC/C,EAAOwC,SAAWO,EAAUoB,QAAQ,YACpCC,EAAI/C,QACF+E,EAA8BrD,EAAW,oBACzCA,EAAUlG,MAAM,kCAClBmD,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,kCAClBuH,EAAIqE,QAAUV,QAAQ7C,MAAMnC,GACxB/C,EAAOwC,UAAY4B,EAAIqE,SACzB1F,EAAUlG,MAAM,2CAClBmD,EAAOqJ,YACLtG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,gDACXuH,EAAI3D,IACb,CAEIrC,WACF,MAAO,OACT,CACIa,WACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CACI4F,eACF,QAAS/B,KAAKT,OAAOwC,QACvB,CAEA,UAAUlB,SACDb,KAAKY,QAAQkE,SAASjE,EAC/B,CAGA2B,MAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKuG,SAAS/D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOwC,UACpBU,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE6F,WAAWtI,KAAKT,OAAOf,KAAM,CAAE+J,KAAMvI,KAAMpB,WAC7CoB,KAAKgI,QAAUhI,KAAKgI,QAAQxF,MAAMC,GAAK,GACvCA,EAAE/C,MAAMM,KAAKT,OAAOqJ,eAEtB,CAAEL,KAAMvI,KAAMpB,UAElB,EC3DK,MAAMuS,mBAAmBlE,UAO9B5K,aAAaC,GAAW,WAAEgM,EAAa,GAAE,QAAE7P,GAAY,CAAC,GACtD,MAAMc,EAAS,CAAEd,WAEjB,GADAc,EAAOR,KAAOuD,EAAUoB,QAAQ,cAC3BnE,EAAOR,KAGZ,OAAOkO,UAAUxI,MACfnC,EACA,IAAI6O,WAAW,CAAE9U,OAAQiG,EAAUjG,OAAQkD,WAC3C,CACE4N,aAAc1O,EACd2O,eAAgB,IAAIkB,EAAY,CAAC4C,MAAMzM,SAG7C,CAEI9G,WACF,MAAO,YACT,ECrBK,MAAMyT,kBAAkBnE,UAO7B5K,aAAaC,GAAW,WAAEgM,EAAa,GAAE,QAAE7P,GAAY,CAAC,GACtD,MAAMc,EAAS,CAAEd,WAEjB,GADAc,EAAOR,KAAOuD,EAAUoB,QAAQ,aAC3BnE,EAAOR,KAGZ,OAAOkO,UAAUxI,MACfnC,EACA,IAAI8O,UAAU,CAAE/U,OAAQiG,EAAUjG,OAAQkD,WAC1C,CACE6N,eAAgB,IACXkB,EACH,CAACrF,UAAUxE,MAAO,CAAEyE,WAAW,EAAMC,UAAU,IAC/C,CAACwE,SAASlJ,OACV,CAACgE,UAAUhE,MAAO,CAAEkE,SAAS,MAIrC,CAEIhL,WACF,MAAO,WACT,CAEA,UAAUkD,GACR,IACGb,KAAKvB,SACNuB,KAAKuG,SAASgI,OAAO3J,GAA6B,YAAjBA,EAAQpG,OACzC,CACA,MAAMhC,EAAU,gTAKViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,kBACAxD,EACA,CACEG,QAASwN,EAAwBnK,OAGvC,OACOmC,MAAM2C,SAASjE,EACxB,ECvDK,MAAMwQ,0BAA0BpE,UAOrC5K,aAAaC,EAAWmL,GAAU,WAAEa,EAAa,IAAO,CAAC,GACvD,MAAM/O,EAAS,CAAEkO,YAEjB,GADAlO,EAAOR,KAAOuD,EAAUoB,QAAQ,aAC3BnE,EAAOR,KAGZ,OAAOkO,UAAUxI,MACfnC,EACA,IAAI+O,kBAAkB,CAAEhV,OAAQiG,EAAUjG,OAAQkD,WAClD,CACE6N,eAAgB,IACXkB,EACH,CAACX,SAASlJ,OACV,CAACgE,UAAUhE,MAAO,CAAEkE,SAAS,MAIrC,CAEIhL,WACF,MAAO,oBACT,ECDF,SAAS2T,EAAchP,EAAW3C,GAChC,MAAMtD,EAASiG,EAAUjG,OAEzB,SAASD,EAAM6N,GACb3H,EAAUlG,MAAM6N,EAClB,CAEA,SAASvG,KAAW8I,GAClB,OAAOlK,EAAUoB,WAAW8I,EAC9B,CAaA,SAAS+E,EAAWC,GAClB,MAAMzS,EAAO2E,EAAQ,aACrB,GAAK3E,EACL,OACEkS,MAAMxM,MAAMnC,EAAWvD,EAAM,IACxByS,KACA7R,GAAS8R,YAAY3E,SAE1BuB,UAAU5J,MAAMnC,EAAWvD,EAAM,IAC5ByS,KACA7R,GAAS8R,YAAYC,aAE1BtV,EAAM,+BAEV,CAmBA,SAASf,IACP,GAAIsE,EAAQgS,YACV,IAAK,MAAMC,KAAcjS,EAAQgS,YAAa,CAC5C,MAAM1S,EAAS2S,EAAWtP,GAC1B,GAAIrD,EACF,OAAOA,CAEX,CAGF,OAtDF,WACE,MAAMwO,EAAW/J,EAAQ,YACzB,GAAK+J,EACL,OAAInL,EAAU8C,MAAM,aACXiM,kBAAkB5M,MAAMnC,EAAWmL,EAAU,IAC/C9N,GAAS8R,YAAYI,oBAGrB7E,iBAAiBvI,MAAMnC,EAAWmL,EAC3C,CA8CIA,IACA8D,KA7BJ,WACE,MAAM9S,EAAUiF,EAAQ,WACxB,GAAKjF,EACL,OACE0S,WAAW1M,MAAMnC,EAAW,CAC1B7D,aACGkB,GAAS8R,YAAYlQ,cAE1BgQ,EAAW,CAAE9S,aACb2S,UAAU3M,MAAMnC,EAAW,CACzB7D,aACGkB,GAAS8R,YAAYK,aAE1B1V,EAAM,oCAEV,CAeIqC,IACA0S,WAAW1M,MAAMnC,EAAW3C,GAAS8R,YAAYlQ,aACjDoL,KAAKlI,MAAMnC,IACXyK,QAAQtI,MAAMnC,IACduK,SAASpI,MAAMnC,IACf8O,UAAU3M,MAAMnC,EAAW3C,GAAS8R,YAAYK,UAEpD,CAsBA,MAAMC,EApBN,WACE,IAAK1V,EAAOuB,OAAQ,MAAO,GAC3B,MAAMiD,EAAO,GACb,OAAa,CACX,MAAMwE,EAAKJ,mBAAmBR,MAAMnC,GAC9BtB,EAAM3F,IACZ,IAAK2F,EAAK,CACJqE,EAAGzH,QAAQxB,EAAM,6BACrB,KACF,CACAwH,EAAa5C,GAAKuF,SAAWlB,EAC7BxE,EAAKqE,KAAKlE,EACZ,CACA,MAAMgR,EAAMnP,IAAI4B,MAAMnC,GAItB,OAHI3C,EAAQsS,UACVpR,EAAKqE,KAAK8M,GAELnR,CACT,CAEYqR,GAEZ,OADI5P,EAAUhG,SAAWD,EAAOuB,QAAQxB,EAAM,uBACvC2V,CACT,CAMO,SAAStN,EAAMwF,EAAKtK,EAAU,CAAC,GACpC,MAAM2C,EAAY,IAAIkG,UAAUyB,GAKhC,YAJkC,IAAvBtK,EAAQN,aAEjBiD,EAAUjG,OAAOmC,KAAOmB,EAAQN,YAE3BiS,EAAchP,EAAW3C,EAClC,CChJA,SAASwS,EAAKtN,GACZ,OAAOA,CACT,CAEA,MAAMuN,EAAY,CAChBzP,KAAO8G,GAAUA,EAAMhM,KAAK,IAC5BD,OAAQ2U,EACR3T,KAAM2T,EACN7Q,UAAW6Q,EACXxU,KAAMwU,EACNhM,QAASgM,EACTnJ,SAAUmJ,EACV9R,YAAa8R,EACb9W,WAAY8W,EACZpN,kBAAmBoN,EACnBnN,2BAA4BmN,GAGvB,MAAME,OACXvS,YAAY4C,GACV1C,KAAK0C,GAAKlH,OAAOiI,OAAO,CAAC,EAAG2O,EAAW1P,EACzC,CASApB,UAAUgR,GAAK,UAAErL,EAAS,QAAE1I,IAI1B,OAHK0I,IACHA,EAAYqL,EAAIhJ,WAAW,KAAOgJ,EAAIvV,MAAM,GAAKuV,GAE5CtS,KAAK0C,GAAGpB,UAAUgR,EAAKrL,EAAW1I,EAC3C,CAQAmB,MAAMnC,EAAGgV,EAAUJ,KAAS5E,GAC1B,IAAKhQ,EACH,MAAO,GAET,MAAMpB,EAAQoW,EAAQhV,EAAEpB,SAAUoR,GAClC,OAAOvN,KAAK0C,GAAGC,KAAK,CAAC3C,KAAK0C,GAAGlF,OAAOD,EAAEC,QAASrB,GACjD,CAEAiI,gBAAgB7G,EAAGgB,GACjB,OAAOyB,KAAKN,MAAMnC,EAAGyC,KAAKsB,UAAUkR,KAAKxS,MAAO,CAAEzB,WACpD,CAEA+J,WAAW/K,EAAGsH,GACZ,OAAO7E,KAAKN,MAAMnC,EAAGyC,KAAK0C,GAAGlE,KAAMqG,EACrC,CAEAP,WAAWmO,EAAIlU,GACb,OAAOyB,KAAK0C,GAAGC,KAAK,CAClB3C,KAAKoE,gBAAgBqO,EAAGlT,OAAOpD,MAAOoC,GACtCyB,KAAKN,MAAM+S,EAAGlT,OAAOqD,YAEzB,EAGK,SAASJ,EAAMkQ,GAAON,UAAW1P,EAAK0P,GAAc,CAAC,GAC1D1P,EAAKlH,OAAOiI,OAAO,CAAC,EAAG2O,EAAW1P,GAElC,MAAMD,EAAI,IAAI4P,OAAO3P,GAErB,OAAOA,EAAGC,KAAK+P,EAAIpV,KAAKqV,GAAOA,EAAGnQ,MAAMC,KAC1C,CCvEA,SAASmQ,EAAYC,EAAK5R,GACxB,MAAM3D,EAAM,IAAI8F,IACVyF,EAAWgK,EAAIlM,QAAQ3F,GAAqB,aAAbA,EAAIrD,OACzC,IAAK,MAAMmV,KAAWjK,EAAU,CAC9B,MAAMiE,EAAQ7L,EAAOtF,IAAImX,EAAQjK,UACjC,IAAKiE,EACH,SAEF,MAAM4D,EAAQpT,EAAI3B,IAAImX,EAAQ9T,QAC1B0R,EACFA,EAAMxL,KAAK4H,GAEXxP,EAAI+D,IAAIyR,EAAQ9T,OAAQ,CAAC8N,GAE7B,CACA,OAAOxP,CACT,CAmDA,SAAUyV,EAAiBL,GACzB,MAAM7R,EA/CR,SAA0BgS,GACxB,MAAM5R,EAAS,IAAImC,IACb4P,EAAa,IAAI9D,IACjBI,EAAW,IAAIlM,IACrB,IAAK,MAAMpC,KAAO6R,EAChB,GAAI7R,EAAIvC,QAAR,CACE,MAAMiS,EAAQpB,EAAS3T,IAAIqF,EAAIxC,MAC3BkS,EACFA,EAAMxL,KAAKlE,GAEXsO,EAASjO,IAAIL,EAAIxC,KAAM,CAACwC,GAG5B,MACKA,EAAIxC,OAGJyC,EAAOG,IAAIJ,EAAIxC,MAGlBwU,EAAWnD,IAAI7O,GAFfC,EAAOI,IAAIL,EAAIxC,KAAMwC,IAKzB,MAAO,CACL6R,MACA5R,SACAqO,WACA0D,aACAxD,SAAUoD,EAAYC,EAAK5R,GAC3BE,MAAO,CACLD,0BAA2B,IAAI+R,QAC/BvR,gCAAiC,IAAIuR,SAG3C,CAaeC,CAAiBR,GAC9B,IAAK,MAAM1R,KAAOH,EAAKgS,IACjB7R,EAAI8D,iBACC9D,EAAI8D,SAASjE,UAd1B,WAA+B,OAAEI,EAAM,WAAE+R,IACvC,IAAK,MAAMG,KAAOH,EAAY,CAC5B,MAAM,KAAExU,GAAS2U,EACX3W,EAAU,aAAagC,eAC3ByC,EAAOtF,IAAI6C,GAAMb,+BAEb,EAAMwV,EAAI5T,OAAOf,KAAM2U,EAAK,eAAgB3W,EACpD,CACF,CASS4W,CAAqBvS,EAC9B,CAcO,SAASiE,EAAS4N,GACvB,MAAO,IAAIK,GAZIrC,EAYqBgC,EAXhChC,EAAM2C,KACD3C,EAAM2C,OAER,GAAGhI,UAAUqF,MAJtB,IAAiBA,CAajB,C","sources":["webpack://WebIDL2/webpack/universalModuleDefinition","webpack://WebIDL2/webpack/bootstrap","webpack://WebIDL2/webpack/runtime/define property getters","webpack://WebIDL2/webpack/runtime/hasOwnProperty shorthand","webpack://WebIDL2/webpack/runtime/make namespace object","webpack://WebIDL2/./lib/error.js","webpack://WebIDL2/./lib/productions/base.js","webpack://WebIDL2/./lib/validators/helpers.js","webpack://WebIDL2/./lib/productions/array-base.js","webpack://WebIDL2/./lib/productions/token.js","webpack://WebIDL2/./lib/productions/extended-attributes.js","webpack://WebIDL2/./lib/productions/type.js","webpack://WebIDL2/./lib/productions/default.js","webpack://WebIDL2/./lib/productions/argument.js","webpack://WebIDL2/./lib/productions/operation.js","webpack://WebIDL2/./lib/productions/attribute.js","webpack://WebIDL2/./lib/productions/helpers.js","webpack://WebIDL2/./lib/tokeniser.js","webpack://WebIDL2/./lib/productions/enum.js","webpack://WebIDL2/./lib/productions/includes.js","webpack://WebIDL2/./lib/productions/typedef.js","webpack://WebIDL2/./lib/productions/callback.js","webpack://WebIDL2/./lib/productions/container.js","webpack://WebIDL2/./lib/productions/constant.js","webpack://WebIDL2/./lib/productions/iterable.js","webpack://WebIDL2/./lib/productions/constructor.js","webpack://WebIDL2/./lib/productions/interface.js","webpack://WebIDL2/./lib/validators/interface.js","webpack://WebIDL2/./lib/productions/mixin.js","webpack://WebIDL2/./lib/productions/field.js","webpack://WebIDL2/./lib/productions/dictionary.js","webpack://WebIDL2/./lib/productions/namespace.js","webpack://WebIDL2/./lib/productions/callback-interface.js","webpack://WebIDL2/./lib/webidl2.js","webpack://WebIDL2/./lib/writer.js","webpack://WebIDL2/./lib/validator.js"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"WebIDL2\"] = factory();\n\telse\n\t\troot[\"WebIDL2\"] = factory();\n})(globalThis, () => {\nreturn ","// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","/**\n * @param {string} text\n */\nfunction lastLine(text) {\n  const splitted = text.split(\"\\n\");\n  return splitted[splitted.length - 1];\n}\n\nfunction appendIfExist(base, target) {\n  let result = base;\n  if (target) {\n    result += ` ${target}`;\n  }\n  return result;\n}\n\nfunction contextAsText(node) {\n  const hierarchy = [node];\n  while (node && node.parent) {\n    const { parent } = node;\n    hierarchy.unshift(parent);\n    node = parent;\n  }\n  return hierarchy.map((n) => appendIfExist(n.type, n.name)).join(\" -> \");\n}\n\n/**\n * @typedef {object} WebIDL2ErrorOptions\n * @property {\"error\" | \"warning\"} [level]\n * @property {Function} [autofix]\n * @property {string} [ruleName]\n *\n * @typedef {ReturnType<typeof error>} WebIDLErrorData\n *\n * @param {string} message error message\n * @param {*} position\n * @param {*} current\n * @param {*} message\n * @param {\"Syntax\" | \"Validation\"} kind error type\n * @param {WebIDL2ErrorOptions=} options\n */\nfunction error(\n  source,\n  position,\n  current,\n  message,\n  kind,\n  { level = \"error\", autofix, ruleName } = {}\n) {\n  /**\n   * @param {number} count\n   */\n  function sliceTokens(count) {\n    return count > 0\n      ? source.slice(position, position + count)\n      : source.slice(Math.max(position + count, 0), position);\n  }\n\n  /**\n   * @param {import(\"./tokeniser.js\").Token[]} inputs\n   * @param {object} [options]\n   * @param {boolean} [options.precedes]\n   * @returns\n   */\n  function tokensToText(inputs, { precedes } = {}) {\n    const text = inputs.map((t) => t.trivia + t.value).join(\"\");\n    const nextToken = source[position];\n    if (nextToken.type === \"eof\") {\n      return text;\n    }\n    if (precedes) {\n      return text + nextToken.trivia;\n    }\n    return text.slice(nextToken.trivia.length);\n  }\n\n  const maxTokens = 5; // arbitrary but works well enough\n  const line =\n    source[position].type !== \"eof\"\n      ? source[position].line\n      : source.length > 1\n      ? source[position - 1].line\n      : 1;\n\n  const precedingLastLine = lastLine(\n    tokensToText(sliceTokens(-maxTokens), { precedes: true })\n  );\n\n  const subsequentTokens = sliceTokens(maxTokens);\n  const subsequentText = tokensToText(subsequentTokens);\n  const subsequentFirstLine = subsequentText.split(\"\\n\")[0];\n\n  const spaced = \" \".repeat(precedingLastLine.length) + \"^\";\n  const sourceContext = precedingLastLine + subsequentFirstLine + \"\\n\" + spaced;\n\n  const contextType = kind === \"Syntax\" ? \"since\" : \"inside\";\n  const inSourceName = source.name ? ` in ${source.name}` : \"\";\n  const grammaticalContext =\n    current && current.name\n      ? `, ${contextType} \\`${current.partial ? \"partial \" : \"\"}${contextAsText(\n          current\n        )}\\``\n      : \"\";\n  const context = `${kind} error at line ${line}${inSourceName}${grammaticalContext}:\\n${sourceContext}`;\n  return {\n    message: `${context} ${message}`,\n    bareMessage: message,\n    context,\n    line,\n    sourceName: source.name,\n    level,\n    ruleName,\n    autofix,\n    input: subsequentText,\n    tokens: subsequentTokens,\n  };\n}\n\n/**\n * @param {string} message error message\n */\nexport function syntaxError(source, position, current, message) {\n  return error(source, position, current, message, \"Syntax\");\n}\n\n/**\n * @param {string} message error message\n * @param {WebIDL2ErrorOptions} [options]\n */\nexport function validationError(\n  token,\n  current,\n  ruleName,\n  message,\n  options = {}\n) {\n  options.ruleName = ruleName;\n  return error(\n    current.source,\n    token.index,\n    current,\n    message,\n    \"Validation\",\n    options\n  );\n}\n","export class Base {\n  /**\n   * @param {object} initializer\n   * @param {Base[\"source\"]} initializer.source\n   * @param {Base[\"tokens\"]} initializer.tokens\n   */\n  constructor({ source, tokens }) {\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens, writable: true },\n      parent: { value: null, writable: true },\n      this: { value: this }, // useful when escaping from proxy\n    });\n  }\n\n  toJSON() {\n    const json = { type: undefined, name: undefined, inheritance: undefined };\n    let proto = this;\n    while (proto !== Object.prototype) {\n      const descMap = Object.getOwnPropertyDescriptors(proto);\n      for (const [key, value] of Object.entries(descMap)) {\n        if (value.enumerable || value.get) {\n          // @ts-ignore - allow indexing here\n          json[key] = this[key];\n        }\n      }\n      proto = Object.getPrototypeOf(proto);\n    }\n    return json;\n  }\n}\n","/**\n * @typedef {import(\"../validator.js\").Definitions} Definitions\n * @typedef {import(\"../productions/dictionary.js\").Dictionary} Dictionary\n * @typedef {import(\"../../lib/productions/type\").Type} Type\n *\n * @param {Type} idlType\n * @param {Definitions} defs\n * @param {object} [options]\n * @param {boolean} [options.useNullableInner] use when the input idlType is nullable and you want to use its inner type\n * @return {{ reference: *, dictionary: Dictionary }} the type reference that ultimately includes dictionary.\n */\nexport function idlTypeIncludesDictionary(\n  idlType,\n  defs,\n  { useNullableInner } = {}\n) {\n  if (!idlType.union) {\n    const def = defs.unique.get(idlType.idlType);\n    if (!def) {\n      return;\n    }\n    if (def.type === \"typedef\") {\n      const { typedefIncludesDictionary } = defs.cache;\n      if (typedefIncludesDictionary.has(def)) {\n        // Note that this also halts when it met indeterminate state\n        // to prevent infinite recursion\n        return typedefIncludesDictionary.get(def);\n      }\n      defs.cache.typedefIncludesDictionary.set(def, undefined); // indeterminate state\n      const result = idlTypeIncludesDictionary(def.idlType, defs);\n      defs.cache.typedefIncludesDictionary.set(def, result);\n      if (result) {\n        return {\n          reference: idlType,\n          dictionary: result.dictionary,\n        };\n      }\n    }\n    if (def.type === \"dictionary\" && (useNullableInner || !idlType.nullable)) {\n      return {\n        reference: idlType,\n        dictionary: def,\n      };\n    }\n  }\n  for (const subtype of idlType.subtype) {\n    const result = idlTypeIncludesDictionary(subtype, defs);\n    if (result) {\n      if (subtype.union) {\n        return result;\n      }\n      return {\n        reference: subtype,\n        dictionary: result.dictionary,\n      };\n    }\n  }\n}\n\n/**\n * @param {Dictionary} dict dictionary type\n * @param {Definitions} defs\n * @return {boolean}\n */\nexport function dictionaryIncludesRequiredField(dict, defs) {\n  if (defs.cache.dictionaryIncludesRequiredField.has(dict)) {\n    return defs.cache.dictionaryIncludesRequiredField.get(dict);\n  }\n  // Set cached result to indeterminate to short-circuit circular definitions.\n  // The final result will be updated to true or false.\n  defs.cache.dictionaryIncludesRequiredField.set(dict, undefined);\n  let result = dict.members.some((field) => field.required);\n  if (!result && dict.inheritance) {\n    const superdict = defs.unique.get(dict.inheritance);\n    if (!superdict) {\n      // Assume required members in the supertype if it is unknown.\n      result = true;\n    } else if (dictionaryIncludesRequiredField(superdict, defs)) {\n      result = true;\n    }\n  }\n  defs.cache.dictionaryIncludesRequiredField.set(dict, result);\n  return result;\n}\n\n/**\n * For now this only checks the most frequent cases:\n * 1. direct inclusion of [EnforceRange]\n * 2. typedef of that\n *\n * More complex cases with dictionaries and records are not covered yet.\n *\n * @param {Type} idlType\n * @param {Definitions} defs\n */\nexport function idlTypeIncludesEnforceRange(idlType, defs) {\n  if (idlType.union) {\n    // TODO: This should ideally be checked too\n    return false;\n  }\n\n  if (idlType.extAttrs.some((e) => e.name === \"EnforceRange\")) {\n    return true;\n  }\n\n  const def = defs.unique.get(idlType.idlType);\n  if (def?.type !== \"typedef\") {\n    return false;\n  }\n\n  return def.idlType.extAttrs.some((e) => e.name === \"EnforceRange\");\n}\n","export class ArrayBase extends Array {\n  constructor({ source, tokens }) {\n    super();\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens },\n      parent: { value: null, writable: true },\n    });\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape } from \"./helpers.js\";\n\nexport class WrappedToken extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {string} type\n   */\n  static parser(tokeniser, type) {\n    return () => {\n      const value = tokeniser.consumeKind(type);\n      if (value) {\n        return new WrappedToken({\n          source: tokeniser.source,\n          tokens: { value },\n        });\n      }\n    };\n  }\n\n  get value() {\n    return unescape(this.tokens.value.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      w.token(this.tokens.value),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\nexport class Eof extends WrappedToken {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const value = tokeniser.consumeKind(\"eof\");\n    if (value) {\n      return new Eof({ source: tokeniser.source, tokens: { value } });\n    }\n  }\n\n  get type() {\n    return \"eof\";\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ArrayBase } from \"./array-base.js\";\nimport { WrappedToken } from \"./token.js\";\nimport { list, argument_list, autoParenter, unescape } from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} tokenName\n */\nfunction tokens(tokeniser, tokenName) {\n  return list(tokeniser, {\n    parser: WrappedToken.parser(tokeniser, tokenName),\n    listName: tokenName + \" list\",\n  });\n}\n\nconst extAttrValueSyntax = [\"identifier\", \"decimal\", \"integer\", \"string\"];\n\nconst shouldBeLegacyPrefixed = [\n  \"NoInterfaceObject\",\n  \"LenientSetter\",\n  \"LenientThis\",\n  \"TreatNonObjectAsNull\",\n  \"Unforgeable\",\n];\n\nconst renamedLegacies = new Map([\n  .../** @type {[string, string][]} */ (\n    shouldBeLegacyPrefixed.map((name) => [name, `Legacy${name}`])\n  ),\n  [\"NamedConstructor\", \"LegacyFactoryFunction\"],\n  [\"OverrideBuiltins\", \"LegacyOverrideBuiltIns\"],\n  [\"TreatNullAs\", \"LegacyNullToEmptyString\"],\n]);\n\n/**\n * This will allow a set of extended attribute values to be parsed.\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction extAttrListItems(tokeniser) {\n  for (const syntax of extAttrValueSyntax) {\n    const toks = tokens(tokeniser, syntax);\n    if (toks.length) {\n      return toks;\n    }\n  }\n  tokeniser.error(\n    `Expected identifiers, strings, decimals, or integers but none found`\n  );\n}\n\nexport class ExtendedAttributeParameters extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = { assign: tokeniser.consume(\"=\") };\n    const ret = autoParenter(\n      new ExtendedAttributeParameters({ source: tokeniser.source, tokens })\n    );\n    ret.list = [];\n    if (tokens.assign) {\n      tokens.asterisk = tokeniser.consume(\"*\");\n      if (tokens.asterisk) {\n        return ret.this;\n      }\n      tokens.secondaryName = tokeniser.consumeKind(...extAttrValueSyntax);\n    }\n    tokens.open = tokeniser.consume(\"(\");\n    if (tokens.open) {\n      ret.list = ret.rhsIsList\n        ? // [Exposed=(Window,Worker)]\n          extAttrListItems(tokeniser)\n        : // [LegacyFactoryFunction=Audio(DOMString src)] or [Constructor(DOMString str)]\n          argument_list(tokeniser);\n      tokens.close =\n        tokeniser.consume(\")\") ||\n        tokeniser.error(\"Unexpected token in extended attribute argument list\");\n    } else if (tokens.assign && !tokens.secondaryName) {\n      tokeniser.error(\"No right hand side to extended attribute assignment\");\n    }\n    return ret.this;\n  }\n\n  get rhsIsList() {\n    return (\n      this.tokens.assign && !this.tokens.asterisk && !this.tokens.secondaryName\n    );\n  }\n\n  get rhsType() {\n    if (this.rhsIsList) {\n      return this.list[0].tokens.value.type + \"-list\";\n    }\n    if (this.tokens.asterisk) {\n      return \"*\";\n    }\n    if (this.tokens.secondaryName) {\n      return this.tokens.secondaryName.type;\n    }\n    return null;\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { rhsType } = this;\n    return w.ts.wrap([\n      w.token(this.tokens.assign),\n      w.token(this.tokens.asterisk),\n      w.reference_token(this.tokens.secondaryName, this.parent),\n      w.token(this.tokens.open),\n      ...this.list.map((p) => {\n        return rhsType === \"identifier-list\"\n          ? w.identifier(p, this.parent)\n          : p.write(w);\n      }),\n      w.token(this.tokens.close),\n    ]);\n  }\n}\n\nexport class SimpleExtendedAttribute extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const name = tokeniser.consumeKind(\"identifier\");\n    if (name) {\n      return new SimpleExtendedAttribute({\n        source: tokeniser.source,\n        tokens: { name },\n        params: ExtendedAttributeParameters.parse(tokeniser),\n      });\n    }\n  }\n\n  constructor({ source, tokens, params }) {\n    super({ source, tokens });\n    params.parent = this;\n    Object.defineProperty(this, \"params\", { value: params });\n  }\n\n  get type() {\n    return \"extended-attribute\";\n  }\n  get name() {\n    return this.tokens.name.value;\n  }\n  get rhs() {\n    const { rhsType: type, tokens, list } = this.params;\n    if (!type) {\n      return null;\n    }\n    const value = this.params.rhsIsList\n      ? list\n      : this.params.tokens.secondaryName\n      ? unescape(tokens.secondaryName.value)\n      : null;\n    return { type, value };\n  }\n  get arguments() {\n    const { rhsIsList, list } = this.params;\n    if (!list || rhsIsList) {\n      return [];\n    }\n    return list;\n  }\n\n  *validate(defs) {\n    const { name } = this;\n    if (name === \"LegacyNoInterfaceObject\") {\n      const message = `\\`[LegacyNoInterfaceObject]\\` extended attribute is an \\\nundesirable feature that may be removed from Web IDL in the future. Refer to the \\\n[relevant upstream PR](https://github.com/whatwg/webidl/pull/609) for more \\\ninformation.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"no-nointerfaceobject\",\n        message,\n        { level: \"warning\" }\n      );\n    } else if (renamedLegacies.has(name)) {\n      const message = `\\`[${name}]\\` extended attribute is a legacy feature \\\nthat is now renamed to \\`[${renamedLegacies.get(name)}]\\`. Refer to the \\\n[relevant upstream PR](https://github.com/whatwg/webidl/pull/870) for more \\\ninformation.`;\n      yield validationError(this.tokens.name, this, \"renamed-legacy\", message, {\n        level: \"warning\",\n        autofix: renameLegacyExtendedAttribute(this),\n      });\n    }\n    for (const arg of this.arguments) {\n      yield* arg.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      w.ts.trivia(this.tokens.name.trivia),\n      w.ts.extendedAttribute(\n        w.ts.wrap([\n          w.ts.extendedAttributeReference(this.name),\n          this.params.write(w),\n        ])\n      ),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\n/**\n * @param {SimpleExtendedAttribute} extAttr\n */\nfunction renameLegacyExtendedAttribute(extAttr) {\n  return () => {\n    const { name } = extAttr;\n    extAttr.tokens.name.value = renamedLegacies.get(name);\n    if (name === \"TreatNullAs\") {\n      extAttr.params.tokens = {};\n    }\n  };\n}\n\n// Note: we parse something simpler than the official syntax. It's all that ever\n// seems to be used\nexport class ExtendedAttributes extends ArrayBase {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    tokens.open = tokeniser.consume(\"[\");\n    const ret = new ExtendedAttributes({ source: tokeniser.source, tokens });\n    if (!tokens.open) return ret;\n    ret.push(\n      ...list(tokeniser, {\n        parser: SimpleExtendedAttribute.parse,\n        listName: \"extended attribute\",\n      })\n    );\n    tokens.close =\n      tokeniser.consume(\"]\") ||\n      tokeniser.error(\n        \"Expected a closing token for the extended attribute list\"\n      );\n    if (!ret.length) {\n      tokeniser.unconsume(tokens.close.index);\n      tokeniser.error(\"An extended attribute list must not be empty\");\n    }\n    if (tokeniser.probe(\"[\")) {\n      tokeniser.error(\n        \"Illegal double extended attribute lists, consider merging them\"\n      );\n    }\n    return ret;\n  }\n\n  *validate(defs) {\n    for (const extAttr of this) {\n      yield* extAttr.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    if (!this.length) return \"\";\n    return w.ts.wrap([\n      w.token(this.tokens.open),\n      ...this.map((ea) => ea.write(w)),\n      w.token(this.tokens.close),\n    ]);\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  unescape,\n  type_with_extended_attributes,\n  return_type,\n  primitive_type,\n  autoParenter,\n} from \"./helpers.js\";\nimport { stringTypes, typeNameKeywords } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport { idlTypeIncludesDictionary } from \"../validators/helpers.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction generic_type(tokeniser, typeName) {\n  const base = tokeniser.consume(\n    \"FrozenArray\",\n    \"ObservableArray\",\n    \"Promise\",\n    \"sequence\",\n    \"record\"\n  );\n  if (!base) {\n    return;\n  }\n  const ret = autoParenter(\n    new Type({ source: tokeniser.source, tokens: { base } })\n  );\n  ret.tokens.open =\n    tokeniser.consume(\"<\") ||\n    tokeniser.error(`No opening bracket after ${base.value}`);\n  switch (base.value) {\n    case \"Promise\": {\n      if (tokeniser.probe(\"[\"))\n        tokeniser.error(\"Promise type cannot have extended attribute\");\n      const subtype =\n        return_type(tokeniser, typeName) ||\n        tokeniser.error(\"Missing Promise subtype\");\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"sequence\":\n    case \"FrozenArray\":\n    case \"ObservableArray\": {\n      const subtype =\n        type_with_extended_attributes(tokeniser, typeName) ||\n        tokeniser.error(`Missing ${base.value} subtype`);\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"record\": {\n      if (tokeniser.probe(\"[\"))\n        tokeniser.error(\"Record key cannot have extended attribute\");\n      const keyType =\n        tokeniser.consume(...stringTypes) ||\n        tokeniser.error(`Record key must be one of: ${stringTypes.join(\", \")}`);\n      const keyIdlType = new Type({\n        source: tokeniser.source,\n        tokens: { base: keyType },\n      });\n      keyIdlType.tokens.separator =\n        tokeniser.consume(\",\") ||\n        tokeniser.error(\"Missing comma after record key type\");\n      keyIdlType.type = typeName;\n      const valueType =\n        type_with_extended_attributes(tokeniser, typeName) ||\n        tokeniser.error(\"Error parsing generic type record\");\n      ret.subtype.push(keyIdlType, valueType);\n      break;\n    }\n  }\n  if (!ret.idlType) tokeniser.error(`Error parsing generic type ${base.value}`);\n  ret.tokens.close =\n    tokeniser.consume(\">\") ||\n    tokeniser.error(`Missing closing bracket after ${base.value}`);\n  return ret.this;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction type_suffix(tokeniser, obj) {\n  const nullable = tokeniser.consume(\"?\");\n  if (nullable) {\n    obj.tokens.nullable = nullable;\n  }\n  if (tokeniser.probe(\"?\")) tokeniser.error(\"Can't nullable more than once\");\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction single_type(tokeniser, typeName) {\n  let ret = generic_type(tokeniser, typeName) || primitive_type(tokeniser);\n  if (!ret) {\n    const base =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.consume(...stringTypes, ...typeNameKeywords);\n    if (!base) {\n      return;\n    }\n    ret = new Type({ source: tokeniser.source, tokens: { base } });\n    if (tokeniser.probe(\"<\"))\n      tokeniser.error(`Unsupported generic type ${base.value}`);\n  }\n  if (ret.generic === \"Promise\" && tokeniser.probe(\"?\")) {\n    tokeniser.error(\"Promise type cannot be nullable\");\n  }\n  ret.type = typeName || null;\n  type_suffix(tokeniser, ret);\n  if (ret.nullable && ret.idlType === \"any\")\n    tokeniser.error(\"Type `any` cannot be made nullable\");\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} type\n */\nfunction union_type(tokeniser, type) {\n  const tokens = {};\n  tokens.open = tokeniser.consume(\"(\");\n  if (!tokens.open) return;\n  const ret = autoParenter(new Type({ source: tokeniser.source, tokens }));\n  ret.type = type || null;\n  while (true) {\n    const typ =\n      type_with_extended_attributes(tokeniser, type) ||\n      tokeniser.error(\"No type after open parenthesis or 'or' in union type\");\n    if (typ.idlType === \"any\")\n      tokeniser.error(\"Type `any` cannot be included in a union type\");\n    if (typ.generic === \"Promise\")\n      tokeniser.error(\"Type `Promise` cannot be included in a union type\");\n    ret.subtype.push(typ);\n    const or = tokeniser.consume(\"or\");\n    if (or) {\n      typ.tokens.separator = or;\n    } else break;\n  }\n  if (ret.idlType.length < 2) {\n    tokeniser.error(\n      \"At least two types are expected in a union type but found less\"\n    );\n  }\n  tokens.close =\n    tokeniser.consume(\")\") || tokeniser.error(\"Unterminated union type\");\n  type_suffix(tokeniser, ret);\n  return ret.this;\n}\n\nexport class Type extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {string} typeName\n   */\n  static parse(tokeniser, typeName) {\n    return single_type(tokeniser, typeName) || union_type(tokeniser, typeName);\n  }\n\n  constructor({ source, tokens }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"subtype\", { value: [], writable: true });\n    this.extAttrs = new ExtendedAttributes({ source, tokens: {} });\n  }\n\n  get generic() {\n    if (this.subtype.length && this.tokens.base) {\n      return this.tokens.base.value;\n    }\n    return \"\";\n  }\n  get nullable() {\n    return Boolean(this.tokens.nullable);\n  }\n  get union() {\n    return Boolean(this.subtype.length) && !this.tokens.base;\n  }\n  get idlType() {\n    if (this.subtype.length) {\n      return this.subtype;\n    }\n    // Adding prefixes/postfixes for \"unrestricted float\", etc.\n    const name = [this.tokens.prefix, this.tokens.base, this.tokens.postfix]\n      .filter((t) => t)\n      .map((t) => t.value)\n      .join(\" \");\n    return unescape(name);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n\n    if (this.idlType === \"BufferSource\") {\n      // XXX: For now this is a hack. Consider moving parents' extAttrs into types as the spec says:\n      // https://webidl.spec.whatwg.org/#idl-annotated-types\n      for (const extAttrs of [this.extAttrs, this.parent?.extAttrs]) {\n        for (const extAttr of extAttrs) {\n          if (extAttr.name !== \"AllowShared\") {\n            continue;\n          }\n          const message = `\\`[AllowShared] BufferSource\\` is now replaced with AllowSharedBufferSource.`;\n          yield validationError(\n            this.tokens.base,\n            this,\n            \"migrate-allowshared\",\n            message,\n            { autofix: replaceAllowShared(this, extAttr, extAttrs) }\n          );\n        }\n      }\n    }\n\n    if (this.idlType === \"void\") {\n      const message = `\\`void\\` is now replaced by \\`undefined\\`. Refer to the \\\n[relevant GitHub issue](https://github.com/whatwg/webidl/issues/60) \\\nfor more information.`;\n      yield validationError(this.tokens.base, this, \"replace-void\", message, {\n        autofix: replaceVoid(this),\n      });\n    }\n\n    /*\n     * If a union is nullable, its subunions cannot include a dictionary\n     * If not, subunions may include dictionaries if each union is not nullable\n     */\n    const typedef = !this.union && defs.unique.get(this.idlType);\n    const target = this.union\n      ? this\n      : typedef && typedef.type === \"typedef\"\n      ? typedef.idlType\n      : undefined;\n    if (target && this.nullable) {\n      // do not allow any dictionary\n      const { reference } = idlTypeIncludesDictionary(target, defs) || {};\n      if (reference) {\n        const targetToken = (this.union ? reference : this).tokens.base;\n        const message = \"Nullable union cannot include a dictionary type.\";\n        yield validationError(\n          targetToken,\n          this,\n          \"no-nullable-union-dict\",\n          message\n        );\n      }\n    } else {\n      // allow some dictionary\n      for (const subtype of this.subtype) {\n        yield* subtype.validate(defs);\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const type_body = () => {\n      if (this.union || this.generic) {\n        return w.ts.wrap([\n          w.token(this.tokens.base, w.ts.generic),\n          w.token(this.tokens.open),\n          ...this.subtype.map((t) => t.write(w)),\n          w.token(this.tokens.close),\n        ]);\n      }\n      const firstToken = this.tokens.prefix || this.tokens.base;\n      const prefix = this.tokens.prefix\n        ? [this.tokens.prefix.value, w.ts.trivia(this.tokens.base.trivia)]\n        : [];\n      const ref = w.reference(\n        w.ts.wrap([\n          ...prefix,\n          this.tokens.base.value,\n          w.token(this.tokens.postfix),\n        ]),\n        {\n          unescaped: /** @type {string} (because it's not union) */ (\n            this.idlType\n          ),\n          context: this,\n        }\n      );\n      return w.ts.wrap([w.ts.trivia(firstToken.trivia), ref]);\n    };\n    return w.ts.wrap([\n      this.extAttrs.write(w),\n      type_body(),\n      w.token(this.tokens.nullable),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\n/**\n * @param {Type} type\n * @param {import(\"./extended-attributes.js\").SimpleExtendedAttribute} extAttr\n * @param {ExtendedAttributes} extAttrs\n */\nfunction replaceAllowShared(type, extAttr, extAttrs) {\n  return () => {\n    const index = extAttrs.indexOf(extAttr);\n    extAttrs.splice(index, 1);\n    if (!extAttrs.length && type.tokens.base.trivia.match(/^\\s$/)) {\n      type.tokens.base.trivia = \"\"; // (let's not remove comments)\n    }\n\n    type.tokens.base.value = \"AllowSharedBufferSource\";\n  };\n}\n\n/**\n * @param {Type} type\n */\nfunction replaceVoid(type) {\n  return () => {\n    type.tokens.base.value = \"undefined\";\n  };\n}\n","import { Base } from \"./base.js\";\nimport { const_data, const_value } from \"./helpers.js\";\n\nexport class Default extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const assign = tokeniser.consume(\"=\");\n    if (!assign) {\n      return null;\n    }\n    const def =\n      const_value(tokeniser) ||\n      tokeniser.consumeKind(\"string\") ||\n      tokeniser.consume(\"null\", \"[\", \"{\") ||\n      tokeniser.error(\"No value for default\");\n    const expression = [def];\n    if (def.value === \"[\") {\n      const close =\n        tokeniser.consume(\"]\") ||\n        tokeniser.error(\"Default sequence value must be empty\");\n      expression.push(close);\n    } else if (def.value === \"{\") {\n      const close =\n        tokeniser.consume(\"}\") ||\n        tokeniser.error(\"Default dictionary value must be empty\");\n      expression.push(close);\n    }\n    return new Default({\n      source: tokeniser.source,\n      tokens: { assign },\n      expression,\n    });\n  }\n\n  constructor({ source, tokens, expression }) {\n    super({ source, tokens });\n    expression.parent = this;\n    Object.defineProperty(this, \"expression\", { value: expression });\n  }\n\n  get type() {\n    return const_data(this.expression[0]).type;\n  }\n  get value() {\n    return const_data(this.expression[0]).value;\n  }\n  get negative() {\n    return const_data(this.expression[0]).negative;\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      w.token(this.tokens.assign),\n      ...this.expression.map((t) => w.token(t)),\n    ]);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { Default } from \"./default.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport {\n  unescape,\n  type_with_extended_attributes,\n  autoParenter,\n  getFirstToken,\n} from \"./helpers.js\";\nimport { argumentNameKeywords, Tokeniser } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport {\n  idlTypeIncludesDictionary,\n  dictionaryIncludesRequiredField,\n} from \"../validators/helpers.js\";\n\nexport class Argument extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(\n      new Argument({ source: tokeniser.source, tokens })\n    );\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.optional = tokeniser.consume(\"optional\");\n    ret.idlType = type_with_extended_attributes(tokeniser, \"argument-type\");\n    if (!ret.idlType) {\n      return tokeniser.unconsume(start_position);\n    }\n    if (!tokens.optional) {\n      tokens.variadic = tokeniser.consume(\"...\");\n    }\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.consume(...argumentNameKeywords);\n    if (!tokens.name) {\n      return tokeniser.unconsume(start_position);\n    }\n    ret.default = tokens.optional ? Default.parse(tokeniser) : null;\n    return ret.this;\n  }\n\n  get type() {\n    return \"argument\";\n  }\n  get optional() {\n    return !!this.tokens.optional;\n  }\n  get variadic() {\n    return !!this.tokens.variadic;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  /**\n   * @param {import(\"../validator.js\").Definitions} defs\n   */\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    yield* this.idlType.validate(defs);\n    const result = idlTypeIncludesDictionary(this.idlType, defs, {\n      useNullableInner: true,\n    });\n    if (result) {\n      if (this.idlType.nullable) {\n        const message = `Dictionary arguments cannot be nullable.`;\n        yield validationError(\n          this.tokens.name,\n          this,\n          \"no-nullable-dict-arg\",\n          message\n        );\n      } else if (!this.optional) {\n        if (\n          this.parent &&\n          !dictionaryIncludesRequiredField(result.dictionary, defs) &&\n          isLastRequiredArgument(this)\n        ) {\n          const message = `Dictionary argument must be optional if it has no required fields`;\n          yield validationError(\n            this.tokens.name,\n            this,\n            \"dict-arg-optional\",\n            message,\n            {\n              autofix: autofixDictionaryArgumentOptionality(this),\n            }\n          );\n        }\n      } else if (!this.default) {\n        const message = `Optional dictionary arguments must have a default value of \\`{}\\`.`;\n        yield validationError(\n          this.tokens.name,\n          this,\n          \"dict-arg-default\",\n          message,\n          {\n            autofix: autofixOptionalDictionaryDefaultValue(this),\n          }\n        );\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      this.extAttrs.write(w),\n      w.token(this.tokens.optional),\n      w.ts.type(this.idlType.write(w)),\n      w.token(this.tokens.variadic),\n      w.name_token(this.tokens.name, { data: this }),\n      this.default ? this.default.write(w) : \"\",\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\n/**\n * @param {Argument} arg\n */\nfunction isLastRequiredArgument(arg) {\n  const list = arg.parent.arguments || arg.parent.list;\n  const index = list.indexOf(arg);\n  const requiredExists = list.slice(index + 1).some((a) => !a.optional);\n  return !requiredExists;\n}\n\n/**\n * @param {Argument} arg\n */\nfunction autofixDictionaryArgumentOptionality(arg) {\n  return () => {\n    const firstToken = getFirstToken(arg.idlType);\n    arg.tokens.optional = {\n      ...firstToken,\n      type: \"optional\",\n      value: \"optional\",\n    };\n    firstToken.trivia = \" \";\n    autofixOptionalDictionaryDefaultValue(arg)();\n  };\n}\n\n/**\n * @param {Argument} arg\n */\nfunction autofixOptionalDictionaryDefaultValue(arg) {\n  return () => {\n    arg.default = Default.parse(new Tokeniser(\" = {}\"));\n  };\n}\n","import { Base } from \"./base.js\";\nimport {\n  return_type,\n  argument_list,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\nexport class Operation extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"../tokeniser.js\").Token} [options.special]\n   * @param {import(\"../tokeniser.js\").Token} [options.regular]\n   */\n  static parse(tokeniser, { special, regular } = {}) {\n    const tokens = { special };\n    const ret = autoParenter(\n      new Operation({ source: tokeniser.source, tokens })\n    );\n    if (special && special.value === \"stringifier\") {\n      tokens.termination = tokeniser.consume(\";\");\n      if (tokens.termination) {\n        ret.arguments = [];\n        return ret;\n      }\n    }\n    if (!special && !regular) {\n      tokens.special = tokeniser.consume(\"getter\", \"setter\", \"deleter\");\n    }\n    ret.idlType =\n      return_type(tokeniser) || tokeniser.error(\"Missing return type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") || tokeniser.consume(\"includes\");\n    tokens.open =\n      tokeniser.consume(\"(\") || tokeniser.error(\"Invalid operation\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close =\n      tokeniser.consume(\")\") || tokeniser.error(\"Unterminated operation\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated operation, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"operation\";\n  }\n  get name() {\n    const { name } = this.tokens;\n    if (!name) {\n      return \"\";\n    }\n    return unescape(name.value);\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    if (!this.name && [\"\", \"static\"].includes(this.special)) {\n      const message = `Regular or static operations must have both a return type and an identifier.`;\n      yield validationError(this.tokens.open, this, \"incomplete-op\", message);\n    }\n    if (this.idlType) {\n      yield* this.idlType.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    const body = this.idlType\n      ? [\n          w.ts.type(this.idlType.write(w)),\n          w.name_token(this.tokens.name, { data: this, parent }),\n          w.token(this.tokens.open),\n          w.ts.wrap(this.arguments.map((arg) => arg.write(w))),\n          w.token(this.tokens.close),\n        ]\n      : [];\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        this.tokens.name\n          ? w.token(this.tokens.special)\n          : w.token(this.tokens.special, w.ts.nameless, { data: this, parent }),\n        ...body,\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent }\n    );\n  }\n}\n","import { validationError } from \"../error.js\";\nimport {\n  idlTypeIncludesDictionary,\n  idlTypeIncludesEnforceRange,\n} from \"../validators/helpers.js\";\nimport { Base } from \"./base.js\";\nimport {\n  type_with_extended_attributes,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\n\nexport class Attribute extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"../tokeniser.js\").Token} [options.special]\n   * @param {boolean} [options.noInherit]\n   * @param {boolean} [options.readonly]\n   */\n  static parse(\n    tokeniser,\n    { special, noInherit = false, readonly = false } = {}\n  ) {\n    const start_position = tokeniser.position;\n    const tokens = { special };\n    const ret = autoParenter(\n      new Attribute({ source: tokeniser.source, tokens })\n    );\n    if (!special && !noInherit) {\n      tokens.special = tokeniser.consume(\"inherit\");\n    }\n    if (ret.special === \"inherit\" && tokeniser.probe(\"readonly\")) {\n      tokeniser.error(\"Inherited attributes cannot be read-only\");\n    }\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (readonly && !tokens.readonly && tokeniser.probe(\"attribute\")) {\n      tokeniser.error(\"Attributes must be readonly in this context\");\n    }\n    tokens.base = tokeniser.consume(\"attribute\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n    ret.idlType =\n      type_with_extended_attributes(tokeniser, \"attribute-type\") ||\n      tokeniser.error(\"Attribute lacks a type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.consume(\"async\", \"required\") ||\n      tokeniser.error(\"Attribute lacks a name\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated attribute, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"attribute\";\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    yield* this.idlType.validate(defs);\n\n    if ([\"sequence\", \"record\"].includes(this.idlType.generic)) {\n      const message = `Attributes cannot accept ${this.idlType.generic} types.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"attr-invalid-type\",\n        message\n      );\n    }\n\n    {\n      const { reference } = idlTypeIncludesDictionary(this.idlType, defs) || {};\n      if (reference) {\n        const targetToken = (this.idlType.union ? reference : this.idlType)\n          .tokens.base;\n        const message = \"Attributes cannot accept dictionary types.\";\n        yield validationError(targetToken, this, \"attr-invalid-type\", message);\n      }\n    }\n\n    if (this.readonly) {\n      if (idlTypeIncludesEnforceRange(this.idlType, defs)) {\n        const targetToken = this.idlType.tokens.base;\n        const message =\n          \"Readonly attributes cannot accept [EnforceRange] extended attribute.\";\n        yield validationError(targetToken, this, \"attr-invalid-type\", message);\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.special),\n        w.token(this.tokens.readonly),\n        w.token(this.tokens.base),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this, parent }),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent }\n    );\n  }\n}\n","import { Type } from \"./type.js\";\nimport { Argument } from \"./argument.js\";\nimport {\n  ExtendedAttributes,\n  SimpleExtendedAttribute,\n} from \"./extended-attributes.js\";\nimport { Operation } from \"./operation.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Tokeniser } from \"../tokeniser.js\";\n\n/**\n * @param {string} identifier\n */\nexport function unescape(identifier) {\n  return identifier.startsWith(\"_\") ? identifier.slice(1) : identifier;\n}\n\n/**\n * Parses comma-separated list\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {object} args\n * @param {Function} args.parser parser function for each item\n * @param {boolean} [args.allowDangler] whether to allow dangling comma\n * @param {string} [args.listName] the name to be shown on error messages\n */\nexport function list(tokeniser, { parser, allowDangler, listName = \"list\" }) {\n  const first = parser(tokeniser);\n  if (!first) {\n    return [];\n  }\n  first.tokens.separator = tokeniser.consume(\",\");\n  const items = [first];\n  while (first.tokens.separator) {\n    const item = parser(tokeniser);\n    if (!item) {\n      if (!allowDangler) {\n        tokeniser.error(`Trailing comma in ${listName}`);\n      }\n      break;\n    }\n    item.tokens.separator = tokeniser.consume(\",\");\n    items.push(item);\n    if (!item.tokens.separator) break;\n  }\n  return items;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function const_value(tokeniser) {\n  return (\n    tokeniser.consumeKind(\"decimal\", \"integer\") ||\n    tokeniser.consume(\"true\", \"false\", \"Infinity\", \"-Infinity\", \"NaN\")\n  );\n}\n\n/**\n * @param {object} token\n * @param {string} token.type\n * @param {string} token.value\n */\nexport function const_data({ type, value }) {\n  switch (type) {\n    case \"decimal\":\n    case \"integer\":\n      return { type: \"number\", value };\n    case \"string\":\n      return { type: \"string\", value: value.slice(1, -1) };\n  }\n\n  switch (value) {\n    case \"true\":\n    case \"false\":\n      return { type: \"boolean\", value: value === \"true\" };\n    case \"Infinity\":\n    case \"-Infinity\":\n      return { type: \"Infinity\", negative: value.startsWith(\"-\") };\n    case \"[\":\n      return { type: \"sequence\", value: [] };\n    case \"{\":\n      return { type: \"dictionary\" };\n    default:\n      return { type: value };\n  }\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function primitive_type(tokeniser) {\n  function integer_type() {\n    const prefix = tokeniser.consume(\"unsigned\");\n    const base = tokeniser.consume(\"short\", \"long\");\n    if (base) {\n      const postfix = tokeniser.consume(\"long\");\n      return new Type({ source, tokens: { prefix, base, postfix } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse integer type\");\n  }\n\n  function decimal_type() {\n    const prefix = tokeniser.consume(\"unrestricted\");\n    const base = tokeniser.consume(\"float\", \"double\");\n    if (base) {\n      return new Type({ source, tokens: { prefix, base } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse float type\");\n  }\n\n  const { source } = tokeniser;\n  const num_type = integer_type() || decimal_type();\n  if (num_type) return num_type;\n  const base = tokeniser.consume(\n    \"bigint\",\n    \"boolean\",\n    \"byte\",\n    \"octet\",\n    \"undefined\"\n  );\n  if (base) {\n    return new Type({ source, tokens: { base } });\n  }\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function argument_list(tokeniser) {\n  return list(tokeniser, {\n    parser: Argument.parse,\n    listName: \"arguments list\",\n  });\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string=} typeName (TODO: See Type.type for more details)\n */\nexport function type_with_extended_attributes(tokeniser, typeName) {\n  const extAttrs = ExtendedAttributes.parse(tokeniser);\n  const ret = Type.parse(tokeniser, typeName);\n  if (ret) autoParenter(ret).extAttrs = extAttrs;\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string=} typeName (TODO: See Type.type for more details)\n */\nexport function return_type(tokeniser, typeName) {\n  const typ = Type.parse(tokeniser, typeName || \"return-type\");\n  if (typ) {\n    return typ;\n  }\n  const voidToken = tokeniser.consume(\"void\");\n  if (voidToken) {\n    const ret = new Type({\n      source: tokeniser.source,\n      tokens: { base: voidToken },\n    });\n    ret.type = \"return-type\";\n    return ret;\n  }\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function stringifier(tokeniser) {\n  const special = tokeniser.consume(\"stringifier\");\n  if (!special) return;\n  const member =\n    Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"Unterminated stringifier\");\n  return member;\n}\n\n/**\n * @param {string} str\n */\nexport function getLastIndentation(str) {\n  const lines = str.split(\"\\n\");\n  // the first line visually binds to the preceding token\n  if (lines.length) {\n    const match = lines[lines.length - 1].match(/^\\s+/);\n    if (match) {\n      return match[0];\n    }\n  }\n  return \"\";\n}\n\n/**\n * @param {string} parentTrivia\n */\nexport function getMemberIndentation(parentTrivia) {\n  const indentation = getLastIndentation(parentTrivia);\n  const indentCh = indentation.includes(\"\\t\") ? \"\\t\" : \"  \";\n  return indentation + indentCh;\n}\n\n/**\n * @param {import(\"./interface.js\").Interface} def\n */\nexport function autofixAddExposedWindow(def) {\n  return () => {\n    if (def.extAttrs.length) {\n      const tokeniser = new Tokeniser(\"Exposed=Window,\");\n      const exposed = SimpleExtendedAttribute.parse(tokeniser);\n      exposed.tokens.separator = tokeniser.consume(\",\");\n      const existing = def.extAttrs[0];\n      if (!/^\\s/.test(existing.tokens.name.trivia)) {\n        existing.tokens.name.trivia = ` ${existing.tokens.name.trivia}`;\n      }\n      def.extAttrs.unshift(exposed);\n    } else {\n      autoParenter(def).extAttrs = ExtendedAttributes.parse(\n        new Tokeniser(\"[Exposed=Window]\")\n      );\n      const trivia = def.tokens.base.trivia;\n      def.extAttrs.tokens.open.trivia = trivia;\n      def.tokens.base.trivia = `\\n${getLastIndentation(trivia)}`;\n    }\n  };\n}\n\n/**\n * Get the first syntax token for the given IDL object.\n * @param {*} data\n */\nexport function getFirstToken(data) {\n  if (data.extAttrs.length) {\n    return data.extAttrs.tokens.open;\n  }\n  if (data.type === \"operation\" && !data.special) {\n    return getFirstToken(data.idlType);\n  }\n  const tokens = Object.values(data.tokens).sort((x, y) => x.index - y.index);\n  return tokens[0];\n}\n\n/**\n * @template T\n * @param {T[]} array\n * @param {(item: T) => boolean} predicate\n */\nexport function findLastIndex(array, predicate) {\n  const index = array.slice().reverse().findIndex(predicate);\n  if (index === -1) {\n    return index;\n  }\n  return array.length - index - 1;\n}\n\n/**\n * Returns a proxy that auto-assign `parent` field.\n * @template {Record<string | symbol, any>} T\n * @param {T} data\n * @param {*} [parent] The object that will be assigned to `parent`.\n *                     If absent, it will be `data` by default.\n * @return {T}\n */\nexport function autoParenter(data, parent) {\n  if (!parent) {\n    // Defaults to `data` unless specified otherwise.\n    parent = data;\n  }\n  if (!data) {\n    // This allows `autoParenter(undefined)` which again allows\n    // `autoParenter(parse())` where the function may return nothing.\n    return data;\n  }\n  const proxy = new Proxy(data, {\n    get(target, p) {\n      const value = target[p];\n      if (Array.isArray(value) && p !== \"source\") {\n        // Wraps the array so that any added items will also automatically\n        // get their `parent` values.\n        return autoParenter(value, target);\n      }\n      return value;\n    },\n    set(target, p, value) {\n      // @ts-ignore https://github.com/microsoft/TypeScript/issues/47357\n      target[p] = value;\n      if (!value) {\n        return true;\n      } else if (Array.isArray(value)) {\n        // Assigning an array will add `parent` to its items.\n        for (const item of value) {\n          if (typeof item.parent !== \"undefined\") {\n            item.parent = parent;\n          }\n        }\n      } else if (typeof value.parent !== \"undefined\") {\n        value.parent = parent;\n      }\n      return true;\n    },\n  });\n  return proxy;\n}\n","import { syntaxError } from \"./error.js\";\nimport { unescape } from \"./productions/helpers.js\";\n\n// These regular expressions use the sticky flag so they will only match at\n// the current location (ie. the offset of lastIndex).\nconst tokenRe = {\n  // This expression uses a lookahead assertion to catch false matches\n  // against integers early.\n  decimal:\n    /-?(?=[0-9]*\\.|[0-9]+[eE])(([0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+)([Ee][-+]?[0-9]+)?|[0-9]+[Ee][-+]?[0-9]+)/y,\n  integer: /-?(0([Xx][0-9A-Fa-f]+|[0-7]*)|[1-9][0-9]*)/y,\n  identifier: /[_-]?[A-Za-z][0-9A-Z_a-z-]*/y,\n  string: /\"[^\"]*\"/y,\n  whitespace: /[\\t\\n\\r ]+/y,\n  comment: /\\/\\/.*|\\/\\*[\\s\\S]*?\\*\\//y,\n  other: /[^\\t\\n\\r 0-9A-Za-z]/y,\n};\n\nexport const typeNameKeywords = [\n  \"ArrayBuffer\",\n  \"SharedArrayBuffer\",\n  \"DataView\",\n  \"Int8Array\",\n  \"Int16Array\",\n  \"Int32Array\",\n  \"Uint8Array\",\n  \"Uint16Array\",\n  \"Uint32Array\",\n  \"Uint8ClampedArray\",\n  \"BigInt64Array\",\n  \"BigUint64Array\",\n  \"Float32Array\",\n  \"Float64Array\",\n  \"any\",\n  \"object\",\n  \"symbol\",\n];\n\nexport const stringTypes = [\"ByteString\", \"DOMString\", \"USVString\"];\n\nexport const argumentNameKeywords = [\n  \"async\",\n  \"attribute\",\n  \"callback\",\n  \"const\",\n  \"constructor\",\n  \"deleter\",\n  \"dictionary\",\n  \"enum\",\n  \"getter\",\n  \"includes\",\n  \"inherit\",\n  \"interface\",\n  \"iterable\",\n  \"maplike\",\n  \"namespace\",\n  \"partial\",\n  \"required\",\n  \"setlike\",\n  \"setter\",\n  \"static\",\n  \"stringifier\",\n  \"typedef\",\n  \"unrestricted\",\n];\n\nconst nonRegexTerminals = [\n  \"-Infinity\",\n  \"FrozenArray\",\n  \"Infinity\",\n  \"NaN\",\n  \"ObservableArray\",\n  \"Promise\",\n  \"bigint\",\n  \"boolean\",\n  \"byte\",\n  \"double\",\n  \"false\",\n  \"float\",\n  \"long\",\n  \"mixin\",\n  \"null\",\n  \"octet\",\n  \"optional\",\n  \"or\",\n  \"readonly\",\n  \"record\",\n  \"sequence\",\n  \"short\",\n  \"true\",\n  \"undefined\",\n  \"unsigned\",\n  \"void\",\n].concat(argumentNameKeywords, stringTypes, typeNameKeywords);\n\nconst punctuations = [\n  \"(\",\n  \")\",\n  \",\",\n  \"...\",\n  \":\",\n  \";\",\n  \"<\",\n  \"=\",\n  \">\",\n  \"?\",\n  \"*\",\n  \"[\",\n  \"]\",\n  \"{\",\n  \"}\",\n];\n\nconst reserved = [\n  // \"constructor\" is now a keyword\n  \"_constructor\",\n  \"toString\",\n  \"_toString\",\n];\n\n/**\n * @typedef {ArrayItemType<ReturnType<typeof tokenise>>} Token\n * @param {string} str\n */\nfunction tokenise(str) {\n  const tokens = [];\n  let lastCharIndex = 0;\n  let trivia = \"\";\n  let line = 1;\n  let index = 0;\n  while (lastCharIndex < str.length) {\n    const nextChar = str.charAt(lastCharIndex);\n    let result = -1;\n\n    if (/[\\t\\n\\r ]/.test(nextChar)) {\n      result = attemptTokenMatch(\"whitespace\", { noFlushTrivia: true });\n    } else if (nextChar === \"/\") {\n      result = attemptTokenMatch(\"comment\", { noFlushTrivia: true });\n    }\n\n    if (result !== -1) {\n      const currentTrivia = tokens.pop().value;\n      line += (currentTrivia.match(/\\n/g) || []).length;\n      trivia += currentTrivia;\n      index -= 1;\n    } else if (/[-0-9.A-Z_a-z]/.test(nextChar)) {\n      result = attemptTokenMatch(\"decimal\");\n      if (result === -1) {\n        result = attemptTokenMatch(\"integer\");\n      }\n      if (result === -1) {\n        result = attemptTokenMatch(\"identifier\");\n        const lastIndex = tokens.length - 1;\n        const token = tokens[lastIndex];\n        if (result !== -1) {\n          if (reserved.includes(token.value)) {\n            const message = `${unescape(\n              token.value\n            )} is a reserved identifier and must not be used.`;\n            throw new WebIDLParseError(\n              syntaxError(tokens, lastIndex, null, message)\n            );\n          } else if (nonRegexTerminals.includes(token.value)) {\n            token.type = \"inline\";\n          }\n        }\n      }\n    } else if (nextChar === '\"') {\n      result = attemptTokenMatch(\"string\");\n    }\n\n    for (const punctuation of punctuations) {\n      if (str.startsWith(punctuation, lastCharIndex)) {\n        tokens.push({\n          type: \"inline\",\n          value: punctuation,\n          trivia,\n          line,\n          index,\n        });\n        trivia = \"\";\n        lastCharIndex += punctuation.length;\n        result = lastCharIndex;\n        break;\n      }\n    }\n\n    // other as the last try\n    if (result === -1) {\n      result = attemptTokenMatch(\"other\");\n    }\n    if (result === -1) {\n      throw new Error(\"Token stream not progressing\");\n    }\n    lastCharIndex = result;\n    index += 1;\n  }\n\n  // remaining trivia as eof\n  tokens.push({\n    type: \"eof\",\n    value: \"\",\n    trivia,\n    line,\n    index,\n  });\n\n  return tokens;\n\n  /**\n   * @param {keyof typeof tokenRe} type\n   * @param {object} options\n   * @param {boolean} [options.noFlushTrivia]\n   */\n  function attemptTokenMatch(type, { noFlushTrivia } = {}) {\n    const re = tokenRe[type];\n    re.lastIndex = lastCharIndex;\n    const result = re.exec(str);\n    if (result) {\n      tokens.push({ type, value: result[0], trivia, line, index });\n      if (!noFlushTrivia) {\n        trivia = \"\";\n      }\n      return re.lastIndex;\n    }\n    return -1;\n  }\n}\n\nexport class Tokeniser {\n  /**\n   * @param {string} idl\n   */\n  constructor(idl) {\n    this.source = tokenise(idl);\n    this.position = 0;\n  }\n\n  /**\n   * @param {string} message\n   * @return {never}\n   */\n  error(message) {\n    throw new WebIDLParseError(\n      syntaxError(this.source, this.position, this.current, message)\n    );\n  }\n\n  /**\n   * @param {string} type\n   */\n  probeKind(type) {\n    return (\n      this.source.length > this.position &&\n      this.source[this.position].type === type\n    );\n  }\n\n  /**\n   * @param {string} value\n   */\n  probe(value) {\n    return (\n      this.probeKind(\"inline\") && this.source[this.position].value === value\n    );\n  }\n\n  /**\n   * @param {...string} candidates\n   */\n  consumeKind(...candidates) {\n    for (const type of candidates) {\n      if (!this.probeKind(type)) continue;\n      const token = this.source[this.position];\n      this.position++;\n      return token;\n    }\n  }\n\n  /**\n   * @param {...string} candidates\n   */\n  consume(...candidates) {\n    if (!this.probeKind(\"inline\")) return;\n    const token = this.source[this.position];\n    for (const value of candidates) {\n      if (token.value !== value) continue;\n      this.position++;\n      return token;\n    }\n  }\n\n  /**\n   * @param {string} value\n   */\n  consumeIdentifier(value) {\n    if (!this.probeKind(\"identifier\")) {\n      return;\n    }\n    if (this.source[this.position].value !== value) {\n      return;\n    }\n    return this.consumeKind(\"identifier\");\n  }\n\n  /**\n   * @param {number} position\n   */\n  unconsume(position) {\n    this.position = position;\n  }\n}\n\nexport class WebIDLParseError extends Error {\n  /**\n   * @param {object} options\n   * @param {string} options.message\n   * @param {string} options.bareMessage\n   * @param {string} options.context\n   * @param {number} options.line\n   * @param {*} options.sourceName\n   * @param {string} options.input\n   * @param {*[]} options.tokens\n   */\n  constructor({\n    message,\n    bareMessage,\n    context,\n    line,\n    sourceName,\n    input,\n    tokens,\n  }) {\n    super(message);\n\n    this.name = \"WebIDLParseError\"; // not to be mangled\n    this.bareMessage = bareMessage;\n    this.context = context;\n    this.line = line;\n    this.sourceName = sourceName;\n    this.input = input;\n    this.tokens = tokens;\n  }\n}\n","import { list, unescape, autoParenter } from \"./helpers.js\";\nimport { WrappedToken } from \"./token.js\";\nimport { Base } from \"./base.js\";\n\nexport class EnumValue extends WrappedToken {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const value = tokeniser.consumeKind(\"string\");\n    if (value) {\n      return new EnumValue({ source: tokeniser.source, tokens: { value } });\n    }\n  }\n\n  get type() {\n    return \"enum-value\";\n  }\n  get value() {\n    return super.value.slice(1, -1);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.wrap([\n      w.ts.trivia(this.tokens.value.trivia),\n      w.ts.definition(\n        w.ts.wrap(['\"', w.ts.name(this.value, { data: this, parent }), '\"']),\n        { data: this, parent }\n      ),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\nexport class Enum extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"enum\");\n    if (!tokens.base) {\n      return;\n    }\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"No name for enum\");\n    const ret = autoParenter(new Enum({ source: tokeniser.source, tokens }));\n    tokeniser.current = ret.this;\n    tokens.open = tokeniser.consume(\"{\") || tokeniser.error(\"Bodyless enum\");\n    ret.values = list(tokeniser, {\n      parser: EnumValue.parse,\n      allowDangler: true,\n      listName: \"enumeration\",\n    });\n    if (tokeniser.probeKind(\"string\")) {\n      tokeniser.error(\"No comma between enum values\");\n    }\n    tokens.close =\n      tokeniser.consume(\"}\") || tokeniser.error(\"Unexpected value in enum\");\n    if (!ret.values.length) {\n      tokeniser.error(\"No value in enum\");\n    }\n    tokens.termination =\n      tokeniser.consume(\";\") || tokeniser.error(\"No semicolon after enum\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"enum\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.name_token(this.tokens.name, { data: this }),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.values.map((v) => v.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this }\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape } from \"./helpers.js\";\n\nexport class Includes extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const target = tokeniser.consumeKind(\"identifier\");\n    if (!target) {\n      return;\n    }\n    const tokens = { target };\n    tokens.includes = tokeniser.consume(\"includes\");\n    if (!tokens.includes) {\n      tokeniser.unconsume(target.index);\n      return;\n    }\n    tokens.mixin =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Incomplete includes statement\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"No terminating ; for includes statement\");\n    return new Includes({ source: tokeniser.source, tokens });\n  }\n\n  get type() {\n    return \"includes\";\n  }\n  get target() {\n    return unescape(this.tokens.target.value);\n  }\n  get includes() {\n    return unescape(this.tokens.mixin.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.reference_token(this.tokens.target, this),\n        w.token(this.tokens.includes),\n        w.reference_token(this.tokens.mixin, this),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this }\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  type_with_extended_attributes,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\n\nexport class Typedef extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(new Typedef({ source: tokeniser.source, tokens }));\n    tokens.base = tokeniser.consume(\"typedef\");\n    if (!tokens.base) {\n      return;\n    }\n    ret.idlType =\n      type_with_extended_attributes(tokeniser, \"typedef-type\") ||\n      tokeniser.error(\"Typedef lacks a type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Typedef lacks a name\");\n    tokeniser.current = ret.this;\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated typedef, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"typedef\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this }),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this }\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  return_type,\n  argument_list,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\n\nexport class CallbackFunction extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, base) {\n    const tokens = { base };\n    const ret = autoParenter(\n      new CallbackFunction({ source: tokeniser.source, tokens })\n    );\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Callback lacks a name\");\n    tokeniser.current = ret.this;\n    tokens.assign =\n      tokeniser.consume(\"=\") || tokeniser.error(\"Callback lacks an assignment\");\n    ret.idlType =\n      return_type(tokeniser) || tokeniser.error(\"Callback lacks a return type\");\n    tokens.open =\n      tokeniser.consume(\"(\") ||\n      tokeniser.error(\"Callback lacks parentheses for arguments\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close =\n      tokeniser.consume(\")\") || tokeniser.error(\"Unterminated callback\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated callback, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"callback\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    yield* this.idlType.validate(defs);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.name_token(this.tokens.name, { data: this }),\n        w.token(this.tokens.assign),\n        w.ts.type(this.idlType.write(w)),\n        w.token(this.tokens.open),\n        ...this.arguments.map((arg) => arg.write(w)),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this }\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { unescape, autoParenter } from \"./helpers.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction inheritance(tokeniser) {\n  const colon = tokeniser.consume(\":\");\n  if (!colon) {\n    return {};\n  }\n  const inheritance =\n    tokeniser.consumeKind(\"identifier\") ||\n    tokeniser.error(\"Inheritance lacks a type\");\n  return { colon, inheritance };\n}\n\n/**\n * Parser callback.\n * @callback ParserCallback\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {...*} args\n */\n\n/**\n * A parser callback and optional option object.\n * @typedef AllowedMember\n * @type {[ParserCallback, object?]}\n */\n\nexport class Container extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {*} instance TODO: This should be {T extends Container}, but see https://github.com/microsoft/TypeScript/issues/4628\n   * @param {*} args\n   */\n  static parse(tokeniser, instance, { inheritable, allowedMembers }) {\n    const { tokens, type } = instance;\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(`Missing name in ${type}`);\n    tokeniser.current = instance;\n    instance = autoParenter(instance);\n    if (inheritable) {\n      Object.assign(tokens, inheritance(tokeniser));\n    }\n    tokens.open = tokeniser.consume(\"{\") || tokeniser.error(`Bodyless ${type}`);\n    instance.members = [];\n    while (true) {\n      tokens.close = tokeniser.consume(\"}\");\n      if (tokens.close) {\n        tokens.termination =\n          tokeniser.consume(\";\") ||\n          tokeniser.error(`Missing semicolon after ${type}`);\n        return instance.this;\n      }\n      const ea = ExtendedAttributes.parse(tokeniser);\n      let mem;\n      for (const [parser, ...args] of allowedMembers) {\n        mem = autoParenter(parser(tokeniser, ...args));\n        if (mem) {\n          break;\n        }\n      }\n      if (!mem) {\n        tokeniser.error(\"Unknown member\");\n      }\n      mem.extAttrs = ea;\n      instance.members.push(mem.this);\n    }\n  }\n\n  get partial() {\n    return !!this.tokens.partial;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get inheritance() {\n    if (!this.tokens.inheritance) {\n      return null;\n    }\n    return unescape(this.tokens.inheritance.value);\n  }\n\n  *validate(defs) {\n    for (const member of this.members) {\n      if (member.validate) {\n        yield* member.validate(defs);\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const inheritance = () => {\n      if (!this.tokens.inheritance) {\n        return \"\";\n      }\n      return w.ts.wrap([\n        w.token(this.tokens.colon),\n        w.ts.trivia(this.tokens.inheritance.trivia),\n        w.ts.inheritance(\n          w.reference(this.tokens.inheritance.value, { context: this })\n        ),\n      ]);\n    };\n\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.callback),\n        w.token(this.tokens.partial),\n        w.token(this.tokens.base),\n        w.token(this.tokens.mixin),\n        w.name_token(this.tokens.name, { data: this }),\n        inheritance(),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.members.map((m) => m.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this }\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport { Type } from \"./type.js\";\nimport {\n  const_data,\n  const_value,\n  primitive_type,\n  autoParenter,\n  unescape,\n} from \"./helpers.js\";\n\nexport class Constant extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"const\");\n    if (!tokens.base) {\n      return;\n    }\n    let idlType = primitive_type(tokeniser);\n    if (!idlType) {\n      const base =\n        tokeniser.consumeKind(\"identifier\") ||\n        tokeniser.error(\"Const lacks a type\");\n      idlType = new Type({ source: tokeniser.source, tokens: { base } });\n    }\n    if (tokeniser.probe(\"?\")) {\n      tokeniser.error(\"Unexpected nullable constant type\");\n    }\n    idlType.type = \"const-type\";\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Const lacks a name\");\n    tokens.assign =\n      tokeniser.consume(\"=\") || tokeniser.error(\"Const lacks value assignment\");\n    tokens.value =\n      const_value(tokeniser) || tokeniser.error(\"Const lacks a value\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated const, expected `;`\");\n    const ret = new Constant({ source: tokeniser.source, tokens });\n    autoParenter(ret).idlType = idlType;\n    return ret;\n  }\n\n  get type() {\n    return \"const\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get value() {\n    return const_data(this.tokens.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this, parent }),\n        w.token(this.tokens.assign),\n        w.token(this.tokens.value),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent }\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  type_with_extended_attributes,\n  autoParenter,\n  argument_list,\n} from \"./helpers.js\";\n\nexport class IterableLike extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    const ret = autoParenter(\n      new IterableLike({ source: tokeniser.source, tokens: {} })\n    );\n    const { tokens } = ret;\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (!tokens.readonly) {\n      tokens.async = tokeniser.consume(\"async\");\n    }\n    tokens.base = tokens.readonly\n      ? tokeniser.consume(\"maplike\", \"setlike\")\n      : tokens.async\n      ? tokeniser.consume(\"iterable\")\n      : tokeniser.consume(\"iterable\", \"maplike\", \"setlike\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n\n    const { type } = ret;\n    const secondTypeRequired = type === \"maplike\";\n    const secondTypeAllowed = secondTypeRequired || type === \"iterable\";\n    const argumentAllowed = ret.async && type === \"iterable\";\n\n    tokens.open =\n      tokeniser.consume(\"<\") ||\n      tokeniser.error(`Missing less-than sign \\`<\\` in ${type} declaration`);\n    const first =\n      type_with_extended_attributes(tokeniser) ||\n      tokeniser.error(`Missing a type argument in ${type} declaration`);\n    ret.idlType = [first];\n    ret.arguments = [];\n\n    if (secondTypeAllowed) {\n      first.tokens.separator = tokeniser.consume(\",\");\n      if (first.tokens.separator) {\n        ret.idlType.push(type_with_extended_attributes(tokeniser));\n      } else if (secondTypeRequired) {\n        tokeniser.error(`Missing second type argument in ${type} declaration`);\n      }\n    }\n\n    tokens.close =\n      tokeniser.consume(\">\") ||\n      tokeniser.error(`Missing greater-than sign \\`>\\` in ${type} declaration`);\n\n    if (tokeniser.probe(\"(\")) {\n      if (argumentAllowed) {\n        tokens.argsOpen = tokeniser.consume(\"(\");\n        ret.arguments.push(...argument_list(tokeniser));\n        tokens.argsClose =\n          tokeniser.consume(\")\") ||\n          tokeniser.error(\"Unterminated async iterable argument list\");\n      } else {\n        tokeniser.error(`Arguments are only allowed for \\`async iterable\\``);\n      }\n    }\n\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(`Missing semicolon after ${type} declaration`);\n\n    return ret.this;\n  }\n\n  get type() {\n    return this.tokens.base.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get async() {\n    return !!this.tokens.async;\n  }\n\n  *validate(defs) {\n    for (const type of this.idlType) {\n      yield* type.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.readonly),\n        w.token(this.tokens.async),\n        w.token(this.tokens.base, w.ts.generic),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.idlType.map((t) => t.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.argsOpen),\n        w.ts.wrap(this.arguments.map((arg) => arg.write(w))),\n        w.token(this.tokens.argsClose),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent: this.parent }\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport { argument_list, autoParenter } from \"./helpers.js\";\n\nexport class Constructor extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const base = tokeniser.consume(\"constructor\");\n    if (!base) {\n      return;\n    }\n    /** @type {Base[\"tokens\"]} */\n    const tokens = { base };\n    tokens.open =\n      tokeniser.consume(\"(\") ||\n      tokeniser.error(\"No argument list in constructor\");\n    const args = argument_list(tokeniser);\n    tokens.close =\n      tokeniser.consume(\")\") || tokeniser.error(\"Unterminated constructor\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"No semicolon after constructor\");\n    const ret = new Constructor({ source: tokeniser.source, tokens });\n    autoParenter(ret).arguments = args;\n    return ret;\n  }\n\n  get type() {\n    return \"constructor\";\n  }\n\n  *validate(defs) {\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base, w.ts.nameless, { data: this, parent }),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.arguments.map((arg) => arg.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent }\n    );\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\nimport { IterableLike } from \"./iterable.js\";\nimport {\n  stringifier,\n  autofixAddExposedWindow,\n  getMemberIndentation,\n  getLastIndentation,\n  getFirstToken,\n  findLastIndex,\n  autoParenter,\n} from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\nimport { checkInterfaceMemberDuplication } from \"../validators/interface.js\";\nimport { Constructor } from \"./constructor.js\";\nimport { Tokeniser } from \"../tokeniser.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction static_member(tokeniser) {\n  const special = tokeniser.consume(\"static\");\n  if (!special) return;\n  const member =\n    Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"No body in static member\");\n  return member;\n}\n\nexport class Interface extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {import(\"../tokeniser.js\").Token} base\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token|null} [options.partial]\n   */\n  static parse(tokeniser, base, { extMembers = [], partial = null } = {}) {\n    const tokens = { partial, base };\n    return Container.parse(\n      tokeniser,\n      new Interface({ source: tokeniser.source, tokens }),\n      {\n        inheritable: !partial,\n        allowedMembers: [\n          ...extMembers,\n          [Constant.parse],\n          [Constructor.parse],\n          [static_member],\n          [stringifier],\n          [IterableLike.parse],\n          [Attribute.parse],\n          [Operation.parse],\n        ],\n      }\n    );\n  }\n\n  get type() {\n    return \"interface\";\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    if (\n      !this.partial &&\n      this.extAttrs.every((extAttr) => extAttr.name !== \"Exposed\")\n    ) {\n      const message = `Interfaces must have \\`[Exposed]\\` extended attribute. \\\nTo fix, add, for example, \\`[Exposed=Window]\\`. Please also consider carefully \\\nif your interface should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"require-exposed\",\n        message,\n        {\n          autofix: autofixAddExposedWindow(this),\n        }\n      );\n    }\n    const oldConstructors = this.extAttrs.filter(\n      (extAttr) => extAttr.name === \"Constructor\"\n    );\n    for (const constructor of oldConstructors) {\n      const message = `Constructors should now be represented as a \\`constructor()\\` operation on the interface \\\ninstead of \\`[Constructor]\\` extended attribute. Refer to the \\\n[WebIDL spec section on constructor operations](https://heycam.github.io/webidl/#idl-constructors) \\\nfor more information.`;\n      yield validationError(\n        constructor.tokens.name,\n        this,\n        \"constructor-member\",\n        message,\n        {\n          autofix: autofixConstructor(this, constructor),\n        }\n      );\n    }\n\n    const isGlobal = this.extAttrs.some((extAttr) => extAttr.name === \"Global\");\n    if (isGlobal) {\n      const factoryFunctions = this.extAttrs.filter(\n        (extAttr) => extAttr.name === \"LegacyFactoryFunction\"\n      );\n      for (const named of factoryFunctions) {\n        const message = `Interfaces marked as \\`[Global]\\` cannot have factory functions.`;\n        yield validationError(\n          named.tokens.name,\n          this,\n          \"no-constructible-global\",\n          message\n        );\n      }\n\n      const constructors = this.members.filter(\n        (member) => member.type === \"constructor\"\n      );\n      for (const named of constructors) {\n        const message = `Interfaces marked as \\`[Global]\\` cannot have constructors.`;\n        yield validationError(\n          named.tokens.base,\n          this,\n          \"no-constructible-global\",\n          message\n        );\n      }\n    }\n\n    yield* super.validate(defs);\n    if (!this.partial) {\n      yield* checkInterfaceMemberDuplication(defs, this);\n    }\n  }\n}\n\nfunction autofixConstructor(interfaceDef, constructorExtAttr) {\n  interfaceDef = autoParenter(interfaceDef);\n  return () => {\n    const indentation = getLastIndentation(\n      interfaceDef.extAttrs.tokens.open.trivia\n    );\n    const memberIndent = interfaceDef.members.length\n      ? getLastIndentation(getFirstToken(interfaceDef.members[0]).trivia)\n      : getMemberIndentation(indentation);\n    const constructorOp = Constructor.parse(\n      new Tokeniser(`\\n${memberIndent}constructor();`)\n    );\n    constructorOp.extAttrs = new ExtendedAttributes({\n      source: interfaceDef.source,\n      tokens: {},\n    });\n    autoParenter(constructorOp).arguments = constructorExtAttr.arguments;\n\n    const existingIndex = findLastIndex(\n      interfaceDef.members,\n      (m) => m.type === \"constructor\"\n    );\n    interfaceDef.members.splice(existingIndex + 1, 0, constructorOp);\n\n    const { close } = interfaceDef.tokens;\n    if (!close.trivia.includes(\"\\n\")) {\n      close.trivia += `\\n${indentation}`;\n    }\n\n    const { extAttrs } = interfaceDef;\n    const index = extAttrs.indexOf(constructorExtAttr);\n    const removed = extAttrs.splice(index, 1);\n    if (!extAttrs.length) {\n      extAttrs.tokens.open = extAttrs.tokens.close = undefined;\n    } else if (extAttrs.length === index) {\n      extAttrs[index - 1].tokens.separator = undefined;\n    } else if (!extAttrs[index].tokens.name.trivia.trim()) {\n      extAttrs[index].tokens.name.trivia = removed[0].tokens.name.trivia;\n    }\n  };\n}\n","import { validationError } from \"../error.js\";\n\n/**\n * @param {import(\"../validator.js\").Definitions} defs\n * @param {import(\"../productions/container.js\").Container} i\n */\nexport function* checkInterfaceMemberDuplication(defs, i) {\n  const opNames = groupOperationNames(i);\n  const partials = defs.partials.get(i.name) || [];\n  const mixins = defs.mixinMap.get(i.name) || [];\n  for (const ext of [...partials, ...mixins]) {\n    const additions = getOperations(ext);\n    const statics = additions.filter((a) => a.special === \"static\");\n    const nonstatics = additions.filter((a) => a.special !== \"static\");\n    yield* checkAdditions(statics, opNames.statics, ext, i);\n    yield* checkAdditions(nonstatics, opNames.nonstatics, ext, i);\n    statics.forEach((op) => opNames.statics.add(op.name));\n    nonstatics.forEach((op) => opNames.nonstatics.add(op.name));\n  }\n\n  /**\n   * @param {import(\"../productions/operation.js\").Operation[]} additions\n   * @param {Set<string>} existings\n   * @param {import(\"../productions/container.js\").Container} ext\n   * @param {import(\"../productions/container.js\").Container} base\n   */\n  function* checkAdditions(additions, existings, ext, base) {\n    for (const addition of additions) {\n      const { name } = addition;\n      if (name && existings.has(name)) {\n        const isStatic = addition.special === \"static\" ? \"static \" : \"\";\n        const message = `The ${isStatic}operation \"${name}\" has already been defined for the base interface \"${base.name}\" either in itself or in a mixin`;\n        yield validationError(\n          addition.tokens.name,\n          ext,\n          \"no-cross-overload\",\n          message\n        );\n      }\n    }\n  }\n\n  /**\n   * @param {import(\"../productions/container.js\").Container} i\n   * @returns {import(\"../productions/operation.js\").Operation[]}\n   */\n  function getOperations(i) {\n    return i.members.filter(({ type }) => type === \"operation\");\n  }\n\n  /**\n   * @param {import(\"../productions/container.js\").Container} i\n   */\n  function groupOperationNames(i) {\n    const ops = getOperations(i);\n    return {\n      statics: new Set(\n        ops.filter((op) => op.special === \"static\").map((op) => op.name)\n      ),\n      nonstatics: new Set(\n        ops.filter((op) => op.special !== \"static\").map((op) => op.name)\n      ),\n    };\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Constant } from \"./constant.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { stringifier } from \"./helpers.js\";\n\nexport class Mixin extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {import(\"../tokeniser.js\").Token} base\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, base, { extMembers = [], partial } = {}) {\n    const tokens = { partial, base };\n    tokens.mixin = tokeniser.consume(\"mixin\");\n    if (!tokens.mixin) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new Mixin({ source: tokeniser.source, tokens }),\n      {\n        allowedMembers: [\n          ...extMembers,\n          [Constant.parse],\n          [stringifier],\n          [Attribute.parse, { noInherit: true }],\n          [Operation.parse, { regular: true }],\n        ],\n      }\n    );\n  }\n\n  get type() {\n    return \"interface mixin\";\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  unescape,\n  type_with_extended_attributes,\n  autoParenter,\n} from \"./helpers.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { Default } from \"./default.js\";\n\nexport class Field extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(new Field({ source: tokeniser.source, tokens }));\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.required = tokeniser.consume(\"required\");\n    ret.idlType =\n      type_with_extended_attributes(tokeniser, \"dictionary-type\") ||\n      tokeniser.error(\"Dictionary member lacks a type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Dictionary member lacks a name\");\n    ret.default = Default.parse(tokeniser);\n    if (tokens.required && ret.default)\n      tokeniser.error(\"Required member must not have a default\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated dictionary member, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"field\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get required() {\n    return !!this.tokens.required;\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.required),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this, parent }),\n        this.default ? this.default.write(w) : \"\",\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent }\n    );\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Field } from \"./field.js\";\n\nexport class Dictionary extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, { extMembers = [], partial } = {}) {\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"dictionary\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new Dictionary({ source: tokeniser.source, tokens }),\n      {\n        inheritable: !partial,\n        allowedMembers: [...extMembers, [Field.parse]],\n      }\n    );\n  }\n\n  get type() {\n    return \"dictionary\";\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { validationError } from \"../error.js\";\nimport { autofixAddExposedWindow } from \"./helpers.js\";\nimport { Constant } from \"./constant.js\";\n\nexport class Namespace extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, { extMembers = [], partial } = {}) {\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"namespace\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new Namespace({ source: tokeniser.source, tokens }),\n      {\n        allowedMembers: [\n          ...extMembers,\n          [Attribute.parse, { noInherit: true, readonly: true }],\n          [Constant.parse],\n          [Operation.parse, { regular: true }],\n        ],\n      }\n    );\n  }\n\n  get type() {\n    return \"namespace\";\n  }\n\n  *validate(defs) {\n    if (\n      !this.partial &&\n      this.extAttrs.every((extAttr) => extAttr.name !== \"Exposed\")\n    ) {\n      const message = `Namespaces must have [Exposed] extended attribute. \\\nTo fix, add, for example, [Exposed=Window]. Please also consider carefully \\\nif your namespace should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"require-exposed\",\n        message,\n        {\n          autofix: autofixAddExposedWindow(this),\n        }\n      );\n    }\n    yield* super.validate(defs);\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\n\nexport class CallbackInterface extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {*} callback\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   */\n  static parse(tokeniser, callback, { extMembers = [] } = {}) {\n    const tokens = { callback };\n    tokens.base = tokeniser.consume(\"interface\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new CallbackInterface({ source: tokeniser.source, tokens }),\n      {\n        allowedMembers: [\n          ...extMembers,\n          [Constant.parse],\n          [Operation.parse, { regular: true }],\n        ],\n      }\n    );\n  }\n\n  get type() {\n    return \"callback interface\";\n  }\n}\n","import { Tokeniser } from \"./tokeniser.js\";\nimport { Enum } from \"./productions/enum.js\";\nimport { Includes } from \"./productions/includes.js\";\nimport { ExtendedAttributes } from \"./productions/extended-attributes.js\";\nimport { Typedef } from \"./productions/typedef.js\";\nimport { CallbackFunction } from \"./productions/callback.js\";\nimport { Interface } from \"./productions/interface.js\";\nimport { Mixin } from \"./productions/mixin.js\";\nimport { Dictionary } from \"./productions/dictionary.js\";\nimport { Namespace } from \"./productions/namespace.js\";\nimport { CallbackInterface } from \"./productions/callback-interface.js\";\nimport { autoParenter } from \"./productions/helpers.js\";\nimport { Eof } from \"./productions/token.js\";\n\n/** @typedef {'callbackInterface'|'dictionary'|'interface'|'mixin'|'namespace'} ExtendableInterfaces */\n/** @typedef {{ extMembers?: import(\"./productions/container.js\").AllowedMember[]}} Extension */\n/** @typedef {Partial<Record<ExtendableInterfaces, Extension>>} Extensions */\n\n/**\n * Parser options.\n * @typedef {Object} ParserOptions\n * @property {string} [sourceName]\n * @property {boolean} [concrete]\n * @property {Function[]} [productions]\n * @property {Extensions} [extensions]\n */\n\n/**\n * @param {Tokeniser} tokeniser\n * @param {ParserOptions} options\n */\nfunction parseByTokens(tokeniser, options) {\n  const source = tokeniser.source;\n\n  function error(str) {\n    tokeniser.error(str);\n  }\n\n  function consume(...candidates) {\n    return tokeniser.consume(...candidates);\n  }\n\n  function callback() {\n    const callback = consume(\"callback\");\n    if (!callback) return;\n    if (tokeniser.probe(\"interface\")) {\n      return CallbackInterface.parse(tokeniser, callback, {\n        ...options?.extensions?.callbackInterface,\n      });\n    }\n    return CallbackFunction.parse(tokeniser, callback);\n  }\n\n  function interface_(opts) {\n    const base = consume(\"interface\");\n    if (!base) return;\n    return (\n      Mixin.parse(tokeniser, base, {\n        ...opts,\n        ...options?.extensions?.mixin,\n      }) ||\n      Interface.parse(tokeniser, base, {\n        ...opts,\n        ...options?.extensions?.interface,\n      }) ||\n      error(\"Interface has no proper body\")\n    );\n  }\n\n  function partial() {\n    const partial = consume(\"partial\");\n    if (!partial) return;\n    return (\n      Dictionary.parse(tokeniser, {\n        partial,\n        ...options?.extensions?.dictionary,\n      }) ||\n      interface_({ partial }) ||\n      Namespace.parse(tokeniser, {\n        partial,\n        ...options?.extensions?.namespace,\n      }) ||\n      error(\"Partial doesn't apply to anything\")\n    );\n  }\n\n  function definition() {\n    if (options.productions) {\n      for (const production of options.productions) {\n        const result = production(tokeniser);\n        if (result) {\n          return result;\n        }\n      }\n    }\n\n    return (\n      callback() ||\n      interface_() ||\n      partial() ||\n      Dictionary.parse(tokeniser, options?.extensions?.dictionary) ||\n      Enum.parse(tokeniser) ||\n      Typedef.parse(tokeniser) ||\n      Includes.parse(tokeniser) ||\n      Namespace.parse(tokeniser, options?.extensions?.namespace)\n    );\n  }\n\n  function definitions() {\n    if (!source.length) return [];\n    const defs = [];\n    while (true) {\n      const ea = ExtendedAttributes.parse(tokeniser);\n      const def = definition();\n      if (!def) {\n        if (ea.length) error(\"Stray extended attributes\");\n        break;\n      }\n      autoParenter(def).extAttrs = ea;\n      defs.push(def);\n    }\n    const eof = Eof.parse(tokeniser);\n    if (options.concrete) {\n      defs.push(eof);\n    }\n    return defs;\n  }\n\n  const res = definitions();\n  if (tokeniser.position < source.length) error(\"Unrecognised tokens\");\n  return res;\n}\n\n/**\n * @param {string} str\n * @param {ParserOptions} [options]\n */\nexport function parse(str, options = {}) {\n  const tokeniser = new Tokeniser(str);\n  if (typeof options.sourceName !== \"undefined\") {\n    // @ts-ignore (See Tokeniser.source in supplement.d.ts)\n    tokeniser.source.name = options.sourceName;\n  }\n  return parseByTokens(tokeniser, options);\n}\n","function noop(arg) {\n  return arg;\n}\n\nconst templates = {\n  wrap: (items) => items.join(\"\"),\n  trivia: noop,\n  name: noop,\n  reference: noop,\n  type: noop,\n  generic: noop,\n  nameless: noop,\n  inheritance: noop,\n  definition: noop,\n  extendedAttribute: noop,\n  extendedAttributeReference: noop,\n};\n\nexport class Writer {\n  constructor(ts) {\n    this.ts = Object.assign({}, templates, ts);\n  }\n\n  /**\n   * @param {string} raw\n   * @param {object} options\n   * @param {string} [options.unescaped]\n   * @param {import(\"./productions/base.js\").Base} [options.context]\n   * @returns\n   */\n  reference(raw, { unescaped, context }) {\n    if (!unescaped) {\n      unescaped = raw.startsWith(\"_\") ? raw.slice(1) : raw;\n    }\n    return this.ts.reference(raw, unescaped, context);\n  }\n\n  /**\n   * @param {import(\"./tokeniser.js\").Token} t\n   * @param {Function} wrapper\n   * @param {...any} args\n   * @returns\n   */\n  token(t, wrapper = noop, ...args) {\n    if (!t) {\n      return \"\";\n    }\n    const value = wrapper(t.value, ...args);\n    return this.ts.wrap([this.ts.trivia(t.trivia), value]);\n  }\n\n  reference_token(t, context) {\n    return this.token(t, this.reference.bind(this), { context });\n  }\n\n  name_token(t, arg) {\n    return this.token(t, this.ts.name, arg);\n  }\n\n  identifier(id, context) {\n    return this.ts.wrap([\n      this.reference_token(id.tokens.value, context),\n      this.token(id.tokens.separator),\n    ]);\n  }\n}\n\nexport function write(ast, { templates: ts = templates } = {}) {\n  ts = Object.assign({}, templates, ts);\n\n  const w = new Writer(ts);\n\n  return ts.wrap(ast.map((it) => it.write(w)));\n}\n","import { validationError as error } from \"./error.js\";\n\nfunction getMixinMap(all, unique) {\n  const map = new Map();\n  const includes = all.filter((def) => def.type === \"includes\");\n  for (const include of includes) {\n    const mixin = unique.get(include.includes);\n    if (!mixin) {\n      continue;\n    }\n    const array = map.get(include.target);\n    if (array) {\n      array.push(mixin);\n    } else {\n      map.set(include.target, [mixin]);\n    }\n  }\n  return map;\n}\n\n/**\n * @typedef {ReturnType<typeof groupDefinitions>} Definitions\n */\nfunction groupDefinitions(all) {\n  const unique = new Map();\n  const duplicates = new Set();\n  const partials = new Map();\n  for (const def of all) {\n    if (def.partial) {\n      const array = partials.get(def.name);\n      if (array) {\n        array.push(def);\n      } else {\n        partials.set(def.name, [def]);\n      }\n      continue;\n    }\n    if (!def.name) {\n      continue;\n    }\n    if (!unique.has(def.name)) {\n      unique.set(def.name, def);\n    } else {\n      duplicates.add(def);\n    }\n  }\n  return {\n    all,\n    unique,\n    partials,\n    duplicates,\n    mixinMap: getMixinMap(all, unique),\n    cache: {\n      typedefIncludesDictionary: new WeakMap(),\n      dictionaryIncludesRequiredField: new WeakMap(),\n    },\n  };\n}\n\nfunction* checkDuplicatedNames({ unique, duplicates }) {\n  for (const dup of duplicates) {\n    const { name } = dup;\n    const message = `The name \"${name}\" of type \"${\n      unique.get(name).type\n    }\" was already seen`;\n    yield error(dup.tokens.name, dup, \"no-duplicate\", message);\n  }\n}\n\nfunction* validateIterable(ast) {\n  const defs = groupDefinitions(ast);\n  for (const def of defs.all) {\n    if (def.validate) {\n      yield* def.validate(defs);\n    }\n  }\n  yield* checkDuplicatedNames(defs);\n}\n\n// Remove this once all of our support targets expose `.flat()` by default\nfunction flatten(array) {\n  if (array.flat) {\n    return array.flat();\n  }\n  return [].concat(...array);\n}\n\n/**\n * @param {import(\"./productions/base.js\").Base[]} ast\n * @return {import(\"./error.js\").WebIDLErrorData[]} validation errors\n */\nexport function validate(ast) {\n  return [...validateIterable(flatten(ast))];\n}\n"],"names":["root","factory","exports","module","define","amd","globalThis","__webpack_require__","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","error","source","position","current","message","kind","level","autofix","ruleName","sliceTokens","count","slice","Math","max","tokensToText","inputs","precedes","text","map","t","trivia","join","nextToken","type","length","line","precedingLastLine","splitted","split","lastLine","subsequentTokens","subsequentText","sourceContext","repeat","contextType","context","name","partial","node","hierarchy","parent","unshift","n","base","target","result","appendIfExist","contextAsText","bareMessage","sourceName","input","tokens","syntaxError","validationError","token","options","index","Base","constructor","defineProperties","this","writable","toJSON","json","undefined","inheritance","proto","descMap","getOwnPropertyDescriptors","entries","getPrototypeOf","idlTypeIncludesDictionary","idlType","defs","useNullableInner","union","def","unique","typedefIncludesDictionary","cache","has","set","reference","dictionary","nullable","subtype","dictionaryIncludesRequiredField","dict","members","some","field","required","superdict","ArrayBase","Array","super","WrappedToken","static","tokeniser","consumeKind","write","w","ts","wrap","separator","Eof","tokenName","list","parser","listName","extAttrValueSyntax","renamedLegacies","Map","extAttrListItems","syntax","toks","ExtendedAttributeParameters","assign","consume","ret","autoParenter","asterisk","secondaryName","open","rhsIsList","argument_list","close","rhsType","reference_token","p","identifier","SimpleExtendedAttribute","params","parse","rhs","arguments","extAttr","arg","validate","extendedAttribute","extendedAttributeReference","ExtendedAttributes","push","unconsume","probe","ea","type_suffix","single_type","typeName","Type","return_type","type_with_extended_attributes","keyType","stringTypes","keyIdlType","valueType","generic_type","primitive_type","typeNameKeywords","generic","typ","or","union_type","extAttrs","Boolean","prefix","postfix","filter","replaceAllowShared","typedef","targetToken","firstToken","ref","unescaped","type_body","indexOf","splice","match","Default","const_value","expression","const_data","negative","Argument","start_position","optional","variadic","argumentNameKeywords","default","autofixOptionalDictionaryDefaultValue","requiredExists","a","isLastRequiredArgument","getFirstToken","name_token","data","Tokeniser","Operation","special","regular","termination","includes","argument","body","nameless","Attribute","noInherit","readonly","e","idlTypeIncludesEnforceRange","startsWith","allowDangler","first","items","item","num_type","integer_type","decimal_type","voidToken","stringifier","getLastIndentation","str","lines","autofixAddExposedWindow","exposed","existing","test","values","sort","x","y","Proxy","isArray","tokenRe","decimal","integer","string","whitespace","comment","other","nonRegexTerminals","concat","punctuations","reserved","idl","lastCharIndex","nextChar","charAt","attemptTokenMatch","noFlushTrivia","currentTrivia","pop","lastIndex","WebIDLParseError","punctuation","Error","re","exec","tokenise","probeKind","candidates","consumeIdentifier","EnumValue","Enum","v","Includes","mixin","Typedef","CallbackFunction","Container","instance","inheritable","allowedMembers","colon","mem","args","member","callback","m","Constant","IterableLike","async","secondTypeRequired","secondTypeAllowed","argumentAllowed","argsOpen","argsClose","Constructor","static_member","Interface","extMembers","every","oldConstructors","autofixConstructor","factoryFunctions","named","constructors","i","opNames","ops","getOperations","statics","Set","op","nonstatics","groupOperationNames","partials","mixins","mixinMap","ext","additions","checkAdditions","forEach","add","existings","addition","checkInterfaceMemberDuplication","interfaceDef","constructorExtAttr","indentation","memberIndent","parentTrivia","indentCh","getMemberIndentation","constructorOp","existingIndex","array","predicate","reverse","findIndex","findLastIndex","removed","trim","Mixin","Field","Dictionary","Namespace","CallbackInterface","parseByTokens","interface_","opts","extensions","interface","productions","production","callbackInterface","namespace","res","eof","concrete","definitions","noop","templates","Writer","raw","wrapper","bind","id","ast","it","getMixinMap","all","include","validateIterable","duplicates","WeakMap","groupDefinitions","dup","checkDuplicatedNames","flat"],"sourceRoot":""}