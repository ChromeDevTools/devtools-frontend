{"version":3,"file":"webidl2.js","mappings":"CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,GAAIH,GACe,iBAAZC,QACdA,QAAiB,QAAID,IAErBD,EAAc,QAAIC,GACnB,CATD,CASGK,YAAY,I,mBCRf,IAAIC,EAAsB,CCA1BA,EAAwB,CAACL,EAASM,KACjC,IAAI,IAAIC,KAAOD,EACXD,EAAoBG,EAAEF,EAAYC,KAASF,EAAoBG,EAAER,EAASO,IAC5EE,OAAOC,eAAeV,EAASO,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,IAE1E,ECNDF,EAAwB,CAACQ,EAAKC,IAAUL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,GCClFT,EAAyBL,IACH,oBAAXkB,QAA0BA,OAAOC,aAC1CV,OAAOC,eAAeV,EAASkB,OAAOC,YAAa,CAAEC,MAAO,WAE7DX,OAAOC,eAAeV,EAAS,aAAc,CAAEoB,OAAO,GAAO,G,KCoC9D,SAASC,EACPC,EACAC,EACAC,EACAC,EACAC,GACA,MAAEC,EAAQ,QAAO,QAAEC,EAAO,SAAEC,GAAa,CAAC,GAK1C,SAASC,EAAYC,GACnB,OAAOA,EAAQ,EACXT,EAAOU,MAAMT,EAAUA,EAAWQ,GAClCT,EAAOU,MAAMC,KAAKC,IAAIX,EAAWQ,EAAO,GAAIR,EAClD,CAQA,SAASY,EAAaC,GAAQ,SAAEC,GAAa,CAAC,GAC5C,MAAMC,EAAOF,EAAOG,KAAKC,GAAMA,EAAEC,OAASD,EAAEpB,QAAOsB,KAAK,IAClDC,EAAYrB,EAAOC,GACzB,MAAuB,QAAnBoB,EAAUC,KACLN,EAELD,EACKC,EAAOK,EAAUF,OAEnBH,EAAKN,MAAMW,EAAUF,OAAOI,OACrC,CAEA,MACMC,EACsB,QAA1BxB,EAAOC,GAAUqB,KACbtB,EAAOC,GAAUuB,KACjBxB,EAAOuB,OAAS,EACdvB,EAAOC,EAAW,GAAGuB,KACrB,EAEFC,EAjFR,SAAkBT,GAChB,MAAMU,EAAWV,EAAKW,MAAM,MAC5B,OAAOD,EAASA,EAASH,OAAS,EACpC,CA8E4BK,CACxBf,EAAaL,GATG,GASsB,CAAEO,UAAU,KAG9Cc,EAAmBrB,EAZP,GAaZsB,EAAiBjB,EAAagB,GAI9BE,EAAgBN,EAHMK,EAAeH,MAAM,MAAM,GAGS,MADjD,IAAIK,OAAOP,EAAkBF,QAAU,KAGhDU,EAAuB,WAAT7B,EAAoB,QAAU,SAQ5C8B,EAAU,GAAG9B,mBAAsBoB,IAPpBxB,EAAOmC,KAAO,OAAOnC,EAAOmC,OAAS,KAExDjC,GAAWA,EAAQiC,KACf,KAAKF,OAAiB/B,EAAQkC,QAAU,WAAa,KAnF7D,SAAuBC,GACrB,MAAMC,EAAY,CAACD,GACnB,KAAOA,GAAQA,EAAKE,QAAQ,CAC1B,MAAM,OAAEA,GAAWF,EACnBC,EAAUE,QAAQD,GAClBF,EAAOE,CACT,CACA,OAAOD,EAAUrB,KAAKwB,GAfxB,SAAuBC,EAAMC,GAC3B,IAAIC,EAASF,EAIb,OAHIC,IACFC,GAAU,IAAID,KAETC,CACT,CAS8BC,CAAcJ,EAAEnB,KAAMmB,EAAEN,QAAOf,KAAK,OAClE,CA2EkE0B,CACxD5C,OAEF,QACiF6B,IACvF,MAAO,CACL5B,QAAS,GAAG+B,KAAW/B,IACvB4C,YAAa5C,EACb+B,UACAV,OACAwB,WAAYhD,EAAOmC,KACnB9B,QACAE,WACAD,UACA2C,MAAOnB,EACPoB,OAAQrB,EAEZ,CAKO,SAASsB,EAAYnD,EAAQC,EAAUC,EAASC,GACrD,OAAOJ,EAAMC,EAAQC,EAAUC,EAASC,EAAS,SACnD,CAMO,SAASiD,EACdC,EACAnD,EACAK,EACAJ,EACAmD,EAAU,CAAC,GAGX,OADAA,EAAQ/C,SAAWA,EACZR,EACLG,EAAQF,OACRqD,EAAME,MACNrD,EACAC,EACA,aACAmD,EAEJ,C,6FCjJO,MAAME,KAMX,WAAAC,EAAY,OAAEzD,EAAM,OAAEkD,IACpB/D,OAAOuE,iBAAiBC,KAAM,CAC5B3D,OAAQ,CAAEF,MAAOE,GACjBkD,OAAQ,CAAEpD,MAAOoD,EAAQU,UAAU,GACnCrB,OAAQ,CAAEzC,MAAO,KAAM8D,UAAU,GACjCD,KAAM,CAAE7D,MAAO6D,OAEnB,CAEA,MAAAE,GACE,MAAMC,EAAO,CAAExC,UAAMyC,EAAW5B,UAAM4B,EAAWC,iBAAaD,GAC9D,IAAIE,EAAQN,KACZ,KAAOM,IAAU9E,OAAOM,WAAW,CACjC,MAAMyE,EAAU/E,OAAOgF,0BAA0BF,GACjD,IAAK,MAAOhF,EAAKa,KAAUX,OAAOiF,QAAQF,IACpCpE,EAAMT,YAAcS,EAAMR,OAE5BwE,EAAK7E,GAAO0E,KAAK1E,IAGrBgF,EAAQ9E,OAAOkF,eAAeJ,EAChC,CACA,OAAOH,CACT,EClBK,SAASQ,EACdC,EACAC,GACA,iBAAEC,GAAqB,CAAC,GAExB,IAAKF,EAAQG,MAAO,CAClB,MAAMC,EAAMH,EAAKI,OAAOtF,IAAIiF,EAAQA,SACpC,IAAKI,EACH,OAEF,GAAiB,YAAbA,EAAIrD,KAAoB,CAC1B,MAAM,0BAAEuD,GAA8BL,EAAKM,MAC3C,GAAID,EAA0BE,IAAIJ,GAGhC,OAAOE,EAA0BvF,IAAIqF,GAEvCH,EAAKM,MAAMD,0BAA0BG,IAAIL,OAAKZ,GAC9C,MAAMnB,EAAS0B,EAA0BK,EAAIJ,QAASC,GAEtD,GADAA,EAAKM,MAAMD,0BAA0BG,IAAIL,EAAK/B,GAC1CA,EACF,MAAO,CACLqC,UAAWV,EACXW,WAAYtC,EAAOsC,WAGzB,CACA,GAAiB,eAAbP,EAAIrD,OAA0BmD,IAAqBF,EAAQY,UAC7D,MAAO,CACLF,UAAWV,EACXW,WAAYP,EAGlB,CACA,IAAK,MAAMS,KAAWb,EAAQa,QAAS,CACrC,MAAMxC,EAAS0B,EAA0Bc,EAASZ,GAClD,GAAI5B,EACF,OAAIwC,EAAQV,MACH9B,EAEF,CACLqC,UAAWG,EACXF,WAAYtC,EAAOsC,WAGzB,CACF,CAOO,SAASG,EAAgCC,EAAMd,GACpD,GAAIA,EAAKM,MAAMO,gCAAgCN,IAAIO,GACjD,OAAOd,EAAKM,MAAMO,gCAAgC/F,IAAIgG,GAIxDd,EAAKM,MAAMO,gCAAgCL,IAAIM,OAAMvB,GACrD,IAAInB,EAAS0C,EAAKC,QAAQC,MAAMC,GAAUA,EAAMC,WAChD,IAAK9C,GAAU0C,EAAKtB,YAAa,CAC/B,MAAM2B,EAAYnB,EAAKI,OAAOtF,IAAIgG,EAAKtB,aAClC2B,EAGMN,EAAgCM,EAAWnB,KACpD5B,GAAS,GAFTA,GAAS,CAIb,CAEA,OADA4B,EAAKM,MAAMO,gCAAgCL,IAAIM,EAAM1C,GAC9CA,CACT,CCnFO,MAAMgD,kBAAkBC,MAC7B,WAAApC,EAAY,OAAEzD,EAAM,OAAEkD,IACpB4C,QACA3G,OAAOuE,iBAAiBC,KAAM,CAC5B3D,OAAQ,CAAEF,MAAOE,GACjBkD,OAAQ,CAAEpD,MAAOoD,GACjBX,OAAQ,CAAEzC,MAAO,KAAM8D,UAAU,IAErC,ECLK,MAAMmC,qBAAqBvC,KAKhC,aAAOwC,CAAOC,EAAW3E,GACvB,MAAO,KACL,MAAMxB,EAAQmG,EAAUC,YAAY5E,GACpC,GAAIxB,EACF,OAAO,IAAIiG,aAAa,CACtB/F,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAEpD,UAEd,CAEJ,CAEA,SAAIA,GACF,OAAO,EAAS6D,KAAKT,OAAOpD,MAAMA,MACpC,CAGA,KAAAqG,CAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOpD,OACpBsG,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAGK,MAAMC,YAAYT,aAIvB,YAAOU,CAAMR,GACX,MAAMnG,EAAQmG,EAAUC,YAAY,OACpC,GAAIpG,EACF,OAAO,IAAI0G,IAAI,CAAExG,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAEpD,UAEzD,CAEA,QAAIwB,GACF,MAAO,KACT,ECpCF,SAAS4B,EAAO+C,EAAWS,GACzB,OAAOC,EAAKV,EAAW,CACrBD,OAAQD,aAAaC,OAAOC,EAAWS,GACvCE,SAAUF,EAAY,SAE1B,CAEA,MAAMG,EAAqB,CAAC,aAAc,UAAW,UAAW,UAU1DC,EAAkB,IAAIC,IAAI,IARD,CAC7B,oBACA,gBACA,cACA,uBACA,eAKyB9F,KAAKkB,GAAS,CAACA,EAAM,SAASA,OAEvD,CAAC,mBAAoB,yBACrB,CAAC,mBAAoB,0BACrB,CAAC,cAAe,6BAOlB,SAAS6E,EAAiBf,GACxB,IAAK,MAAMgB,KAAUJ,EAAoB,CACvC,MAAMK,EAAOhE,EAAO+C,EAAWgB,GAC/B,GAAIC,EAAK3F,OACP,OAAO2F,CAEX,CACAjB,EAAUlG,MACR,sEAEJ,CAEO,MAAMoH,oCAAoC3D,KAI/C,YAAOiD,CAAMR,GACX,MAAM/C,EAAS,CAAEkE,OAAQnB,EAAUoB,QAAQ,MACrCC,EAAMC,EACV,IAAIJ,4BAA4B,CAAEnH,OAAQiG,EAAUjG,OAAQkD,YAG9D,GADAoE,EAAIX,KAAO,GACPzD,EAAOkE,OAAQ,CAEjB,GADAlE,EAAOsE,SAAWvB,EAAUoB,QAAQ,KAChCnE,EAAOsE,SACT,OAAOF,EAAI3D,KAEbT,EAAOuE,cAAgBxB,EAAUC,eAAeW,EAClD,CAcA,OAbA3D,EAAOwE,KAAOzB,EAAUoB,QAAQ,KAC5BnE,EAAOwE,MACTJ,EAAIX,KAAOW,EAAIK,UAEXX,EAAiBf,GAEjB2B,EAAc3B,GAClB/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,yDACTmD,EAAOkE,SAAWlE,EAAOuE,eAClCxB,EAAUlG,MAAM,uDAEXuH,EAAI3D,IACb,CAEA,aAAIgE,GACF,OACEhE,KAAKT,OAAOkE,SAAWzD,KAAKT,OAAOsE,WAAa7D,KAAKT,OAAOuE,aAEhE,CAEA,WAAIK,GACF,OAAInE,KAAKgE,UACAhE,KAAKgD,KAAK,GAAGzD,OAAOpD,MAAMwB,KAAO,QAEtCqC,KAAKT,OAAOsE,SACP,IAEL7D,KAAKT,OAAOuE,cACP9D,KAAKT,OAAOuE,cAAcnG,KAE5B,IACT,CAGA,KAAA6E,CAAMC,GACJ,MAAM,QAAE0B,GAAYnE,KACpB,OAAOyC,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOkE,QACpBhB,EAAE/C,MAAMM,KAAKT,OAAOsE,UACpBpB,EAAE2B,gBAAgBpE,KAAKT,OAAOuE,cAAe9D,KAAKpB,QAClD6D,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAKgD,KAAK1F,KAAK+G,GACG,oBAAZF,EACH1B,EAAE6B,WAAWD,EAAGrE,KAAKpB,QACrByF,EAAE7B,MAAMC,KAEdA,EAAE/C,MAAMM,KAAKT,OAAO2E,QAExB,EAGK,MAAMK,gCAAgC1E,KAI3C,YAAOiD,CAAMR,GACX,MAAM9D,EAAO8D,EAAUC,YAAY,cACnC,GAAI/D,EACF,OAAO,IAAI+F,wBAAwB,CACjClI,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAEf,QACVgG,OAAQhB,4BAA4BV,MAAMR,IAGhD,CAEA,WAAAxC,EAAY,OAAEzD,EAAM,OAAEkD,EAAM,OAAEiF,IAC5BrC,MAAM,CAAE9F,SAAQkD,WAChBiF,EAAO5F,OAASoB,KAChBxE,OAAOC,eAAeuE,KAAM,SAAU,CAAE7D,MAAOqI,GACjD,CAEA,QAAI7G,GACF,MAAO,oBACT,CACA,QAAIa,GACF,OAAOwB,KAAKT,OAAOf,KAAKrC,KAC1B,CACA,OAAIsI,GACF,MAAQN,QAASxG,EAAI,OAAE4B,EAAM,KAAEyD,GAAShD,KAAKwE,OAC7C,IAAK7G,EACH,OAAO,KAOT,MAAO,CAAEA,OAAMxB,MALD6D,KAAKwE,OAAOR,UACtBhB,EACAhD,KAAKwE,OAAOjF,OAAOuE,cACjB,EAASvE,EAAOuE,cAAc3H,OAC9B,KAER,CACA,aAAIuI,GACF,MAAM,UAAEV,EAAS,KAAEhB,GAAShD,KAAKwE,OACjC,OAAKxB,GAAQgB,EACJ,GAEFhB,CACT,CAEA,SAAC2B,CAAS9D,GACR,MAAM,KAAErC,GAASwB,KACjB,GAAa,4BAATxB,EAAoC,CACtC,MAAMhC,EAAU,sOAIViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,uBACAxD,EACA,CAAEE,MAAO,WAEb,MAAO,GAAIyG,EAAgB/B,IAAI5C,GAAO,CACpC,MAAMhC,EAAU,MAAMgC,yEACA2E,EAAgBxH,IAAI6C,oHAGpCiB,EAAgBO,KAAKT,OAAOf,KAAMwB,KAAM,iBAAkBxD,EAAS,CACvEE,MAAO,UACPC,SA0B+BiI,EA1BQ5E,KA2BtC,KACL,MAAM,KAAExB,GAASoG,EACjBA,EAAQrF,OAAOf,KAAKrC,MAAQgH,EAAgBxH,IAAI6C,GACnC,gBAATA,IACFoG,EAAQJ,OAAOjF,OAAS,CAAC,EAC3B,IA9BA,CAwBJ,IAAuCqF,EAvBnC,IAAK,MAAMC,KAAO7E,KAAK0E,gBACdG,EAAIF,SAAS9D,EAExB,CAGA,KAAA2B,CAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACfF,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOf,KAAKhB,QAC7BiF,EAAEC,GAAGoC,kBACHrC,EAAEC,GAAGC,KAAK,CACRF,EAAEC,GAAGqC,2BAA2B/E,KAAKxB,MACrCwB,KAAKwE,OAAOhC,MAAMC,MAGtBA,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAkBK,MAAMoC,2BAA2B/C,UAItC,YAAOa,CAAMR,GACX,MAAM/C,EAAS,CAAC,EAChBA,EAAOwE,KAAOzB,EAAUoB,QAAQ,KAChC,MAAMC,EAAM,IAAIqB,mBAAmB,CAAE3I,OAAQiG,EAAUjG,OAAQkD,WAC/D,OAAKA,EAAOwE,MACZJ,EAAIsB,QACCjC,EAAKV,EAAW,CACjBD,OAAQkC,wBAAwBzB,MAChCG,SAAU,wBAGd1D,EAAO2E,MACL5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MACR,4DAECuH,EAAI/F,SACP0E,EAAU4C,UAAU3F,EAAO2E,MAAMtE,OACjC0C,EAAUlG,MAAM,iDAEdkG,EAAU6C,MAAM,MAClB7C,EAAUlG,MACR,kEAGGuH,GArBkBA,CAsB3B,CAEA,SAACgB,CAAS9D,GACR,IAAK,MAAM+D,KAAW5E,WACb4E,EAAQD,SAAS9D,EAE5B,CAGA,KAAA2B,CAAMC,GACJ,OAAKzC,KAAKpC,OACH6E,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAK1C,KAAK8H,GAAOA,EAAG5C,MAAMC,KAC7BA,EAAE/C,MAAMM,KAAKT,OAAO2E,SAJG,EAM3B,EC5LF,SAASmB,EAAY/C,EAAW1G,GAC9B,MAAM4F,EAAWc,EAAUoB,QAAQ,KAC/BlC,IACF5F,EAAI2D,OAAOiC,SAAWA,GAEpBc,EAAU6C,MAAM,MAAM7C,EAAUlG,MAAM,gCAC5C,CAMA,SAASkJ,EAAYhD,EAAWiD,GAC9B,IAAI5B,EAlFN,SAAsBrB,EAAWiD,GAC/B,MAAMxG,EAAOuD,EAAUoB,QACrB,cACA,kBACA,UACA,iBACA,WACA,UAEF,IAAK3E,EACH,OAEF,MAAM4E,EAAMC,EACV,IAAI4B,KAAK,CAAEnJ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAER,WAKjD,OAHA4E,EAAIpE,OAAOwE,KACTzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,4BAA4B2C,EAAK5C,SAC3C4C,EAAK5C,OACX,IAAK,UAAW,CACVmG,EAAU6C,MAAM,MAClB7C,EAAUlG,MAAM,+CAClB,MAAMqF,EACJgE,EAAYnD,EAAWiD,IACvBjD,EAAUlG,MAAM,2BAClBuH,EAAIlC,QAAQwD,KAAKxD,GACjB,KACF,CACA,IAAK,iBACL,IAAK,WACL,IAAK,cACL,IAAK,kBAAmB,CACtB,MAAMA,EACJiE,EAA8BpD,EAAWiD,IACzCjD,EAAUlG,MAAM,WAAW2C,EAAK5C,iBAClCwH,EAAIlC,QAAQwD,KAAKxD,GACjB,KACF,CACA,IAAK,SAAU,CACTa,EAAU6C,MAAM,MAClB7C,EAAUlG,MAAM,6CAClB,MAAMuJ,EACJrD,EAAUoB,WAAWkC,IACrBtD,EAAUlG,MAAM,8BAA8BwJ,EAAYnI,KAAK,SAC3DoI,EAAa,IAAIL,KAAK,CAC1BnJ,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAER,KAAM4G,KAElBE,EAAWtG,OAAOqD,UAChBN,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,uCAClByJ,EAAWlI,KAAO4H,EAClB,MAAMO,EACJJ,EAA8BpD,EAAWiD,IACzCjD,EAAUlG,MAAM,qCAClBuH,EAAIlC,QAAQwD,KAAKY,EAAYC,GAC7B,KACF,EAMF,OAJKnC,EAAI/C,SAAS0B,EAAUlG,MAAM,8BAA8B2C,EAAK5C,SACrEwH,EAAIpE,OAAO2E,MACT5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,iCAAiC2C,EAAK5C,SACjDwH,EAAI3D,IACb,CAkBY+F,CAAazD,EAAWiD,IAAaS,EAAe1D,GAC9D,IAAKqB,EAAK,CACR,MAAM5E,EACJuD,EAAUC,YAAY,eACtBD,EAAUoB,WAAWkC,KAAgBK,GACvC,IAAKlH,EACH,OAEF4E,EAAM,IAAI6B,KAAK,CAAEnJ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAER,UACjDuD,EAAU6C,MAAM,MAClB7C,EAAUlG,MAAM,4BAA4B2C,EAAK5C,QACrD,CAQA,MAPoB,YAAhBwH,EAAIuC,SAAyB5D,EAAU6C,MAAM,MAC/C7C,EAAUlG,MAAM,mCAElBuH,EAAIhG,KAAO4H,GAAY,KACvBF,EAAY/C,EAAWqB,GACnBA,EAAInC,UAA4B,QAAhBmC,EAAI/C,SACtB0B,EAAUlG,MAAM,sCACXuH,CACT,CAqCO,MAAM6B,aAAa3F,KAKxB,YAAOiD,CAAMR,EAAWiD,GACtB,OAAOD,EAAYhD,EAAWiD,IArClC,SAAoBjD,EAAW3E,GAC7B,MAAM4B,EAAS,CAAC,EAEhB,GADAA,EAAOwE,KAAOzB,EAAUoB,QAAQ,MAC3BnE,EAAOwE,KAAM,OAClB,MAAMJ,EAAMC,EAAa,IAAI4B,KAAK,CAAEnJ,OAAQiG,EAAUjG,OAAQkD,YAE9D,IADAoE,EAAIhG,KAAOA,GAAQ,OACN,CACX,MAAMwI,EACJT,EAA8BpD,EAAW3E,IACzC2E,EAAUlG,MAAM,wDACE,QAAhB+J,EAAIvF,SACN0B,EAAUlG,MAAM,iDACE,YAAhB+J,EAAID,SACN5D,EAAUlG,MAAM,qDAClBuH,EAAIlC,QAAQwD,KAAKkB,GACjB,MAAMC,EAAK9D,EAAUoB,QAAQ,MAC7B,IAAI0C,EAEG,MADLD,EAAI5G,OAAOqD,UAAYwD,CAE3B,CASA,OARIzC,EAAI/C,QAAQhD,OAAS,GACvB0E,EAAUlG,MACR,kEAGJmD,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,2BAC5CiJ,EAAY/C,EAAWqB,GAChBA,EAAI3D,IACb,CAQ+CqG,CAAW/D,EAAWiD,EACnE,CAEA,WAAAzF,EAAY,OAAEzD,EAAM,OAAEkD,IACpB4C,MAAM,CAAE9F,SAAQkD,WAChB/D,OAAOC,eAAeuE,KAAM,UAAW,CAAE7D,MAAO,GAAI8D,UAAU,IAC9DD,KAAKsG,SAAW,IAAItB,mBAAmB,CAAE3I,SAAQkD,OAAQ,CAAC,GAC5D,CAEA,WAAI2G,GACF,OAAIlG,KAAKyB,QAAQ7D,QAAUoC,KAAKT,OAAOR,KAC9BiB,KAAKT,OAAOR,KAAK5C,MAEnB,EACT,CACA,YAAIqF,GACF,OAAO+E,QAAQvG,KAAKT,OAAOiC,SAC7B,CACA,SAAIT,GACF,OAAOwF,QAAQvG,KAAKyB,QAAQ7D,UAAYoC,KAAKT,OAAOR,IACtD,CACA,WAAI6B,GACF,GAAIZ,KAAKyB,QAAQ7D,OACf,OAAOoC,KAAKyB,QAOd,OAAO,EAJM,CAACzB,KAAKT,OAAOiH,OAAQxG,KAAKT,OAAOR,KAAMiB,KAAKT,OAAOkH,SAC7DC,QAAQnJ,GAAMA,IACdD,KAAKC,GAAMA,EAAEpB,QACbsB,KAAK,KAEV,CAEA,SAACkH,CAAS9D,GAGR,SAFOb,KAAKsG,SAAS3B,SAAS9D,GAET,iBAAjBb,KAAKY,QAGP,IAAK,MAAM0F,IAAY,CAACtG,KAAKsG,SAAUtG,KAAKpB,QAAQ0H,UAClD,IAAK,MAAM1B,KAAW0B,EAAU,CAC9B,GAAqB,gBAAjB1B,EAAQpG,KACV,SAEF,MAAMhC,EAAU,mFACViD,EACJO,KAAKT,OAAOR,KACZiB,KACA,sBACAxD,EACA,CAAEG,QAASgK,EAAmB3G,KAAM4E,EAAS0B,IAEjD,CAIJ,GAAqB,SAAjBtG,KAAKY,QAAoB,CAC3B,MAAMpE,EAAU,sJAGViD,EAAgBO,KAAKT,OAAOR,KAAMiB,KAAM,eAAgBxD,EAAS,CACrEG,SA8FagB,EA9FQqC,KA+FpB,KACLrC,EAAK4B,OAAOR,KAAK5C,MAAQ,WAAW,IA9FpC,CA4FJ,IAAqBwB,EAtFjB,MAAMiJ,GAAW5G,KAAKe,OAASF,EAAKI,OAAOtF,IAAIqE,KAAKY,SAC9C5B,EAASgB,KAAKe,MAChBf,KACA4G,GAA4B,YAAjBA,EAAQjJ,KACjBiJ,EAAQhG,aACRR,EACN,GAAIpB,GAAUgB,KAAKwB,SAAU,CAE3B,MAAM,UAAEF,GAAcX,EAA0B3B,EAAQ6B,IAAS,CAAC,EAClE,GAAIS,EAAW,CACb,MAAMuF,GAAe7G,KAAKe,MAAQO,EAAYtB,MAAMT,OAAOR,KACrDvC,EAAU,yDACViD,EACJoH,EACA7G,KACA,yBACAxD,EAEJ,CACF,MAEE,IAAK,MAAMiF,KAAWzB,KAAKyB,cAClBA,EAAQkD,SAAS9D,EAG9B,CAGA,KAAA2B,CAAMC,GA6BJ,OAAOA,EAAEC,GAAGC,KAAK,CACf3C,KAAKsG,SAAS9D,MAAMC,GA7BJ,MAChB,GAAIzC,KAAKe,OAASf,KAAKkG,QACrB,OAAOzD,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOR,KAAM0D,EAAEC,GAAGwD,SAC/BzD,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAKyB,QAAQnE,KAAKC,GAAMA,EAAEiF,MAAMC,KACnCA,EAAE/C,MAAMM,KAAKT,OAAO2E,SAGxB,MAAM4C,EAAa9G,KAAKT,OAAOiH,QAAUxG,KAAKT,OAAOR,KAC/CyH,EAASxG,KAAKT,OAAOiH,OACvB,CAACxG,KAAKT,OAAOiH,OAAOrK,MAAOsG,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOR,KAAKvB,SACxD,GACEuJ,EAAMtE,EAAEnB,UACZmB,EAAEC,GAAGC,KAAK,IACL6D,EACHxG,KAAKT,OAAOR,KAAK5C,MACjBsG,EAAE/C,MAAMM,KAAKT,OAAOkH,WAEtB,CACEO,UACEhH,KACF,QACAzB,QAASyB,OAGb,OAAOyC,EAAEC,GAAGC,KAAK,CAACF,EAAEC,GAAGlF,OAAOsJ,EAAWtJ,QAASuJ,GAAK,EAIvDE,GACAxE,EAAE/C,MAAMM,KAAKT,OAAOiC,UACpBiB,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAQF,SAAS+D,EAAmBhJ,EAAMiH,EAAS0B,GACzC,MAAO,KACL,MAAM1G,EAAQ0G,EAASY,QAAQtC,GAC/B0B,EAASa,OAAOvH,EAAO,IAClB0G,EAAS1I,QAAUD,EAAK4B,OAAOR,KAAKvB,OAAO4J,MAAM,UACpDzJ,EAAK4B,OAAOR,KAAKvB,OAAS,IAG5BG,EAAK4B,OAAOR,KAAK5C,MAAQ,yBAAyB,CAEtD,CCrTO,MAAMkL,gBAAgBxH,KAI3B,YAAOiD,CAAMR,GACX,MAAMmB,EAASnB,EAAUoB,QAAQ,KACjC,IAAKD,EACH,OAAO,KAET,MAAMzC,EACJsG,EAAYhF,IACZA,EAAUC,YAAY,WACtBD,EAAUoB,QAAQ,OAAQ,IAAK,MAC/BpB,EAAUlG,MAAM,wBACZmL,EAAa,CAACvG,GACpB,GAAkB,MAAdA,EAAI7E,MAAe,CACrB,MAAM+H,EACJ5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,wCAClBmL,EAAWtC,KAAKf,EAClB,MAAO,GAAkB,MAAdlD,EAAI7E,MAAe,CAC5B,MAAM+H,EACJ5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,0CAClBmL,EAAWtC,KAAKf,EAClB,CACA,OAAO,IAAImD,QAAQ,CACjBhL,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAEkE,UACV8D,cAEJ,CAEA,WAAAzH,EAAY,OAAEzD,EAAM,OAAEkD,EAAM,WAAEgI,IAC5BpF,MAAM,CAAE9F,SAAQkD,WAChBgI,EAAW3I,OAASoB,KACpBxE,OAAOC,eAAeuE,KAAM,aAAc,CAAE7D,MAAOoL,GACrD,CAEA,QAAI5J,GACF,OAAO6J,EAAWxH,KAAKuH,WAAW,IAAI5J,IACxC,CACA,SAAIxB,GACF,OAAOqL,EAAWxH,KAAKuH,WAAW,IAAIpL,KACxC,CACA,YAAIsL,GACF,OAAOD,EAAWxH,KAAKuH,WAAW,IAAIE,QACxC,CAGA,KAAAjF,CAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAOkE,WACjBzD,KAAKuH,WAAWjK,KAAKC,GAAMkF,EAAE/C,MAAMnC,MAE1C,EC1CK,MAAMmK,iBAAiB7H,KAI5B,YAAOiD,CAAMR,GACX,MAAMqF,EAAiBrF,EAAUhG,SAE3BiD,EAAS,CAAC,EACVoE,EAAMC,EACV,IAAI8D,SAAS,CAAErL,OAAQiG,EAAUjG,OAAQkD,YAK3C,OAHAoE,EAAI2C,SAAWtB,mBAAmBlC,MAAMR,GACxC/C,EAAOqI,SAAWtF,EAAUoB,QAAQ,YACpCC,EAAI/C,QAAU8E,EAA8BpD,EAAW,iBAClDqB,EAAI/C,SAGJrB,EAAOqI,WACVrI,EAAOsI,SAAWvF,EAAUoB,QAAQ,QAEtCnE,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUoB,WAAWoE,GAClBvI,EAAOf,MAGZmF,EAAIoE,QAAUxI,EAAOqI,SAAWP,QAAQvE,MAAMR,GAAa,KACpDqB,EAAI3D,MAHFsC,EAAU4C,UAAUyC,IATpBrF,EAAU4C,UAAUyC,EAa/B,CAEA,QAAIhK,GACF,MAAO,UACT,CACA,YAAIiK,GACF,QAAS5H,KAAKT,OAAOqI,QACvB,CACA,YAAIC,GACF,QAAS7H,KAAKT,OAAOsI,QACvB,CACA,QAAIrJ,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAKA,SAACwI,CAAS9D,SACDb,KAAKsG,SAAS3B,SAAS9D,SACvBb,KAAKY,QAAQ+D,SAAS9D,GAC7B,MAAM5B,EAAS0B,EAA0BX,KAAKY,QAASC,EAAM,CAC3DC,kBAAkB,IAEpB,GAAI7B,EACF,GAAIe,KAAKY,QAAQY,SAAU,CACzB,MAAMhF,EAAU,iDACViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,uBACAxD,EAEJ,MAAO,GAAKwD,KAAK4H,UAiBV,IAAK5H,KAAK+H,QAAS,CACxB,MAAMvL,EAAU,yEACViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,mBACAxD,EACA,CACEG,QAASqL,EAAsChI,OAGrD,OA3BE,GACEA,KAAKpB,SACJ8C,EAAgCzC,EAAOsC,WAAYV,IA8C9D,SAAgCgE,GAC9B,MAAM7B,EAAO6B,EAAIjG,OAAO8F,WAAaG,EAAIjG,OAAOoE,KAC1CpD,EAAQoD,EAAKkE,QAAQrC,GACrBoD,EAAiBjF,EAAKjG,MAAM6C,EAAQ,GAAGiC,MAAMqG,IAAOA,EAAEN,WAC5D,OAAQK,CACV,CAlDUE,CAAuBnI,MACvB,CACA,MAAMxD,EAAU,0EACViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,oBACAxD,EACA,CACEG,SA8CgCkI,EA9Cc7E,KA+CnD,KACL,MAAM8G,EAAasB,EAAcvD,EAAIjE,SACrCiE,EAAItF,OAAOqI,SAAW,IACjBd,EACHnJ,KAAM,WACNxB,MAAO,YAET2K,EAAWtJ,OAAS,IACpBwK,EAAsCnD,EAAtCmD,EAA4C,IApDxC,CA2CR,IAA8CnD,CA7B5C,CAGA,KAAArC,CAAMC,GACJ,OAAOA,EAAEC,GAAGC,KAAK,CACf3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOqI,UACpBnF,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE/C,MAAMM,KAAKT,OAAOsI,UACpBpF,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,OACvCA,KAAK+H,QAAU/H,KAAK+H,QAAQvF,MAAMC,GAAK,GACvCA,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAgCF,SAASoF,EAAsCnD,GAC7C,MAAO,KACLA,EAAIkD,QAAUV,QAAQvE,MAAM,IAAIyF,UAAU,SAAS,CAEvD,CCnJO,MAAMC,kBAAkB3I,KAO7B,YAAOiD,CAAMR,GAAW,QAAEmG,EAAO,QAAEC,GAAY,CAAC,GAC9C,MAAMnJ,EAAS,CAAEkJ,WACX9E,EAAMC,EACV,IAAI4E,UAAU,CAAEnM,OAAQiG,EAAUjG,OAAQkD,YAE5C,OAAIkJ,GAA6B,gBAAlBA,EAAQtM,QACrBoD,EAAOoJ,YAAcrG,EAAUoB,QAAQ,KACnCnE,EAAOoJ,cACThF,EAAIe,UAAY,GACTf,IAGN8E,GAAYC,IACfnJ,EAAOkJ,QAAUnG,EAAUoB,QAAQ,SAAU,SAAU,YAEzDC,EAAI/C,QACF6E,EAAYnD,IAAcA,EAAUlG,MAAM,uBAC5CmD,EAAOf,KACL8D,EAAUC,YAAY,eAAiBD,EAAUoB,QAAQ,YAC3DnE,EAAOwE,KACLzB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,qBAC5CuH,EAAIe,UAAYT,EAAc3B,GAC9B/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,0BAC5CmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,wCACXuH,EAAI3D,KACb,CAEA,QAAIrC,GACF,MAAO,WACT,CACA,QAAIa,GACF,MAAM,KAAEA,GAASwB,KAAKT,OACtB,OAAKf,EAGE,EAASA,EAAKrC,OAFZ,EAGX,CACA,WAAIsM,GACF,OAAKzI,KAAKT,OAAOkJ,QAGVzI,KAAKT,OAAOkJ,QAAQtM,MAFlB,EAGX,CAEA,SAACwI,CAAS9D,GAER,SADOb,KAAKsG,SAAS3B,SAAS9D,IACzBb,KAAKxB,MAAQ,CAAC,GAAI,UAAUoK,SAAS5I,KAAKyI,SAAU,CACvD,MAAMjM,EAAU,qFACViD,EAAgBO,KAAKT,OAAOwE,KAAM/D,KAAM,gBAAiBxD,EACjE,CACA,GAAIwD,KAAKY,QAAS,CAChB,GAA6B,mBAAzBZ,KAAKY,QAAQsF,QAA8B,CAC7C,MAAM1J,EAAU,iEACViD,EACJO,KAAKY,QAAQrB,OAAOR,KACpBiB,KACA,2BACAxD,EAEJ,OACOwD,KAAKY,QAAQ+D,SAAS9D,EAC/B,CACA,IAAK,MAAMgI,KAAY7I,KAAK0E,gBACnBmE,EAASlE,SAAS9D,EAE7B,CAGA,KAAA2B,CAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACb8I,EAAO9I,KAAKY,QACd,CACE6B,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,KAAMpB,WAC7C6D,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAK0E,UAAUpH,KAAKuH,GAAQA,EAAIrC,MAAMC,MAChDA,EAAE/C,MAAMM,KAAKT,OAAO2E,QAEtB,GACJ,OAAOzB,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBzC,KAAKT,OAAOf,KACRiE,EAAE/C,MAAMM,KAAKT,OAAOkJ,SACpBhG,EAAE/C,MAAMM,KAAKT,OAAOkJ,QAAShG,EAAEC,GAAGqG,SAAU,CAAET,KAAMtI,KAAMpB,cAC3DkK,EACHrG,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,KAAMpB,UAElB,ECjGK,MAAMoK,kBAAkBnJ,KAQ7B,YAAOiD,CACLR,GACA,QAAEmG,EAAO,UAAEQ,GAAY,EAAK,SAAEC,GAAW,GAAU,CAAC,GAEpD,MAAMvB,EAAiBrF,EAAUhG,SAC3BiD,EAAS,CAAEkJ,WACX9E,EAAMC,EACV,IAAIoF,UAAU,CAAE3M,OAAQiG,EAAUjG,OAAQkD,YAa5C,GAXKkJ,GAAYQ,IACf1J,EAAOkJ,QAAUnG,EAAUoB,QAAQ,YAEjB,YAAhBC,EAAI8E,SAAyBnG,EAAU6C,MAAM,aAC/C7C,EAAUlG,MAAM,4CAElBmD,EAAO2J,SAAW5G,EAAUoB,QAAQ,YAChCwF,IAAa3J,EAAO2J,UAAY5G,EAAU6C,MAAM,cAClD7C,EAAUlG,MAAM,+CAElBmD,EAAOR,KAAOuD,EAAUoB,QAAQ,aAC3BnE,EAAOR,KAcZ,OAVA4E,EAAI/C,QACF8E,EAA8BpD,EAAW,mBACzCA,EAAUlG,MAAM,0BAClBmD,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUoB,QAAQ,QAAS,aAC3BpB,EAAUlG,MAAM,0BAClBmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,wCACXuH,EAAI3D,KAbTsC,EAAU4C,UAAUyC,EAcxB,CAEA,QAAIhK,GACF,MAAO,WACT,CACA,WAAI8K,GACF,OAAKzI,KAAKT,OAAOkJ,QAGVzI,KAAKT,OAAOkJ,QAAQtM,MAFlB,EAGX,CACA,YAAI+M,GACF,QAASlJ,KAAKT,OAAO2J,QACvB,CACA,QAAI1K,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAEA,SAACwI,CAAS9D,GAIR,SAHOb,KAAKsG,SAAS3B,SAAS9D,SACvBb,KAAKY,QAAQ+D,SAAS9D,GAG3B,CAAC,iBAAkB,WAAY,UAAU+H,SAAS5I,KAAKY,QAAQsF,SAC/D,CACA,MAAM1J,EAAU,4BAA4BwD,KAAKY,QAAQsF,uBACnDzG,EACJO,KAAKT,OAAOf,KACZwB,KACA,oBACAxD,EAEJ,CAEA,CACE,MAAM,UAAE8E,GAAcX,EAA0BX,KAAKY,QAASC,IAAS,CAAC,EACxE,GAAIS,EAAW,CACb,MAAMuF,GAAe7G,KAAKY,QAAQG,MAAQO,EAAYtB,KAAKY,SACxDrB,OAAOR,KACJvC,EAAU,mDACViD,EAAgBoH,EAAa7G,KAAM,oBAAqBxD,EAChE,CACF,CAEA,GAAIwD,KAAKkJ,URJN,SAAqCtI,EAASC,GACnD,GAAID,EAAQG,MAEV,OAAO,EAGT,GAAIH,EAAQ0F,SAASzE,MAAMsH,GAAiB,iBAAXA,EAAE3K,OACjC,OAAO,EAGT,MAAMwC,EAAMH,EAAKI,OAAOtF,IAAIiF,EAAQA,SACpC,MAAkB,YAAdI,GAAKrD,MAIFqD,EAAIJ,QAAQ0F,SAASzE,MAAMsH,GAAiB,iBAAXA,EAAE3K,MAC5C,CQXU4K,CAA4BpJ,KAAKY,QAASC,GAAO,CACnD,MAAMgG,EAAc7G,KAAKY,QAAQrB,OAAOR,KAClCvC,EACJ,6EACIiD,EAAgBoH,EAAa7G,KAAM,oBAAqBxD,EAChE,CAEJ,CAGA,KAAAgG,CAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOkJ,SACpBhG,EAAE/C,MAAMM,KAAKT,OAAO2J,UACpBzG,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,KAAMpB,WAC7C6D,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,KAAMpB,UAElB,EC/GK,SAAS,EAAS0F,GACvB,OAAOA,EAAW+E,WAAW,KAAO/E,EAAWvH,MAAM,GAAKuH,CAC5D,CAUO,SAAStB,EAAKV,GAAW,OAAED,EAAM,aAAEiH,EAAY,SAAErG,EAAW,SACjE,MAAMsG,EAAQlH,EAAOC,GACrB,IAAKiH,EACH,MAAO,GAETA,EAAMhK,OAAOqD,UAAYN,EAAUoB,QAAQ,KAC3C,MAAM8F,EAAQ,CAACD,GACf,KAAOA,EAAMhK,OAAOqD,WAAW,CAC7B,MAAM6G,EAAOpH,EAAOC,GACpB,IAAKmH,EAAM,CACJH,GACHhH,EAAUlG,MAAM,qBAAqB6G,KAEvC,KACF,CAGA,GAFAwG,EAAKlK,OAAOqD,UAAYN,EAAUoB,QAAQ,KAC1C8F,EAAMvE,KAAKwE,IACNA,EAAKlK,OAAOqD,UAAW,KAC9B,CACA,OAAO4G,CACT,CAKO,SAASlC,EAAYhF,GAC1B,OACEA,EAAUC,YAAY,UAAW,YACjCD,EAAUoB,QAAQ,OAAQ,QAAS,WAAY,YAAa,MAEhE,CAOO,SAAS8D,GAAW,KAAE7J,EAAI,MAAExB,IACjC,OAAQwB,GACN,IAAK,UACL,IAAK,UACH,MAAO,CAAEA,KAAM,SAAUxB,SAC3B,IAAK,SACH,MAAO,CAAEwB,KAAM,SAAUxB,MAAOA,EAAMY,MAAM,GAAI,IAGpD,OAAQZ,GACN,IAAK,OACL,IAAK,QACH,MAAO,CAAEwB,KAAM,UAAWxB,MAAiB,SAAVA,GACnC,IAAK,WACL,IAAK,YACH,MAAO,CAAEwB,KAAM,WAAY8J,SAAUtL,EAAMkN,WAAW,MACxD,IAAK,IACH,MAAO,CAAE1L,KAAM,WAAYxB,MAAO,IACpC,IAAK,IACH,MAAO,CAAEwB,KAAM,cACjB,QACE,MAAO,CAAEA,KAAMxB,GAErB,CAKO,SAAS6J,EAAe1D,GAoB7B,MAAM,OAAEjG,GAAWiG,EACboH,EApBN,WACE,MAAMlD,EAASlE,EAAUoB,QAAQ,YAC3B3E,EAAOuD,EAAUoB,QAAQ,QAAS,QACxC,GAAI3E,EAAM,CACR,MAAM0H,EAAUnE,EAAUoB,QAAQ,QAClC,OAAO,IAAI8B,KAAK,CAAEnJ,SAAQkD,OAAQ,CAAEiH,SAAQzH,OAAM0H,YACpD,CACID,GAAQlE,EAAUlG,MAAM,+BAC9B,CAYiBuN,IAVjB,WACE,MAAMnD,EAASlE,EAAUoB,QAAQ,gBAC3B3E,EAAOuD,EAAUoB,QAAQ,QAAS,UACxC,GAAI3E,EACF,OAAO,IAAIyG,KAAK,CAAEnJ,SAAQkD,OAAQ,CAAEiH,SAAQzH,UAE1CyH,GAAQlE,EAAUlG,MAAM,6BAC9B,CAGmCwN,GACnC,GAAIF,EAAU,OAAOA,EACrB,MAAM3K,EAAOuD,EAAUoB,QACrB,SACA,UACA,OACA,QACA,aAEF,OAAI3E,EACK,IAAIyG,KAAK,CAAEnJ,SAAQkD,OAAQ,CAAER,eADtC,CAGF,CAKO,SAASkF,EAAc3B,GAC5B,OAAOU,EAAKV,EAAW,CACrBD,OAAQqF,SAAS5E,MACjBG,SAAU,kBAEd,CAMO,SAASyC,EAA8BpD,EAAWiD,GACvD,MAAMe,EAAWtB,mBAAmBlC,MAAMR,GACpCqB,EAAM6B,KAAK1C,MAAMR,EAAWiD,GAElC,OADI5B,IAAKC,EAAaD,GAAK2C,SAAWA,GAC/B3C,CACT,CAMO,SAAS8B,EAAYnD,EAAWiD,GACrC,MAAMY,EAAMX,KAAK1C,MAAMR,EAAWiD,GAAY,eAC9C,GAAIY,EACF,OAAOA,EAET,MAAM0D,EAAYvH,EAAUoB,QAAQ,QACpC,GAAImG,EAAW,CACb,MAAMlG,EAAM,IAAI6B,KAAK,CACnBnJ,OAAQiG,EAAUjG,OAClBkD,OAAQ,CAAER,KAAM8K,KAGlB,OADAlG,EAAIhG,KAAO,cACJgG,CACT,CACF,CAKO,SAASmG,EAAYxH,GAC1B,MAAMmG,EAAUnG,EAAUoB,QAAQ,eAClC,IAAK+E,EAAS,OAKd,OAHEO,UAAUlG,MAAMR,EAAW,CAAEmG,aAC7BD,UAAU1F,MAAMR,EAAW,CAAEmG,aAC7BnG,EAAUlG,MAAM,2BAEpB,CAKO,SAAS2N,EAAmBC,GACjC,MAAMC,EAAQD,EAAIhM,MAAM,MAExB,GAAIiM,EAAMrM,OAAQ,CAChB,MAAMwJ,EAAQ6C,EAAMA,EAAMrM,OAAS,GAAGwJ,MAAM,QAC5C,GAAIA,EACF,OAAOA,EAAM,EAEjB,CACA,MAAO,EACT,CAcO,SAAS8C,EAAwBlJ,GACtC,MAAO,KACL,GAAIA,EAAIsF,SAAS1I,OAAQ,CACvB,MAAM0E,EAAY,IAAIiG,UAAU,mBAC1B4B,EAAU5F,wBAAwBzB,MAAMR,GAC9C6H,EAAQ5K,OAAOqD,UAAYN,EAAUoB,QAAQ,KAC7C,MAAM0G,EAAWpJ,EAAIsF,SAAS,GACzB,MAAM+D,KAAKD,EAAS7K,OAAOf,KAAKhB,UACnC4M,EAAS7K,OAAOf,KAAKhB,OAAS,IAAI4M,EAAS7K,OAAOf,KAAKhB,UAEzDwD,EAAIsF,SAASzH,QAAQsL,EACvB,KAAO,CACLvG,EAAa5C,GAAKsF,SAAWtB,mBAAmBlC,MAC9C,IAAIyF,UAAU,qBAEhB,MAAM/K,EAASwD,EAAIzB,OAAOR,KAAKvB,OAC/BwD,EAAIsF,SAAS/G,OAAOwE,KAAKvG,OAASA,EAClCwD,EAAIzB,OAAOR,KAAKvB,OAAS,KAAKuM,EAAmBvM,IACnD,EAEJ,CAMO,SAAS4K,EAAcE,GAC5B,GAAIA,EAAKhC,SAAS1I,OAChB,OAAO0K,EAAKhC,SAAS/G,OAAOwE,KAE9B,GAAkB,cAAduE,EAAK3K,OAAyB2K,EAAKG,QACrC,OAAOL,EAAcE,EAAK1H,SAG5B,OADepF,OAAO8O,OAAOhC,EAAK/I,QAAQgL,MAAK,CAACC,EAAGC,IAAMD,EAAE5K,MAAQ6K,EAAE7K,QACvD,EAChB,CAuBO,SAASgE,EAAa0E,EAAM1J,GAKjC,GAJKA,IAEHA,EAAS0J,IAENA,EAGH,OAAOA,EA8BT,OA5Bc,IAAIoC,MAAMpC,EAAM,CAC5B,GAAA3M,CAAIqD,EAAQqF,GACV,MAAMlI,EAAQ6C,EAAOqF,GACrB,OAAInC,MAAMyI,QAAQxO,IAAgB,WAANkI,EAGnBT,EAAazH,EAAO6C,GAEtB7C,CACT,EACA,GAAAkF,CAAIrC,EAAQqF,EAAGlI,GAGb,GADA6C,EAAOqF,GAAKlI,GACPA,EACH,OAAO,EACF,GAAI+F,MAAMyI,QAAQxO,GAEvB,IAAK,MAAMsN,KAAQtN,OACU,IAAhBsN,EAAK7K,SACd6K,EAAK7K,OAASA,aAGe,IAAjBzC,EAAMyC,SACtBzC,EAAMyC,OAASA,GAEjB,OAAO,CACT,GAGJ,CC1SA,MAAMgM,EAAU,CAGdC,QACE,sGACFC,QAAS,8CACTxG,WAAY,+BACZyG,OAAQ,WACRC,WAAY,cACZC,QAAS,2BACTC,MAAO,wBAGIjF,EAAmB,CAC9B,cACA,oBACA,WACA,YACA,aACA,aACA,aACA,cACA,cACA,oBACA,gBACA,iBACA,eACA,eACA,eACA,MACA,SACA,UAGWL,EAAc,CAAC,aAAc,YAAa,aAE1CkC,EAAuB,CAClC,QACA,YACA,WACA,QACA,cACA,UACA,aACA,OACA,SACA,WACA,UACA,YACA,WACA,UACA,YACA,UACA,WACA,UACA,SACA,SACA,cACA,UACA,gBAGIqD,EAAoB,CACxB,YACA,cACA,WACA,MACA,kBACA,UACA,iBACA,iBACA,SACA,UACA,OACA,SACA,QACA,QACA,OACA,QACA,OACA,QACA,WACA,KACA,WACA,SACA,WACA,QACA,OACA,YACA,WACA,QACAC,OAAOtD,EAAsBlC,EAAaK,GAEtCoF,EAAe,CACnB,IACA,IACA,IACA,MACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAGIC,EAAW,CAEf,eACA,WACA,aAgHK,MAAM/C,UAIX,WAAAzI,CAAYyL,GACVvL,KAAK3D,OA9GT,SAAkB2N,GAChB,MAAMzK,EAAS,GACf,IAAIiM,EAAgB,EAChBhO,EAAS,GACTK,EAAO,EACP+B,EAAQ,EACZ,KAAO4L,EAAgBxB,EAAIpM,QAAQ,CACjC,MAAM6N,EAAWzB,EAAI0B,OAAOF,GAC5B,IAAIvM,GAAU,EAQd,GANI,YAAYoL,KAAKoB,GACnBxM,EAAS0M,EAAkB,aAAc,CAAEC,eAAe,IACpC,MAAbH,IACTxM,EAAS0M,EAAkB,UAAW,CAAEC,eAAe,MAGzC,IAAZ3M,EAAe,CACjB,MAAM4M,EAAgBtM,EAAOuM,MAAM3P,MACnC0B,IAASgO,EAAczE,MAAM,QAAU,IAAIxJ,OAC3CJ,GAAUqO,EACVjM,GAAS,CACX,MAAO,GAAI,iBAAiByK,KAAKoB,IAK/B,GAJAxM,EAAS0M,EAAkB,YACX,IAAZ1M,IACFA,EAAS0M,EAAkB,aAEb,IAAZ1M,EAAe,CACjBA,EAAS0M,EAAkB,cAC3B,MAAMI,EAAYxM,EAAO3B,OAAS,EAC5B8B,EAAQH,EAAOwM,GACrB,IAAgB,IAAZ9M,EAAe,CACjB,GAAIqM,EAAS1C,SAASlJ,EAAMvD,OAAQ,CAClC,MAAMK,EAAU,GAAG,EACjBkD,EAAMvD,wDAER,MAAM,IAAI6P,iBACRxM,EAAYD,EAAQwM,EAAW,KAAMvP,GAEzC,CAAW2O,EAAkBvC,SAASlJ,EAAMvD,SAC1CuD,EAAM/B,KAAO,SAEjB,CACF,MACsB,MAAb8N,IACTxM,EAAS0M,EAAkB,WAG7B,IAAK,MAAMM,KAAeZ,EACxB,GAAIrB,EAAIX,WAAW4C,EAAaT,GAAgB,CAC9CjM,EAAO0F,KAAK,CACVtH,KAAM,SACNxB,MAAO8P,EACPzO,SACAK,OACA+B,UAEFpC,EAAS,GACTgO,GAAiBS,EAAYrO,OAC7BqB,EAASuM,EACT,KACF,CAOF,IAHgB,IAAZvM,IACFA,EAAS0M,EAAkB,WAEb,IAAZ1M,EACF,MAAM,IAAIiN,MAAM,gCAElBV,EAAgBvM,EAChBW,GAAS,CACX,CAWA,OARAL,EAAO0F,KAAK,CACVtH,KAAM,MACNxB,MAAO,GACPqB,SACAK,OACA+B,UAGKL,EAOP,SAASoM,EAAkBhO,GAAM,cAAEiO,GAAkB,CAAC,GACpD,MAAMO,EAAKvB,EAAQjN,GACnBwO,EAAGJ,UAAYP,EACf,MAAMvM,EAASkN,EAAGC,KAAKpC,GACvB,OAAI/K,GACFM,EAAO0F,KAAK,CAAEtH,OAAMxB,MAAO8C,EAAO,GAAIzB,SAAQK,OAAM+B,UAC/CgM,IACHpO,EAAS,IAEJ2O,EAAGJ,YAEJ,CACV,CACF,CAOkBM,CAASd,GACvBvL,KAAK1D,SAAW,CAClB,CAMA,KAAAF,CAAMI,GACJ,MAAM,IAAIwP,iBACRxM,EAAYQ,KAAK3D,OAAQ2D,KAAK1D,SAAU0D,KAAKzD,QAASC,GAE1D,CAKA,SAAA8P,CAAU3O,GACR,OACEqC,KAAK3D,OAAOuB,OAASoC,KAAK1D,UAC1B0D,KAAK3D,OAAO2D,KAAK1D,UAAUqB,OAASA,CAExC,CAKA,KAAAwH,CAAMhJ,GACJ,OACE6D,KAAKsM,UAAU,WAAatM,KAAK3D,OAAO2D,KAAK1D,UAAUH,QAAUA,CAErE,CAKA,WAAAoG,IAAegK,GACb,IAAK,MAAM5O,KAAQ4O,EAAY,CAC7B,IAAKvM,KAAKsM,UAAU3O,GAAO,SAC3B,MAAM+B,EAAQM,KAAK3D,OAAO2D,KAAK1D,UAE/B,OADA0D,KAAK1D,WACEoD,CACT,CACF,CAKA,OAAAgE,IAAW6I,GACT,IAAKvM,KAAKsM,UAAU,UAAW,OAC/B,MAAM5M,EAAQM,KAAK3D,OAAO2D,KAAK1D,UAC/B,IAAK,MAAMH,KAASoQ,EAClB,GAAI7M,EAAMvD,QAAUA,EAEpB,OADA6D,KAAK1D,WACEoD,CAEX,CAKA,iBAAA8M,CAAkBrQ,GAChB,GAAK6D,KAAKsM,UAAU,eAGhBtM,KAAK3D,OAAO2D,KAAK1D,UAAUH,QAAUA,EAGzC,OAAO6D,KAAKuC,YAAY,aAC1B,CAKA,SAAA2C,CAAU5I,GACR0D,KAAK1D,SAAWA,CAClB,EAGK,MAAM0P,yBAAyBE,MAWpC,WAAApM,EAAY,QACVtD,EAAO,YACP4C,EAAW,QACXb,EAAO,KACPV,EAAI,WACJwB,EAAU,MACVC,EAAK,OACLC,IAEA4C,MAAM3F,GAENwD,KAAKxB,KAAO,mBACZwB,KAAKZ,YAAcA,EACnBY,KAAKzB,QAAUA,EACfyB,KAAKnC,KAAOA,EACZmC,KAAKX,WAAaA,EAClBW,KAAKV,MAAQA,EACbU,KAAKT,OAASA,CAChB,ECrVK,MAAMkN,kBAAkBrK,aAI7B,YAAOU,CAAMR,GACX,MAAMnG,EAAQmG,EAAUC,YAAY,UACpC,GAAIpG,EACF,OAAO,IAAIsQ,UAAU,CAAEpQ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAEpD,UAE/D,CAEA,QAAIwB,GACF,MAAO,YACT,CACA,SAAIxB,GACF,OAAOgG,MAAMhG,MAAMY,MAAM,GAAI,EAC/B,CAGA,KAAAyF,CAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGC,KAAK,CACfF,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOpD,MAAMqB,QAC9BiF,EAAEC,GAAGrH,WACHoH,EAAEC,GAAGC,KAAK,CAAC,IAAKF,EAAEC,GAAGlE,KAAKwB,KAAK7D,MAAO,CAAEmM,KAAMtI,KAAMpB,WAAW,MAC/D,CAAE0J,KAAMtI,KAAMpB,WAEhB6D,EAAE/C,MAAMM,KAAKT,OAAOqD,YAExB,EAGK,MAAM8J,aAAa7M,KAIxB,YAAOiD,CAAMR,GAEX,MAAM/C,EAAS,CAAC,EAEhB,GADAA,EAAOR,KAAOuD,EAAUoB,QAAQ,SAC3BnE,EAAOR,KACV,OAEFQ,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,oBAClB,MAAMuH,EAAMC,EAAa,IAAI8I,KAAK,CAAErQ,OAAQiG,EAAUjG,OAAQkD,YAkB9D,OAjBA+C,EAAU/F,QAAUoH,EAAI3D,KACxBT,EAAOwE,KAAOzB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,iBACxDuH,EAAI2G,OAAStH,EAAKV,EAAW,CAC3BD,OAAQoK,UAAU3J,MAClBwG,cAAc,EACdrG,SAAU,gBAERX,EAAUgK,UAAU,WACtBhK,EAAUlG,MAAM,gCAElBmD,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,4BACvCuH,EAAI2G,OAAO1M,QACd0E,EAAUlG,MAAM,oBAElBmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,2BACrCuH,EAAI3D,IACb,CAEA,QAAIrC,GACF,MAAO,MACT,CACA,QAAIa,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAGA,KAAAqG,CAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,OACvCyC,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAKsK,OAAOhN,KAAKqP,GAAMA,EAAEnK,MAAMC,MACzCA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,MAEZ,ECzFK,MAAM4M,iBAAiB/M,KAI5B,YAAOiD,CAAMR,GACX,MAAMtD,EAASsD,EAAUC,YAAY,cACrC,IAAKvD,EACH,OAEF,MAAMO,EAAS,CAAEP,UAEjB,GADAO,EAAOqJ,SAAWtG,EAAUoB,QAAQ,YAC/BnE,EAAOqJ,SAUZ,OANArJ,EAAOsN,MACLvK,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,iCAClBmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,2CACX,IAAIwQ,SAAS,CAAEvQ,OAAQiG,EAAUjG,OAAQkD,WAT9C+C,EAAU4C,UAAUlG,EAAOY,MAU/B,CAEA,QAAIjC,GACF,MAAO,UACT,CACA,UAAIqB,GACF,OAAO,EAASgB,KAAKT,OAAOP,OAAO7C,MACrC,CACA,YAAIyM,GACF,OAAO,EAAS5I,KAAKT,OAAOsN,MAAM1Q,MACpC,CAGA,KAAAqG,CAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE2B,gBAAgBpE,KAAKT,OAAOP,OAAQgB,MACtCyC,EAAE/C,MAAMM,KAAKT,OAAOqJ,UACpBnG,EAAE2B,gBAAgBpE,KAAKT,OAAOsN,MAAO7M,MACrCyC,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,MAEZ,EC1CK,MAAM8M,gBAAgBjN,KAI3B,YAAOiD,CAAMR,GAEX,MAAM/C,EAAS,CAAC,EACVoE,EAAMC,EAAa,IAAIkJ,QAAQ,CAAEzQ,OAAQiG,EAAUjG,OAAQkD,YAEjE,GADAA,EAAOR,KAAOuD,EAAUoB,QAAQ,WAC3BnE,EAAOR,KAaZ,OAVA4E,EAAI/C,QACF8E,EAA8BpD,EAAW,iBACzCA,EAAUlG,MAAM,wBAClBmD,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,wBAClBkG,EAAU/F,QAAUoH,EAAI3D,KACxBT,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,sCACXuH,EAAI3D,IACb,CAEA,QAAIrC,GACF,MAAO,SACT,CACA,QAAIa,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAEA,SAACwI,CAAS9D,SACDb,KAAKY,QAAQ+D,SAAS9D,EAC/B,CAGA,KAAA2B,CAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,OACvCyC,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,MAEZ,EC9CK,MAAM+M,yBAAyBlN,KAIpC,YAAOiD,CAAMR,EAAWvD,GACtB,MAAMQ,EAAS,CAAER,QACX4E,EAAMC,EACV,IAAImJ,iBAAiB,CAAE1Q,OAAQiG,EAAUjG,OAAQkD,YAmBnD,OAjBAA,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,yBAClBkG,EAAU/F,QAAUoH,EAAI3D,KACxBT,EAAOkE,OACLnB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,gCAC5CuH,EAAI/C,QACF6E,EAAYnD,IAAcA,EAAUlG,MAAM,gCAC5CmD,EAAOwE,KACLzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,4CAClBuH,EAAIe,UAAYT,EAAc3B,GAC9B/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,yBAC5CmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,uCACXuH,EAAI3D,IACb,CAEA,QAAIrC,GACF,MAAO,UACT,CACA,QAAIa,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CAEA,SAACwI,CAAS9D,SACDb,KAAKsG,SAAS3B,SAAS9D,GAC9B,IAAK,MAAMgE,KAAO7E,KAAK0E,UAErB,SADOG,EAAIF,SAAS9D,GACQ,mBAAxBgE,EAAIjE,QAAQsF,QAA8B,CAC5C,MAAM1J,EAAU,wEACViD,EACJoF,EAAItF,OAAOf,KACXqG,EACA,2BACArI,EAEJ,OAEKwD,KAAKY,QAAQ+D,SAAS9D,EAC/B,CAGA,KAAA2B,CAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,OACvCyC,EAAE/C,MAAMM,KAAKT,OAAOkE,QACpBhB,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE/C,MAAMM,KAAKT,OAAOwE,SACjB/D,KAAK0E,UAAUpH,KAAKuH,GAAQA,EAAIrC,MAAMC,KACzCA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,MAEZ,EC/CK,MAAMgN,kBAAkBnN,KAM7B,YAAOiD,CAAMR,EAAW2K,GAAU,YAAEC,EAAW,eAAEC,IAC/C,MAAM,OAAE5N,EAAM,KAAE5B,GAASsP,EAWzB,IAVA1N,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,mBAAmBuB,KACrC2E,EAAU/F,QAAU0Q,EACpBA,EAAWrJ,EAAaqJ,GACpBC,GACF1R,OAAOiI,OAAOlE,EAtCpB,SAAqB+C,GACnB,MAAM8K,EAAQ9K,EAAUoB,QAAQ,KAChC,OAAK0J,EAME,CAAEA,QAAO/M,YAFdiC,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,6BAJT,CAAC,CAMZ,CA6B4BiE,CAAYiC,IAEpC/C,EAAOwE,KAAOzB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,YAAYuB,KACpEsP,EAASrL,QAAU,KACN,CAEX,GADArC,EAAO2E,MAAQ5B,EAAUoB,QAAQ,KAC7BnE,EAAO2E,MAIT,OAHA3E,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,2BAA2BuB,KACtCsP,EAASjN,KAElB,MAAMoF,EAAKJ,mBAAmBlC,MAAMR,GACpC,IAAI+K,EACJ,IAAK,MAAOhL,KAAWiL,KAASH,EAE9B,GADAE,EAAMzJ,EAAavB,EAAOC,KAAcgL,IACpCD,EACF,MAGCA,GACH/K,EAAUlG,MAAM,kBAElBiR,EAAI/G,SAAWlB,EACf6H,EAASrL,QAAQqD,KAAKoI,EAAIrN,KAC5B,CACF,CAEA,WAAIvB,GACF,QAASuB,KAAKT,OAAOd,OACvB,CACA,QAAID,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CACA,eAAIkE,GACF,OAAKL,KAAKT,OAAOc,YAGV,EAASL,KAAKT,OAAOc,YAAYlE,OAF/B,IAGX,CAEA,SAACwI,CAAS9D,GACR,IAAK,MAAM0M,KAAUvN,KAAK4B,QACpB2L,EAAO5I,iBACF4I,EAAO5I,SAAS9D,GAG7B,CAGA,KAAA2B,CAAMC,GAcJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOiO,UACpB/K,EAAE/C,MAAMM,KAAKT,OAAOd,SACpBgE,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAE/C,MAAMM,KAAKT,OAAOsN,OACpBpK,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,OApBvB,KACbA,KAAKT,OAAOc,YAGVoC,EAAEC,GAAGC,KAAK,CACfF,EAAE/C,MAAMM,KAAKT,OAAO6N,OACpB3K,EAAEC,GAAGlF,OAAOwC,KAAKT,OAAOc,YAAY7C,QACpCiF,EAAEC,GAAGrC,YACHoC,EAAEnB,UAAUtB,KAAKT,OAAOc,YAAYlE,MAAO,CAAEoC,QAASyB,UANjD,GAmBPK,GACAoC,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAK4B,QAAQtE,KAAKmQ,GAAMA,EAAEjL,MAAMC,MAC1CA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,MAEZ,ECnHK,MAAM0N,iBAAiB7N,KAI5B,YAAOiD,CAAMR,GAEX,MAAM/C,EAAS,CAAC,EAEhB,GADAA,EAAOR,KAAOuD,EAAUoB,QAAQ,UAC3BnE,EAAOR,KACV,OAEF,IAAI6B,EAAUoF,EAAe1D,GAC7B,IAAK1B,EAAS,CACZ,MAAM7B,EACJuD,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,sBAClBwE,EAAU,IAAI4E,KAAK,CAAEnJ,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAER,SAC3D,CACIuD,EAAU6C,MAAM,MAClB7C,EAAUlG,MAAM,qCAElBwE,EAAQjD,KAAO,aACf4B,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,sBAClBmD,EAAOkE,OACLnB,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,gCAC5CmD,EAAOpD,MACLmL,EAAYhF,IAAcA,EAAUlG,MAAM,uBAC5CmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,oCAClB,MAAMuH,EAAM,IAAI+J,SAAS,CAAErR,OAAQiG,EAAUjG,OAAQkD,WAErD,OADAqE,EAAaD,GAAK/C,QAAUA,EACrB+C,CACT,CAEA,QAAIhG,GACF,MAAO,OACT,CACA,QAAIa,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CACA,SAAIA,GACF,OAAOqL,EAAWxH,KAAKT,OAAOpD,MAChC,CAGA,KAAAqG,CAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,MACpB0D,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,KAAMpB,WAC7C6D,EAAE/C,MAAMM,KAAKT,OAAOkE,QACpBhB,EAAE/C,MAAMM,KAAKT,OAAOpD,OACpBsG,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,KAAMpB,UAElB,EChEK,MAAM+O,qBAAqB9N,KAIhC,YAAOiD,CAAMR,GACX,MAAMqF,EAAiBrF,EAAUhG,SAC3BqH,EAAMC,EACV,IAAI+J,aAAa,CAAEtR,OAAQiG,EAAUjG,OAAQkD,OAAQ,CAAC,MAElD,OAAEA,GAAWoE,EAUnB,GATApE,EAAO2J,SAAW5G,EAAUoB,QAAQ,YAC/BnE,EAAO2J,WACV3J,EAAOqO,MAAQtL,EAAUoB,QAAQ,UAEnCnE,EAAOR,KAAOQ,EAAO2J,SACjB5G,EAAUoB,QAAQ,UAAW,WAC7BnE,EAAOqO,MACLtL,EAAUoB,QAAQ,YAClBpB,EAAUoB,QAAQ,WAAY,iBAAkB,UAAW,YAC5DnE,EAAOR,KAEV,YADAuD,EAAU4C,UAAUyC,GAItB,MAAM,KAAEhK,GAASgG,EACXkK,EAA8B,YAATlQ,EACrBmQ,EACJD,GAA+B,aAATlQ,GAAgC,mBAATA,EACzCoQ,EACK,mBAATpQ,GAA8BgG,EAAIiK,OAAkB,aAATjQ,EAE7C4B,EAAOwE,KACLzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,mCAAmCuB,iBACrD,MAAM4L,EACJ7D,EAA8BpD,IAC9BA,EAAUlG,MAAM,8BAA8BuB,iBAiChD,OAhCAgG,EAAI/C,QAAU,CAAC2I,GACf5F,EAAIe,UAAY,GAEZoJ,IACFvE,EAAMhK,OAAOqD,UAAYN,EAAUoB,QAAQ,KACvC6F,EAAMhK,OAAOqD,UACfe,EAAI/C,QAAQqE,KAAKS,EAA8BpD,IACtCuL,GACTvL,EAAUlG,MAAM,mCAAmCuB,kBAIvD4B,EAAO2E,MACL5B,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,sCAAsCuB,iBAEpD2E,EAAU6C,MAAM,OACd4I,GACFxO,EAAOyO,SAAW1L,EAAUoB,QAAQ,KACpCC,EAAIe,UAAUO,QAAQhB,EAAc3B,IACpC/C,EAAO0O,UACL3L,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,8CAElBkG,EAAUlG,MAAM,oDAIpBmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,2BAA2BuB,iBAEtCgG,EAAI3D,IACb,CAEA,QAAIrC,GACF,OAAOqC,KAAKT,OAAOR,KAAK5C,KAC1B,CACA,YAAI+M,GACF,QAASlJ,KAAKT,OAAO2J,QACvB,CACA,SAAI0E,GACF,QAAS5N,KAAKT,OAAOqO,KACvB,CAEA,SAACjJ,CAAS9D,GACR,GAAIb,KAAK4N,OAAuB,aAAd5N,KAAKrC,KAAqB,CAC1C,MAAMnB,EAAU,6DACViD,EACJO,KAAKT,OAAOqO,MACZ5N,KACA,iCACAxD,EACA,CACEG,SAoC0BuR,EApCUlO,KAqCrC,KACL,MAAM4N,EAAQM,EAAa3O,OAAOqO,MAClCM,EAAa3O,OAAOR,KAAO,IACtB6O,EACHjQ,KAAM,iBACNxB,MAAO,yBAEF+R,EAAa3O,OAAOqO,KAAK,IAzChC,CAiCJ,IAAoCM,EAhChC,IAAK,MAAMvQ,KAAQqC,KAAKY,cACfjD,EAAKgH,SAAS9D,GAEvB,IAAK,MAAMgI,KAAY7I,KAAK0E,gBACnBmE,EAASlE,SAAS9D,EAE7B,CAGA,KAAA2B,CAAMC,GACJ,OAAOA,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAO2J,UACpBzG,EAAE/C,MAAMM,KAAKT,OAAOqO,OACpBnL,EAAE/C,MAAMM,KAAKT,OAAOR,KAAM0D,EAAEC,GAAGwD,SAC/BzD,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAKY,QAAQtD,KAAKC,GAAMA,EAAEiF,MAAMC,MAC1CA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOyO,UACpBvL,EAAEC,GAAGC,KAAK3C,KAAK0E,UAAUpH,KAAKuH,GAAQA,EAAIrC,MAAMC,MAChDA,EAAE/C,MAAMM,KAAKT,OAAO0O,WACpBxL,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,KAAMpB,OAAQoB,KAAKpB,QAE/B,EC9HK,MAAMuP,oBAAoBtO,KAI/B,YAAOiD,CAAMR,GACX,MAAMvD,EAAOuD,EAAUoB,QAAQ,eAC/B,IAAK3E,EACH,OAGF,MAAMQ,EAAS,CAAER,QACjBQ,EAAOwE,KACLzB,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,mCAClB,MAAMkR,EAAOrJ,EAAc3B,GAC3B/C,EAAO2E,MACL5B,EAAUoB,QAAQ,MAAQpB,EAAUlG,MAAM,4BAC5CmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,kCAClB,MAAMuH,EAAM,IAAIwK,YAAY,CAAE9R,OAAQiG,EAAUjG,OAAQkD,WAExD,OADAqE,EAAaD,GAAKe,UAAY4I,EACvB3J,CACT,CAEA,QAAIhG,GACF,MAAO,aACT,CAEA,SAACgH,CAAS9D,GACR,IAAK,MAAMgI,KAAY7I,KAAK0E,gBACnBmE,EAASlE,SAAS9D,EAE7B,CAGA,KAAA2B,CAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOR,KAAM0D,EAAEC,GAAGqG,SAAU,CAAET,KAAMtI,KAAMpB,WACvD6D,EAAE/C,MAAMM,KAAKT,OAAOwE,MACpBtB,EAAEC,GAAGC,KAAK3C,KAAK0E,UAAUpH,KAAKuH,GAAQA,EAAIrC,MAAMC,MAChDA,EAAE/C,MAAMM,KAAKT,OAAO2E,OACpBzB,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,KAAMpB,UAElB,EC7BF,SAASwP,EAAc9L,GACrB,MAAMmG,EAAUnG,EAAUoB,QAAQ,UAClC,IAAK+E,EAAS,OAKd,OAHEO,UAAUlG,MAAMR,EAAW,CAAEmG,aAC7BD,UAAU1F,MAAMR,EAAW,CAAEmG,aAC7BnG,EAAUlG,MAAM,2BAEpB,CAEO,MAAMiS,kBAAkBrB,UAQ7B,YAAOlK,CAAMR,EAAWvD,GAAM,WAAEuP,EAAa,GAAE,QAAE7P,EAAU,MAAS,CAAC,GACnE,MAAMc,EAAS,CAAEd,UAASM,QAC1B,OAAOiO,UAAUlK,MACfR,EACA,IAAI+L,UAAU,CAAEhS,OAAQiG,EAAUjG,OAAQkD,WAC1C,CACE2N,aAAczO,EACd0O,eAAgB,IACXmB,EACH,CAACZ,SAAS5K,OACV,CAACqL,YAAYrL,OACb,CAACsL,GACD,CAACtE,GACD,CAAC6D,aAAa7K,OACd,CAACkG,UAAUlG,OACX,CAAC0F,UAAU1F,SAInB,CAEA,QAAInF,GACF,MAAO,WACT,CAEA,SAACgH,CAAS9D,GAER,SADOb,KAAKsG,SAAS3B,SAAS9D,IAE3Bb,KAAKvB,SACNuB,KAAKsG,SAASiI,OAAO3J,GAA6B,YAAjBA,EAAQpG,OACzC,CACA,MAAMhC,EAAU,oTAKViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,kBACAxD,EACA,CACEG,QAASuN,EAAwBlK,OAGvC,CACA,MAAMwO,EAAkBxO,KAAKsG,SAASI,QACnC9B,GAA6B,gBAAjBA,EAAQpG,OAEvB,IAAK,MAAMsB,KAAe0O,EAAiB,CACzC,MAAMhS,EAAU,oRAIViD,EACJK,EAAYP,OAAOf,KACnBwB,KACA,qBACAxD,EACA,CACEG,QAAS8R,EAAmBzO,KAAMF,IAGxC,CAGA,GADiBE,KAAKsG,SAASzE,MAAM+C,GAA6B,WAAjBA,EAAQpG,OAC3C,CACZ,MAAMkQ,EAAmB1O,KAAKsG,SAASI,QACpC9B,GAA6B,0BAAjBA,EAAQpG,OAEvB,IAAK,MAAMmQ,KAASD,EAAkB,CACpC,MAAMlS,EAAU,uEACViD,EACJkP,EAAMpP,OAAOf,KACbwB,KACA,0BACAxD,EAEJ,CAEA,MAAMoS,EAAe5O,KAAK4B,QAAQ8E,QAC/B6G,GAA2B,gBAAhBA,EAAO5P,OAErB,IAAK,MAAMgR,KAASC,EAAc,CAChC,MAAMpS,EAAU,kEACViD,EACJkP,EAAMpP,OAAOR,KACbiB,KACA,0BACAxD,EAEJ,CACF,OAEO2F,MAAMwC,SAAS9D,GACjBb,KAAKvB,gBClIP,UAA0CoC,EAAMgO,GACrD,MAAMC,EA8CN,SAA6BD,GAC3B,MAAME,EAAMC,EAAcH,GAC1B,MAAO,CACLI,QAAS,IAAIC,IACXH,EAAIrI,QAAQyI,GAAsB,WAAfA,EAAG1G,UAAsBnL,KAAK6R,GAAOA,EAAG3Q,QAE7D4Q,WAAY,IAAIF,IACdH,EAAIrI,QAAQyI,GAAsB,WAAfA,EAAG1G,UAAsBnL,KAAK6R,GAAOA,EAAG3Q,QAGjE,CAxDgB6Q,CAAoBR,GAC9BS,EAAWzO,EAAKyO,SAAS3T,IAAIkT,EAAErQ,OAAS,GACxC+Q,EAAS1O,EAAK2O,SAAS7T,IAAIkT,EAAErQ,OAAS,GAC5C,IAAK,MAAMiR,IAAO,IAAIH,KAAaC,GAAS,CAC1C,MAAMG,EAAYV,EAAcS,GAC1BR,EAAUS,EAAUhJ,QAAQwB,GAAoB,WAAdA,EAAEO,UACpC2G,EAAaM,EAAUhJ,QAAQwB,GAAoB,WAAdA,EAAEO,gBACtCkH,EAAeV,EAASH,EAAQG,QAASQ,EAAKZ,SAC9Cc,EAAeP,EAAYN,EAAQM,WAAYK,EAAKZ,GAC3DI,EAAQW,SAAST,GAAOL,EAAQG,QAAQY,IAAIV,EAAG3Q,QAC/C4Q,EAAWQ,SAAST,GAAOL,EAAQM,WAAWS,IAAIV,EAAG3Q,OACvD,CAQA,SAAUmR,EAAeD,EAAWI,EAAWL,EAAK1Q,GAClD,IAAK,MAAMgR,KAAYL,EAAW,CAChC,MAAM,KAAElR,GAASuR,EACjB,GAAIvR,GAAQsR,EAAU1O,IAAI5C,GAAO,CAC/B,MACMhC,EAAU,OADsB,WAArBuT,EAAStH,QAAuB,UAAY,gBAChBjK,uDAA0DO,EAAKP,6CACtGiB,EACJsQ,EAASxQ,OAAOf,KAChBiR,EACA,oBACAjT,EAEJ,CACF,CACF,CAMA,SAASwS,EAAcH,GACrB,OAAOA,EAAEjN,QAAQ8E,QAAO,EAAG/I,UAAoB,cAATA,GACxC,CAgBF,CDyEaqS,CAAgCnP,EAAMb,MAEjD,EAGF,SAASyO,EAAmBwB,EAAcC,GAExC,OADAD,EAAerM,EAAaqM,GACrB,KACL,MAAME,EAAcpG,EAClBkG,EAAa3J,SAAS/G,OAAOwE,KAAKvG,QAE9B4S,EAAeH,EAAarO,QAAQhE,OACtCmM,EAAmB3B,EAAc6H,EAAarO,QAAQ,IAAIpE,QVgD3D,SAA8B6S,GACnC,MAAMF,EAAcpG,EAAmBsG,GACjCC,EAAWH,EAAYvH,SAAS,MAAQ,KAAO,KACrD,OAAOuH,EAAcG,CACvB,CUnDQC,CAAqBJ,GACnBK,EAAgBrC,YAAYrL,MAChC,IAAIyF,UAAU,KAAK6H,oBAErBI,EAAclK,SAAW,IAAItB,mBAAmB,CAC9C3I,OAAQ4T,EAAa5T,OACrBkD,OAAQ,CAAC,IAEXqE,EAAa4M,GAAe9L,UAAYwL,EAAmBxL,UAE3D,MAAM+L,EVwFH,SAAuBC,EAAOC,GACnC,MAAM/Q,EAAQ8Q,EAAM3T,QAAQ6T,UAAUC,UAAUF,GAChD,OAAe,IAAX/Q,EACKA,EAEF8Q,EAAM9S,OAASgC,EAAQ,CAChC,CU9F0BkR,CACpBb,EAAarO,SACZ6L,GAAiB,gBAAXA,EAAE9P,OAEXsS,EAAarO,QAAQuF,OAAOsJ,EAAgB,EAAG,EAAGD,GAElD,MAAM,MAAEtM,GAAU+L,EAAa1Q,OAC1B2E,EAAM1G,OAAOoL,SAAS,QACzB1E,EAAM1G,QAAU,KAAK2S,KAGvB,MAAM,SAAE7J,GAAa2J,EACfrQ,EAAQ0G,EAASY,QAAQgJ,GACzBa,EAAUzK,EAASa,OAAOvH,EAAO,GAClC0G,EAAS1I,OAEH0I,EAAS1I,SAAWgC,EAC7B0G,EAAS1G,EAAQ,GAAGL,OAAOqD,eAAYxC,EAC7BkG,EAAS1G,GAAOL,OAAOf,KAAKhB,OAAOwT,SAC7C1K,EAAS1G,GAAOL,OAAOf,KAAKhB,OAASuT,EAAQ,GAAGxR,OAAOf,KAAKhB,QAJ5D8I,EAAS/G,OAAOwE,KAAOuC,EAAS/G,OAAO2E,WAAQ9D,CAKjD,CAEJ,CEhLO,MAAM6Q,cAAcjE,UAQzB,YAAOlK,CAAMR,EAAWvD,GAAM,WAAEuP,EAAa,GAAE,QAAE7P,GAAY,CAAC,GAC5D,MAAMc,EAAS,CAAEd,UAASM,QAE1B,GADAQ,EAAOsN,MAAQvK,EAAUoB,QAAQ,SAC5BnE,EAAOsN,MAGZ,OAAOG,UAAUlK,MACfR,EACA,IAAI2O,MAAM,CAAE5U,OAAQiG,EAAUjG,OAAQkD,WACtC,CACE4N,eAAgB,IACXmB,EACH,CAACZ,SAAS5K,OACV,CAACgH,GACD,CAACd,UAAUlG,MAAO,CAAEmG,WAAW,IAC/B,CAACT,UAAU1F,MAAO,CAAE4F,SAAS,MAIrC,CAEA,QAAI/K,GACF,MAAO,iBACT,EC5BK,MAAMuT,cAAcrR,KAIzB,YAAOiD,CAAMR,GAEX,MAAM/C,EAAS,CAAC,EACVoE,EAAMC,EAAa,IAAIsN,MAAM,CAAE7U,OAAQiG,EAAUjG,OAAQkD,YAe/D,OAdAoE,EAAI2C,SAAWtB,mBAAmBlC,MAAMR,GACxC/C,EAAOwC,SAAWO,EAAUoB,QAAQ,YACpCC,EAAI/C,QACF8E,EAA8BpD,EAAW,oBACzCA,EAAUlG,MAAM,kCAClBmD,EAAOf,KACL8D,EAAUC,YAAY,eACtBD,EAAUlG,MAAM,kCAClBuH,EAAIoE,QAAUV,QAAQvE,MAAMR,GACxB/C,EAAOwC,UAAY4B,EAAIoE,SACzBzF,EAAUlG,MAAM,2CAClBmD,EAAOoJ,YACLrG,EAAUoB,QAAQ,MAClBpB,EAAUlG,MAAM,gDACXuH,EAAI3D,IACb,CAEA,QAAIrC,GACF,MAAO,OACT,CACA,QAAIa,GACF,OAAO,EAASwB,KAAKT,OAAOf,KAAKrC,MACnC,CACA,YAAI4F,GACF,QAAS/B,KAAKT,OAAOwC,QACvB,CAEA,SAAC4C,CAAS9D,SACDb,KAAKY,QAAQ+D,SAAS9D,EAC/B,CAGA,KAAA2B,CAAMC,GACJ,MAAM,OAAE7D,GAAWoB,KACnB,OAAOyC,EAAEC,GAAGrH,WACVoH,EAAEC,GAAGC,KAAK,CACR3C,KAAKsG,SAAS9D,MAAMC,GACpBA,EAAE/C,MAAMM,KAAKT,OAAOwC,UACpBU,EAAEC,GAAG/E,KAAKqC,KAAKY,QAAQ4B,MAAMC,IAC7BA,EAAE4F,WAAWrI,KAAKT,OAAOf,KAAM,CAAE8J,KAAMtI,KAAMpB,WAC7CoB,KAAK+H,QAAU/H,KAAK+H,QAAQvF,MAAMC,GAAK,GACvCA,EAAE/C,MAAMM,KAAKT,OAAOoJ,eAEtB,CAAEL,KAAMtI,KAAMpB,UAElB,EC3DK,MAAMuS,mBAAmBnE,UAO9B,YAAOlK,CAAMR,GAAW,WAAEgM,EAAa,GAAE,QAAE7P,GAAY,CAAC,GACtD,MAAMc,EAAS,CAAEd,WAEjB,GADAc,EAAOR,KAAOuD,EAAUoB,QAAQ,cAC3BnE,EAAOR,KAGZ,OAAOiO,UAAUlK,MACfR,EACA,IAAI6O,WAAW,CAAE9U,OAAQiG,EAAUjG,OAAQkD,WAC3C,CACE2N,aAAczO,EACd0O,eAAgB,IAAImB,EAAY,CAAC4C,MAAMpO,SAG7C,CAEA,QAAInF,GACF,MAAO,YACT,ECrBK,MAAMyT,kBAAkBpE,UAO7B,YAAOlK,CAAMR,GAAW,WAAEgM,EAAa,GAAE,QAAE7P,GAAY,CAAC,GACtD,MAAMc,EAAS,CAAEd,WAEjB,GADAc,EAAOR,KAAOuD,EAAUoB,QAAQ,aAC3BnE,EAAOR,KAGZ,OAAOiO,UAAUlK,MACfR,EACA,IAAI8O,UAAU,CAAE/U,OAAQiG,EAAUjG,OAAQkD,WAC1C,CACE4N,eAAgB,IACXmB,EACH,CAACtF,UAAUlG,MAAO,CAAEmG,WAAW,EAAMC,UAAU,IAC/C,CAACwE,SAAS5K,OACV,CAAC0F,UAAU1F,MAAO,CAAE4F,SAAS,MAIrC,CAEA,QAAI/K,GACF,MAAO,WACT,CAEA,SAACgH,CAAS9D,GACR,IACGb,KAAKvB,SACNuB,KAAKsG,SAASiI,OAAO3J,GAA6B,YAAjBA,EAAQpG,OACzC,CACA,MAAMhC,EAAU,gTAKViD,EACJO,KAAKT,OAAOf,KACZwB,KACA,kBACAxD,EACA,CACEG,QAASuN,EAAwBlK,OAGvC,OACOmC,MAAMwC,SAAS9D,EACxB,ECvDK,MAAMwQ,0BAA0BrE,UAOrC,YAAOlK,CAAMR,EAAWkL,GAAU,WAAEc,EAAa,IAAO,CAAC,GACvD,MAAM/O,EAAS,CAAEiO,YAEjB,GADAjO,EAAOR,KAAOuD,EAAUoB,QAAQ,aAC3BnE,EAAOR,KAGZ,OAAOiO,UAAUlK,MACfR,EACA,IAAI+O,kBAAkB,CAAEhV,OAAQiG,EAAUjG,OAAQkD,WAClD,CACE4N,eAAgB,IACXmB,EACH,CAACZ,SAAS5K,OACV,CAAC0F,UAAU1F,MAAO,CAAE4F,SAAS,MAIrC,CAEA,QAAI/K,GACF,MAAO,oBACT,ECDF,SAAS2T,EAAchP,EAAW3C,GAChC,MAAMtD,EAASiG,EAAUjG,OAEzB,SAASD,EAAM4N,GACb1H,EAAUlG,MAAM4N,EAClB,CAEA,SAAStG,KAAW6I,GAClB,OAAOjK,EAAUoB,WAAW6I,EAC9B,CAaA,SAASgF,EAAWC,GAClB,MAAMzS,EAAO2E,EAAQ,aACrB,GAAK3E,EACL,OACEkS,MAAMnO,MAAMR,EAAWvD,EAAM,IACxByS,KACA7R,GAAS8R,YAAY5E,SAE1BwB,UAAUvL,MAAMR,EAAWvD,EAAM,IAC5ByS,KACA7R,GAAS8R,YAAYC,aAE1BtV,EAAM,+BAEV,CAmBA,SAASf,IACP,GAAIsE,EAAQgS,YACV,IAAK,MAAMC,KAAcjS,EAAQgS,YAAa,CAC5C,MAAM1S,EAAS2S,EAAWtP,GAC1B,GAAIrD,EACF,OAAOA,CAEX,CAGF,OAtDF,WACE,MAAMuO,EAAW9J,EAAQ,YACzB,GAAK8J,EACL,OAAIlL,EAAU6C,MAAM,aACXkM,kBAAkBvO,MAAMR,EAAWkL,EAAU,IAC/C7N,GAAS8R,YAAYI,oBAGrB9E,iBAAiBjK,MAAMR,EAAWkL,EAC3C,CA8CIA,IACA+D,KA7BJ,WACE,MAAM9S,EAAUiF,EAAQ,WACxB,GAAKjF,EACL,OACE0S,WAAWrO,MAAMR,EAAW,CAC1B7D,aACGkB,GAAS8R,YAAYlQ,cAE1BgQ,EAAW,CAAE9S,aACb2S,UAAUtO,MAAMR,EAAW,CACzB7D,aACGkB,GAAS8R,YAAYK,aAE1B1V,EAAM,oCAEV,CAeIqC,IACA0S,WAAWrO,MAAMR,EAAW3C,GAAS8R,YAAYlQ,aACjDmL,KAAK5J,MAAMR,IACXwK,QAAQhK,MAAMR,IACdsK,SAAS9J,MAAMR,IACf8O,UAAUtO,MAAMR,EAAW3C,GAAS8R,YAAYK,UAEpD,CAsBA,MAAMC,EApBN,WACE,IAAK1V,EAAOuB,OAAQ,MAAO,GAC3B,MAAMiD,EAAO,GACb,OAAa,CACX,MAAMuE,EAAKJ,mBAAmBlC,MAAMR,GAC9BtB,EAAM3F,IACZ,IAAK2F,EAAK,CACJoE,EAAGxH,QAAQxB,EAAM,6BACrB,KACF,CACAwH,EAAa5C,GAAKsF,SAAWlB,EAC7BvE,EAAKoE,KAAKjE,EACZ,CACA,MAAMgR,EAAMnP,IAAIC,MAAMR,GAItB,OAHI3C,EAAQsS,UACVpR,EAAKoE,KAAK+M,GAELnR,CACT,CAEYqR,GAEZ,OADI5P,EAAUhG,SAAWD,EAAOuB,QAAQxB,EAAM,uBACvC2V,CACT,CAMO,SAASjP,EAAMkH,EAAKrK,EAAU,CAAC,GACpC,MAAM2C,EAAY,IAAIiG,UAAUyB,GAKhC,YAJkC,IAAvBrK,EAAQN,aAEjBiD,EAAUjG,OAAOmC,KAAOmB,EAAQN,YAE3BiS,EAAchP,EAAW3C,EAClC,CChJA,SAASwS,EAAKtN,GACZ,OAAOA,CACT,CAEA,MAAMuN,EAAY,CAChBzP,KAAO6G,GAAUA,EAAM/L,KAAK,IAC5BD,OAAQ2U,EACR3T,KAAM2T,EACN7Q,UAAW6Q,EACXxU,KAAMwU,EACNjM,QAASiM,EACTpJ,SAAUoJ,EACV9R,YAAa8R,EACb9W,WAAY8W,EACZrN,kBAAmBqN,EACnBpN,2BAA4BoN,GAGvB,MAAME,OACX,WAAAvS,CAAY4C,GACV1C,KAAK0C,GAAKlH,OAAOiI,OAAO,CAAC,EAAG2O,EAAW1P,EACzC,CASA,SAAApB,CAAUgR,GAAK,UAAEtL,EAAS,QAAEzI,IAI1B,OAHKyI,IACHA,EAAYsL,EAAIjJ,WAAW,KAAOiJ,EAAIvV,MAAM,GAAKuV,GAE5CtS,KAAK0C,GAAGpB,UAAUgR,EAAKtL,EAAWzI,EAC3C,CAQA,KAAAmB,CAAMnC,EAAGgV,EAAUJ,KAAS7E,GAC1B,IAAK/P,EACH,MAAO,GAET,MAAMpB,EAAQoW,EAAQhV,EAAEpB,SAAUmR,GAClC,OAAOtN,KAAK0C,GAAGC,KAAK,CAAC3C,KAAK0C,GAAGlF,OAAOD,EAAEC,QAASrB,GACjD,CAEA,eAAAiI,CAAgB7G,EAAGgB,GACjB,OAAOyB,KAAKN,MAAMnC,EAAGyC,KAAKsB,UAAUkR,KAAKxS,MAAO,CAAEzB,WACpD,CAEA,UAAA8J,CAAW9K,EAAGsH,GACZ,OAAO7E,KAAKN,MAAMnC,EAAGyC,KAAK0C,GAAGlE,KAAMqG,EACrC,CAEA,UAAAP,CAAWmO,EAAIlU,GACb,OAAOyB,KAAK0C,GAAGC,KAAK,CAClB3C,KAAKoE,gBAAgBqO,EAAGlT,OAAOpD,MAAOoC,GACtCyB,KAAKN,MAAM+S,EAAGlT,OAAOqD,YAEzB,EAGK,SAASJ,EAAMkQ,GAAON,UAAW1P,EAAK0P,GAAc,CAAC,GAC1D1P,EAAKlH,OAAOiI,OAAO,CAAC,EAAG2O,EAAW1P,GAElC,MAAMD,EAAI,IAAI4P,OAAO3P,GAErB,OAAOA,EAAGC,KAAK+P,EAAIpV,KAAKqV,GAAOA,EAAGnQ,MAAMC,KAC1C,CCvEA,SAASmQ,EAAYC,EAAK5R,GACxB,MAAM3D,EAAM,IAAI8F,IACVwF,EAAWiK,EAAInM,QAAQ1F,GAAqB,aAAbA,EAAIrD,OACzC,IAAK,MAAMmV,KAAWlK,EAAU,CAC9B,MAAMiE,EAAQ5L,EAAOtF,IAAImX,EAAQlK,UACjC,IAAKiE,EACH,SAEF,MAAM6D,EAAQpT,EAAI3B,IAAImX,EAAQ9T,QAC1B0R,EACFA,EAAMzL,KAAK4H,GAEXvP,EAAI+D,IAAIyR,EAAQ9T,OAAQ,CAAC6N,GAE7B,CACA,OAAOvP,CACT,CAmDA,SAAUyV,EAAiBL,GACzB,MAAM7R,EA/CR,SAA0BgS,GACxB,MAAM5R,EAAS,IAAImC,IACb4P,EAAa,IAAI9D,IACjBI,EAAW,IAAIlM,IACrB,IAAK,MAAMpC,KAAO6R,EAChB,GAAI7R,EAAIvC,QAAR,CACE,MAAMiS,EAAQpB,EAAS3T,IAAIqF,EAAIxC,MAC3BkS,EACFA,EAAMzL,KAAKjE,GAEXsO,EAASjO,IAAIL,EAAIxC,KAAM,CAACwC,GAG5B,MACKA,EAAIxC,OAGJyC,EAAOG,IAAIJ,EAAIxC,MAGlBwU,EAAWnD,IAAI7O,GAFfC,EAAOI,IAAIL,EAAIxC,KAAMwC,IAKzB,MAAO,CACL6R,MACA5R,SACAqO,WACA0D,aACAxD,SAAUoD,EAAYC,EAAK5R,GAC3BE,MAAO,CACLD,0BAA2B,IAAI+R,QAC/BvR,gCAAiC,IAAIuR,SAG3C,CAaeC,CAAiBR,GAC9B,IAAK,MAAM1R,KAAOH,EAAKgS,IACjB7R,EAAI2D,iBACC3D,EAAI2D,SAAS9D,UAd1B,WAA+B,OAAEI,EAAM,WAAE+R,IACvC,IAAK,MAAMG,KAAOH,EAAY,CAC5B,MAAM,KAAExU,GAAS2U,EACX3W,EAAU,aAAagC,eAC3ByC,EAAOtF,IAAI6C,GAAMb,+BAEb,EAAMwV,EAAI5T,OAAOf,KAAM2U,EAAK,eAAgB3W,EACpD,CACF,CASS4W,CAAqBvS,EAC9B,CAcO,SAAS8D,EAAS+N,GACvB,MAAO,IAAIK,GAZIrC,EAYqBgC,EAXhChC,EAAM2C,KACD3C,EAAM2C,OAER,GAAGjI,UAAUsF,MAJtB,IAAiBA,CAajB,C","sources":["webpack://WebIDL2/webpack/universalModuleDefinition","webpack://WebIDL2/webpack/bootstrap","webpack://WebIDL2/webpack/runtime/define property getters","webpack://WebIDL2/webpack/runtime/hasOwnProperty shorthand","webpack://WebIDL2/webpack/runtime/make namespace object","webpack://WebIDL2/./lib/error.js","webpack://WebIDL2/./lib/productions/base.js","webpack://WebIDL2/./lib/validators/helpers.js","webpack://WebIDL2/./lib/productions/array-base.js","webpack://WebIDL2/./lib/productions/token.js","webpack://WebIDL2/./lib/productions/extended-attributes.js","webpack://WebIDL2/./lib/productions/type.js","webpack://WebIDL2/./lib/productions/default.js","webpack://WebIDL2/./lib/productions/argument.js","webpack://WebIDL2/./lib/productions/operation.js","webpack://WebIDL2/./lib/productions/attribute.js","webpack://WebIDL2/./lib/productions/helpers.js","webpack://WebIDL2/./lib/tokeniser.js","webpack://WebIDL2/./lib/productions/enum.js","webpack://WebIDL2/./lib/productions/includes.js","webpack://WebIDL2/./lib/productions/typedef.js","webpack://WebIDL2/./lib/productions/callback.js","webpack://WebIDL2/./lib/productions/container.js","webpack://WebIDL2/./lib/productions/constant.js","webpack://WebIDL2/./lib/productions/iterable.js","webpack://WebIDL2/./lib/productions/constructor.js","webpack://WebIDL2/./lib/productions/interface.js","webpack://WebIDL2/./lib/validators/interface.js","webpack://WebIDL2/./lib/productions/mixin.js","webpack://WebIDL2/./lib/productions/field.js","webpack://WebIDL2/./lib/productions/dictionary.js","webpack://WebIDL2/./lib/productions/namespace.js","webpack://WebIDL2/./lib/productions/callback-interface.js","webpack://WebIDL2/./lib/webidl2.js","webpack://WebIDL2/./lib/writer.js","webpack://WebIDL2/./lib/validator.js"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"WebIDL2\"] = factory();\n\telse\n\t\troot[\"WebIDL2\"] = factory();\n})(globalThis, () => {\nreturn ","// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","/**\n * @param {string} text\n */\nfunction lastLine(text) {\n  const splitted = text.split(\"\\n\");\n  return splitted[splitted.length - 1];\n}\n\nfunction appendIfExist(base, target) {\n  let result = base;\n  if (target) {\n    result += ` ${target}`;\n  }\n  return result;\n}\n\nfunction contextAsText(node) {\n  const hierarchy = [node];\n  while (node && node.parent) {\n    const { parent } = node;\n    hierarchy.unshift(parent);\n    node = parent;\n  }\n  return hierarchy.map((n) => appendIfExist(n.type, n.name)).join(\" -> \");\n}\n\n/**\n * @typedef {object} WebIDL2ErrorOptions\n * @property {\"error\" | \"warning\"} [level]\n * @property {Function} [autofix]\n * @property {string} [ruleName]\n *\n * @typedef {ReturnType<typeof error>} WebIDLErrorData\n *\n * @param {string} message error message\n * @param {*} position\n * @param {*} current\n * @param {*} message\n * @param {\"Syntax\" | \"Validation\"} kind error type\n * @param {WebIDL2ErrorOptions=} options\n */\nfunction error(\n  source,\n  position,\n  current,\n  message,\n  kind,\n  { level = \"error\", autofix, ruleName } = {},\n) {\n  /**\n   * @param {number} count\n   */\n  function sliceTokens(count) {\n    return count > 0\n      ? source.slice(position, position + count)\n      : source.slice(Math.max(position + count, 0), position);\n  }\n\n  /**\n   * @param {import(\"./tokeniser.js\").Token[]} inputs\n   * @param {object} [options]\n   * @param {boolean} [options.precedes]\n   * @returns\n   */\n  function tokensToText(inputs, { precedes } = {}) {\n    const text = inputs.map((t) => t.trivia + t.value).join(\"\");\n    const nextToken = source[position];\n    if (nextToken.type === \"eof\") {\n      return text;\n    }\n    if (precedes) {\n      return text + nextToken.trivia;\n    }\n    return text.slice(nextToken.trivia.length);\n  }\n\n  const maxTokens = 5; // arbitrary but works well enough\n  const line =\n    source[position].type !== \"eof\"\n      ? source[position].line\n      : source.length > 1\n        ? source[position - 1].line\n        : 1;\n\n  const precedingLastLine = lastLine(\n    tokensToText(sliceTokens(-maxTokens), { precedes: true }),\n  );\n\n  const subsequentTokens = sliceTokens(maxTokens);\n  const subsequentText = tokensToText(subsequentTokens);\n  const subsequentFirstLine = subsequentText.split(\"\\n\")[0];\n\n  const spaced = \" \".repeat(precedingLastLine.length) + \"^\";\n  const sourceContext = precedingLastLine + subsequentFirstLine + \"\\n\" + spaced;\n\n  const contextType = kind === \"Syntax\" ? \"since\" : \"inside\";\n  const inSourceName = source.name ? ` in ${source.name}` : \"\";\n  const grammaticalContext =\n    current && current.name\n      ? `, ${contextType} \\`${current.partial ? \"partial \" : \"\"}${contextAsText(\n          current,\n        )}\\``\n      : \"\";\n  const context = `${kind} error at line ${line}${inSourceName}${grammaticalContext}:\\n${sourceContext}`;\n  return {\n    message: `${context} ${message}`,\n    bareMessage: message,\n    context,\n    line,\n    sourceName: source.name,\n    level,\n    ruleName,\n    autofix,\n    input: subsequentText,\n    tokens: subsequentTokens,\n  };\n}\n\n/**\n * @param {string} message error message\n */\nexport function syntaxError(source, position, current, message) {\n  return error(source, position, current, message, \"Syntax\");\n}\n\n/**\n * @param {string} message error message\n * @param {WebIDL2ErrorOptions} [options]\n */\nexport function validationError(\n  token,\n  current,\n  ruleName,\n  message,\n  options = {},\n) {\n  options.ruleName = ruleName;\n  return error(\n    current.source,\n    token.index,\n    current,\n    message,\n    \"Validation\",\n    options,\n  );\n}\n","export class Base {\n  /**\n   * @param {object} initializer\n   * @param {Base[\"source\"]} initializer.source\n   * @param {Base[\"tokens\"]} initializer.tokens\n   */\n  constructor({ source, tokens }) {\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens, writable: true },\n      parent: { value: null, writable: true },\n      this: { value: this }, // useful when escaping from proxy\n    });\n  }\n\n  toJSON() {\n    const json = { type: undefined, name: undefined, inheritance: undefined };\n    let proto = this;\n    while (proto !== Object.prototype) {\n      const descMap = Object.getOwnPropertyDescriptors(proto);\n      for (const [key, value] of Object.entries(descMap)) {\n        if (value.enumerable || value.get) {\n          // @ts-ignore - allow indexing here\n          json[key] = this[key];\n        }\n      }\n      proto = Object.getPrototypeOf(proto);\n    }\n    return json;\n  }\n}\n","/**\n * @typedef {import(\"../validator.js\").Definitions} Definitions\n * @typedef {import(\"../productions/dictionary.js\").Dictionary} Dictionary\n * @typedef {import(\"../../lib/productions/type\").Type} Type\n *\n * @param {Type} idlType\n * @param {Definitions} defs\n * @param {object} [options]\n * @param {boolean} [options.useNullableInner] use when the input idlType is nullable and you want to use its inner type\n * @return {{ reference: *, dictionary: Dictionary }} the type reference that ultimately includes dictionary.\n */\nexport function idlTypeIncludesDictionary(\n  idlType,\n  defs,\n  { useNullableInner } = {},\n) {\n  if (!idlType.union) {\n    const def = defs.unique.get(idlType.idlType);\n    if (!def) {\n      return;\n    }\n    if (def.type === \"typedef\") {\n      const { typedefIncludesDictionary } = defs.cache;\n      if (typedefIncludesDictionary.has(def)) {\n        // Note that this also halts when it met indeterminate state\n        // to prevent infinite recursion\n        return typedefIncludesDictionary.get(def);\n      }\n      defs.cache.typedefIncludesDictionary.set(def, undefined); // indeterminate state\n      const result = idlTypeIncludesDictionary(def.idlType, defs);\n      defs.cache.typedefIncludesDictionary.set(def, result);\n      if (result) {\n        return {\n          reference: idlType,\n          dictionary: result.dictionary,\n        };\n      }\n    }\n    if (def.type === \"dictionary\" && (useNullableInner || !idlType.nullable)) {\n      return {\n        reference: idlType,\n        dictionary: def,\n      };\n    }\n  }\n  for (const subtype of idlType.subtype) {\n    const result = idlTypeIncludesDictionary(subtype, defs);\n    if (result) {\n      if (subtype.union) {\n        return result;\n      }\n      return {\n        reference: subtype,\n        dictionary: result.dictionary,\n      };\n    }\n  }\n}\n\n/**\n * @param {Dictionary} dict dictionary type\n * @param {Definitions} defs\n * @return {boolean}\n */\nexport function dictionaryIncludesRequiredField(dict, defs) {\n  if (defs.cache.dictionaryIncludesRequiredField.has(dict)) {\n    return defs.cache.dictionaryIncludesRequiredField.get(dict);\n  }\n  // Set cached result to indeterminate to short-circuit circular definitions.\n  // The final result will be updated to true or false.\n  defs.cache.dictionaryIncludesRequiredField.set(dict, undefined);\n  let result = dict.members.some((field) => field.required);\n  if (!result && dict.inheritance) {\n    const superdict = defs.unique.get(dict.inheritance);\n    if (!superdict) {\n      // Assume required members in the supertype if it is unknown.\n      result = true;\n    } else if (dictionaryIncludesRequiredField(superdict, defs)) {\n      result = true;\n    }\n  }\n  defs.cache.dictionaryIncludesRequiredField.set(dict, result);\n  return result;\n}\n\n/**\n * For now this only checks the most frequent cases:\n * 1. direct inclusion of [EnforceRange]\n * 2. typedef of that\n *\n * More complex cases with dictionaries and records are not covered yet.\n *\n * @param {Type} idlType\n * @param {Definitions} defs\n */\nexport function idlTypeIncludesEnforceRange(idlType, defs) {\n  if (idlType.union) {\n    // TODO: This should ideally be checked too\n    return false;\n  }\n\n  if (idlType.extAttrs.some((e) => e.name === \"EnforceRange\")) {\n    return true;\n  }\n\n  const def = defs.unique.get(idlType.idlType);\n  if (def?.type !== \"typedef\") {\n    return false;\n  }\n\n  return def.idlType.extAttrs.some((e) => e.name === \"EnforceRange\");\n}\n","export class ArrayBase extends Array {\n  constructor({ source, tokens }) {\n    super();\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens },\n      parent: { value: null, writable: true },\n    });\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape } from \"./helpers.js\";\n\nexport class WrappedToken extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {string} type\n   */\n  static parser(tokeniser, type) {\n    return () => {\n      const value = tokeniser.consumeKind(type);\n      if (value) {\n        return new WrappedToken({\n          source: tokeniser.source,\n          tokens: { value },\n        });\n      }\n    };\n  }\n\n  get value() {\n    return unescape(this.tokens.value.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      w.token(this.tokens.value),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\nexport class Eof extends WrappedToken {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const value = tokeniser.consumeKind(\"eof\");\n    if (value) {\n      return new Eof({ source: tokeniser.source, tokens: { value } });\n    }\n  }\n\n  get type() {\n    return \"eof\";\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ArrayBase } from \"./array-base.js\";\nimport { WrappedToken } from \"./token.js\";\nimport { list, argument_list, autoParenter, unescape } from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} tokenName\n */\nfunction tokens(tokeniser, tokenName) {\n  return list(tokeniser, {\n    parser: WrappedToken.parser(tokeniser, tokenName),\n    listName: tokenName + \" list\",\n  });\n}\n\nconst extAttrValueSyntax = [\"identifier\", \"decimal\", \"integer\", \"string\"];\n\nconst shouldBeLegacyPrefixed = [\n  \"NoInterfaceObject\",\n  \"LenientSetter\",\n  \"LenientThis\",\n  \"TreatNonObjectAsNull\",\n  \"Unforgeable\",\n];\n\nconst renamedLegacies = new Map([\n  .../** @type {[string, string][]} */ (\n    shouldBeLegacyPrefixed.map((name) => [name, `Legacy${name}`])\n  ),\n  [\"NamedConstructor\", \"LegacyFactoryFunction\"],\n  [\"OverrideBuiltins\", \"LegacyOverrideBuiltIns\"],\n  [\"TreatNullAs\", \"LegacyNullToEmptyString\"],\n]);\n\n/**\n * This will allow a set of extended attribute values to be parsed.\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction extAttrListItems(tokeniser) {\n  for (const syntax of extAttrValueSyntax) {\n    const toks = tokens(tokeniser, syntax);\n    if (toks.length) {\n      return toks;\n    }\n  }\n  tokeniser.error(\n    `Expected identifiers, strings, decimals, or integers but none found`,\n  );\n}\n\nexport class ExtendedAttributeParameters extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = { assign: tokeniser.consume(\"=\") };\n    const ret = autoParenter(\n      new ExtendedAttributeParameters({ source: tokeniser.source, tokens }),\n    );\n    ret.list = [];\n    if (tokens.assign) {\n      tokens.asterisk = tokeniser.consume(\"*\");\n      if (tokens.asterisk) {\n        return ret.this;\n      }\n      tokens.secondaryName = tokeniser.consumeKind(...extAttrValueSyntax);\n    }\n    tokens.open = tokeniser.consume(\"(\");\n    if (tokens.open) {\n      ret.list = ret.rhsIsList\n        ? // [Exposed=(Window,Worker)]\n          extAttrListItems(tokeniser)\n        : // [LegacyFactoryFunction=Audio(DOMString src)] or [Constructor(DOMString str)]\n          argument_list(tokeniser);\n      tokens.close =\n        tokeniser.consume(\")\") ||\n        tokeniser.error(\"Unexpected token in extended attribute argument list\");\n    } else if (tokens.assign && !tokens.secondaryName) {\n      tokeniser.error(\"No right hand side to extended attribute assignment\");\n    }\n    return ret.this;\n  }\n\n  get rhsIsList() {\n    return (\n      this.tokens.assign && !this.tokens.asterisk && !this.tokens.secondaryName\n    );\n  }\n\n  get rhsType() {\n    if (this.rhsIsList) {\n      return this.list[0].tokens.value.type + \"-list\";\n    }\n    if (this.tokens.asterisk) {\n      return \"*\";\n    }\n    if (this.tokens.secondaryName) {\n      return this.tokens.secondaryName.type;\n    }\n    return null;\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { rhsType } = this;\n    return w.ts.wrap([\n      w.token(this.tokens.assign),\n      w.token(this.tokens.asterisk),\n      w.reference_token(this.tokens.secondaryName, this.parent),\n      w.token(this.tokens.open),\n      ...this.list.map((p) => {\n        return rhsType === \"identifier-list\"\n          ? w.identifier(p, this.parent)\n          : p.write(w);\n      }),\n      w.token(this.tokens.close),\n    ]);\n  }\n}\n\nexport class SimpleExtendedAttribute extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const name = tokeniser.consumeKind(\"identifier\");\n    if (name) {\n      return new SimpleExtendedAttribute({\n        source: tokeniser.source,\n        tokens: { name },\n        params: ExtendedAttributeParameters.parse(tokeniser),\n      });\n    }\n  }\n\n  constructor({ source, tokens, params }) {\n    super({ source, tokens });\n    params.parent = this;\n    Object.defineProperty(this, \"params\", { value: params });\n  }\n\n  get type() {\n    return \"extended-attribute\";\n  }\n  get name() {\n    return this.tokens.name.value;\n  }\n  get rhs() {\n    const { rhsType: type, tokens, list } = this.params;\n    if (!type) {\n      return null;\n    }\n    const value = this.params.rhsIsList\n      ? list\n      : this.params.tokens.secondaryName\n        ? unescape(tokens.secondaryName.value)\n        : null;\n    return { type, value };\n  }\n  get arguments() {\n    const { rhsIsList, list } = this.params;\n    if (!list || rhsIsList) {\n      return [];\n    }\n    return list;\n  }\n\n  *validate(defs) {\n    const { name } = this;\n    if (name === \"LegacyNoInterfaceObject\") {\n      const message = `\\`[LegacyNoInterfaceObject]\\` extended attribute is an \\\nundesirable feature that may be removed from Web IDL in the future. Refer to the \\\n[relevant upstream PR](https://github.com/whatwg/webidl/pull/609) for more \\\ninformation.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"no-nointerfaceobject\",\n        message,\n        { level: \"warning\" },\n      );\n    } else if (renamedLegacies.has(name)) {\n      const message = `\\`[${name}]\\` extended attribute is a legacy feature \\\nthat is now renamed to \\`[${renamedLegacies.get(name)}]\\`. Refer to the \\\n[relevant upstream PR](https://github.com/whatwg/webidl/pull/870) for more \\\ninformation.`;\n      yield validationError(this.tokens.name, this, \"renamed-legacy\", message, {\n        level: \"warning\",\n        autofix: renameLegacyExtendedAttribute(this),\n      });\n    }\n    for (const arg of this.arguments) {\n      yield* arg.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      w.ts.trivia(this.tokens.name.trivia),\n      w.ts.extendedAttribute(\n        w.ts.wrap([\n          w.ts.extendedAttributeReference(this.name),\n          this.params.write(w),\n        ]),\n      ),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\n/**\n * @param {SimpleExtendedAttribute} extAttr\n */\nfunction renameLegacyExtendedAttribute(extAttr) {\n  return () => {\n    const { name } = extAttr;\n    extAttr.tokens.name.value = renamedLegacies.get(name);\n    if (name === \"TreatNullAs\") {\n      extAttr.params.tokens = {};\n    }\n  };\n}\n\n// Note: we parse something simpler than the official syntax. It's all that ever\n// seems to be used\nexport class ExtendedAttributes extends ArrayBase {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    tokens.open = tokeniser.consume(\"[\");\n    const ret = new ExtendedAttributes({ source: tokeniser.source, tokens });\n    if (!tokens.open) return ret;\n    ret.push(\n      ...list(tokeniser, {\n        parser: SimpleExtendedAttribute.parse,\n        listName: \"extended attribute\",\n      }),\n    );\n    tokens.close =\n      tokeniser.consume(\"]\") ||\n      tokeniser.error(\n        \"Expected a closing token for the extended attribute list\",\n      );\n    if (!ret.length) {\n      tokeniser.unconsume(tokens.close.index);\n      tokeniser.error(\"An extended attribute list must not be empty\");\n    }\n    if (tokeniser.probe(\"[\")) {\n      tokeniser.error(\n        \"Illegal double extended attribute lists, consider merging them\",\n      );\n    }\n    return ret;\n  }\n\n  *validate(defs) {\n    for (const extAttr of this) {\n      yield* extAttr.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    if (!this.length) return \"\";\n    return w.ts.wrap([\n      w.token(this.tokens.open),\n      ...this.map((ea) => ea.write(w)),\n      w.token(this.tokens.close),\n    ]);\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  unescape,\n  type_with_extended_attributes,\n  return_type,\n  primitive_type,\n  autoParenter,\n} from \"./helpers.js\";\nimport { stringTypes, typeNameKeywords } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport { idlTypeIncludesDictionary } from \"../validators/helpers.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction generic_type(tokeniser, typeName) {\n  const base = tokeniser.consume(\n    \"FrozenArray\",\n    \"ObservableArray\",\n    \"Promise\",\n    \"async_sequence\",\n    \"sequence\",\n    \"record\",\n  );\n  if (!base) {\n    return;\n  }\n  const ret = autoParenter(\n    new Type({ source: tokeniser.source, tokens: { base } }),\n  );\n  ret.tokens.open =\n    tokeniser.consume(\"<\") ||\n    tokeniser.error(`No opening bracket after ${base.value}`);\n  switch (base.value) {\n    case \"Promise\": {\n      if (tokeniser.probe(\"[\"))\n        tokeniser.error(\"Promise type cannot have extended attribute\");\n      const subtype =\n        return_type(tokeniser, typeName) ||\n        tokeniser.error(\"Missing Promise subtype\");\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"async_sequence\":\n    case \"sequence\":\n    case \"FrozenArray\":\n    case \"ObservableArray\": {\n      const subtype =\n        type_with_extended_attributes(tokeniser, typeName) ||\n        tokeniser.error(`Missing ${base.value} subtype`);\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"record\": {\n      if (tokeniser.probe(\"[\"))\n        tokeniser.error(\"Record key cannot have extended attribute\");\n      const keyType =\n        tokeniser.consume(...stringTypes) ||\n        tokeniser.error(`Record key must be one of: ${stringTypes.join(\", \")}`);\n      const keyIdlType = new Type({\n        source: tokeniser.source,\n        tokens: { base: keyType },\n      });\n      keyIdlType.tokens.separator =\n        tokeniser.consume(\",\") ||\n        tokeniser.error(\"Missing comma after record key type\");\n      keyIdlType.type = typeName;\n      const valueType =\n        type_with_extended_attributes(tokeniser, typeName) ||\n        tokeniser.error(\"Error parsing generic type record\");\n      ret.subtype.push(keyIdlType, valueType);\n      break;\n    }\n  }\n  if (!ret.idlType) tokeniser.error(`Error parsing generic type ${base.value}`);\n  ret.tokens.close =\n    tokeniser.consume(\">\") ||\n    tokeniser.error(`Missing closing bracket after ${base.value}`);\n  return ret.this;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction type_suffix(tokeniser, obj) {\n  const nullable = tokeniser.consume(\"?\");\n  if (nullable) {\n    obj.tokens.nullable = nullable;\n  }\n  if (tokeniser.probe(\"?\")) tokeniser.error(\"Can't nullable more than once\");\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction single_type(tokeniser, typeName) {\n  let ret = generic_type(tokeniser, typeName) || primitive_type(tokeniser);\n  if (!ret) {\n    const base =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.consume(...stringTypes, ...typeNameKeywords);\n    if (!base) {\n      return;\n    }\n    ret = new Type({ source: tokeniser.source, tokens: { base } });\n    if (tokeniser.probe(\"<\"))\n      tokeniser.error(`Unsupported generic type ${base.value}`);\n  }\n  if (ret.generic === \"Promise\" && tokeniser.probe(\"?\")) {\n    tokeniser.error(\"Promise type cannot be nullable\");\n  }\n  ret.type = typeName || null;\n  type_suffix(tokeniser, ret);\n  if (ret.nullable && ret.idlType === \"any\")\n    tokeniser.error(\"Type `any` cannot be made nullable\");\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string} type\n */\nfunction union_type(tokeniser, type) {\n  const tokens = {};\n  tokens.open = tokeniser.consume(\"(\");\n  if (!tokens.open) return;\n  const ret = autoParenter(new Type({ source: tokeniser.source, tokens }));\n  ret.type = type || null;\n  while (true) {\n    const typ =\n      type_with_extended_attributes(tokeniser, type) ||\n      tokeniser.error(\"No type after open parenthesis or 'or' in union type\");\n    if (typ.idlType === \"any\")\n      tokeniser.error(\"Type `any` cannot be included in a union type\");\n    if (typ.generic === \"Promise\")\n      tokeniser.error(\"Type `Promise` cannot be included in a union type\");\n    ret.subtype.push(typ);\n    const or = tokeniser.consume(\"or\");\n    if (or) {\n      typ.tokens.separator = or;\n    } else break;\n  }\n  if (ret.idlType.length < 2) {\n    tokeniser.error(\n      \"At least two types are expected in a union type but found less\",\n    );\n  }\n  tokens.close =\n    tokeniser.consume(\")\") || tokeniser.error(\"Unterminated union type\");\n  type_suffix(tokeniser, ret);\n  return ret.this;\n}\n\nexport class Type extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {string} typeName\n   */\n  static parse(tokeniser, typeName) {\n    return single_type(tokeniser, typeName) || union_type(tokeniser, typeName);\n  }\n\n  constructor({ source, tokens }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"subtype\", { value: [], writable: true });\n    this.extAttrs = new ExtendedAttributes({ source, tokens: {} });\n  }\n\n  get generic() {\n    if (this.subtype.length && this.tokens.base) {\n      return this.tokens.base.value;\n    }\n    return \"\";\n  }\n  get nullable() {\n    return Boolean(this.tokens.nullable);\n  }\n  get union() {\n    return Boolean(this.subtype.length) && !this.tokens.base;\n  }\n  get idlType() {\n    if (this.subtype.length) {\n      return this.subtype;\n    }\n    // Adding prefixes/postfixes for \"unrestricted float\", etc.\n    const name = [this.tokens.prefix, this.tokens.base, this.tokens.postfix]\n      .filter((t) => t)\n      .map((t) => t.value)\n      .join(\" \");\n    return unescape(name);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n\n    if (this.idlType === \"BufferSource\") {\n      // XXX: For now this is a hack. Consider moving parents' extAttrs into types as the spec says:\n      // https://webidl.spec.whatwg.org/#idl-annotated-types\n      for (const extAttrs of [this.extAttrs, this.parent?.extAttrs]) {\n        for (const extAttr of extAttrs) {\n          if (extAttr.name !== \"AllowShared\") {\n            continue;\n          }\n          const message = `\\`[AllowShared] BufferSource\\` is now replaced with AllowSharedBufferSource.`;\n          yield validationError(\n            this.tokens.base,\n            this,\n            \"migrate-allowshared\",\n            message,\n            { autofix: replaceAllowShared(this, extAttr, extAttrs) },\n          );\n        }\n      }\n    }\n\n    if (this.idlType === \"void\") {\n      const message = `\\`void\\` is now replaced by \\`undefined\\`. Refer to the \\\n[relevant GitHub issue](https://github.com/whatwg/webidl/issues/60) \\\nfor more information.`;\n      yield validationError(this.tokens.base, this, \"replace-void\", message, {\n        autofix: replaceVoid(this),\n      });\n    }\n\n    /*\n     * If a union is nullable, its subunions cannot include a dictionary\n     * If not, subunions may include dictionaries if each union is not nullable\n     */\n    const typedef = !this.union && defs.unique.get(this.idlType);\n    const target = this.union\n      ? this\n      : typedef && typedef.type === \"typedef\"\n        ? typedef.idlType\n        : undefined;\n    if (target && this.nullable) {\n      // do not allow any dictionary\n      const { reference } = idlTypeIncludesDictionary(target, defs) || {};\n      if (reference) {\n        const targetToken = (this.union ? reference : this).tokens.base;\n        const message = \"Nullable union cannot include a dictionary type.\";\n        yield validationError(\n          targetToken,\n          this,\n          \"no-nullable-union-dict\",\n          message,\n        );\n      }\n    } else {\n      // allow some dictionary\n      for (const subtype of this.subtype) {\n        yield* subtype.validate(defs);\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const type_body = () => {\n      if (this.union || this.generic) {\n        return w.ts.wrap([\n          w.token(this.tokens.base, w.ts.generic),\n          w.token(this.tokens.open),\n          ...this.subtype.map((t) => t.write(w)),\n          w.token(this.tokens.close),\n        ]);\n      }\n      const firstToken = this.tokens.prefix || this.tokens.base;\n      const prefix = this.tokens.prefix\n        ? [this.tokens.prefix.value, w.ts.trivia(this.tokens.base.trivia)]\n        : [];\n      const ref = w.reference(\n        w.ts.wrap([\n          ...prefix,\n          this.tokens.base.value,\n          w.token(this.tokens.postfix),\n        ]),\n        {\n          unescaped: /** @type {string} (because it's not union) */ (\n            this.idlType\n          ),\n          context: this,\n        },\n      );\n      return w.ts.wrap([w.ts.trivia(firstToken.trivia), ref]);\n    };\n    return w.ts.wrap([\n      this.extAttrs.write(w),\n      type_body(),\n      w.token(this.tokens.nullable),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\n/**\n * @param {Type} type\n * @param {import(\"./extended-attributes.js\").SimpleExtendedAttribute} extAttr\n * @param {ExtendedAttributes} extAttrs\n */\nfunction replaceAllowShared(type, extAttr, extAttrs) {\n  return () => {\n    const index = extAttrs.indexOf(extAttr);\n    extAttrs.splice(index, 1);\n    if (!extAttrs.length && type.tokens.base.trivia.match(/^\\s$/)) {\n      type.tokens.base.trivia = \"\"; // (let's not remove comments)\n    }\n\n    type.tokens.base.value = \"AllowSharedBufferSource\";\n  };\n}\n\n/**\n * @param {Type} type\n */\nfunction replaceVoid(type) {\n  return () => {\n    type.tokens.base.value = \"undefined\";\n  };\n}\n","import { Base } from \"./base.js\";\nimport { const_data, const_value } from \"./helpers.js\";\n\nexport class Default extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const assign = tokeniser.consume(\"=\");\n    if (!assign) {\n      return null;\n    }\n    const def =\n      const_value(tokeniser) ||\n      tokeniser.consumeKind(\"string\") ||\n      tokeniser.consume(\"null\", \"[\", \"{\") ||\n      tokeniser.error(\"No value for default\");\n    const expression = [def];\n    if (def.value === \"[\") {\n      const close =\n        tokeniser.consume(\"]\") ||\n        tokeniser.error(\"Default sequence value must be empty\");\n      expression.push(close);\n    } else if (def.value === \"{\") {\n      const close =\n        tokeniser.consume(\"}\") ||\n        tokeniser.error(\"Default dictionary value must be empty\");\n      expression.push(close);\n    }\n    return new Default({\n      source: tokeniser.source,\n      tokens: { assign },\n      expression,\n    });\n  }\n\n  constructor({ source, tokens, expression }) {\n    super({ source, tokens });\n    expression.parent = this;\n    Object.defineProperty(this, \"expression\", { value: expression });\n  }\n\n  get type() {\n    return const_data(this.expression[0]).type;\n  }\n  get value() {\n    return const_data(this.expression[0]).value;\n  }\n  get negative() {\n    return const_data(this.expression[0]).negative;\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      w.token(this.tokens.assign),\n      ...this.expression.map((t) => w.token(t)),\n    ]);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { Default } from \"./default.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport {\n  unescape,\n  type_with_extended_attributes,\n  autoParenter,\n  getFirstToken,\n} from \"./helpers.js\";\nimport { argumentNameKeywords, Tokeniser } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport {\n  idlTypeIncludesDictionary,\n  dictionaryIncludesRequiredField,\n} from \"../validators/helpers.js\";\n\nexport class Argument extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(\n      new Argument({ source: tokeniser.source, tokens }),\n    );\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.optional = tokeniser.consume(\"optional\");\n    ret.idlType = type_with_extended_attributes(tokeniser, \"argument-type\");\n    if (!ret.idlType) {\n      return tokeniser.unconsume(start_position);\n    }\n    if (!tokens.optional) {\n      tokens.variadic = tokeniser.consume(\"...\");\n    }\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.consume(...argumentNameKeywords);\n    if (!tokens.name) {\n      return tokeniser.unconsume(start_position);\n    }\n    ret.default = tokens.optional ? Default.parse(tokeniser) : null;\n    return ret.this;\n  }\n\n  get type() {\n    return \"argument\";\n  }\n  get optional() {\n    return !!this.tokens.optional;\n  }\n  get variadic() {\n    return !!this.tokens.variadic;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  /**\n   * @param {import(\"../validator.js\").Definitions} defs\n   */\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    yield* this.idlType.validate(defs);\n    const result = idlTypeIncludesDictionary(this.idlType, defs, {\n      useNullableInner: true,\n    });\n    if (result) {\n      if (this.idlType.nullable) {\n        const message = `Dictionary arguments cannot be nullable.`;\n        yield validationError(\n          this.tokens.name,\n          this,\n          \"no-nullable-dict-arg\",\n          message,\n        );\n      } else if (!this.optional) {\n        if (\n          this.parent &&\n          !dictionaryIncludesRequiredField(result.dictionary, defs) &&\n          isLastRequiredArgument(this)\n        ) {\n          const message = `Dictionary argument must be optional if it has no required fields`;\n          yield validationError(\n            this.tokens.name,\n            this,\n            \"dict-arg-optional\",\n            message,\n            {\n              autofix: autofixDictionaryArgumentOptionality(this),\n            },\n          );\n        }\n      } else if (!this.default) {\n        const message = `Optional dictionary arguments must have a default value of \\`{}\\`.`;\n        yield validationError(\n          this.tokens.name,\n          this,\n          \"dict-arg-default\",\n          message,\n          {\n            autofix: autofixOptionalDictionaryDefaultValue(this),\n          },\n        );\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.wrap([\n      this.extAttrs.write(w),\n      w.token(this.tokens.optional),\n      w.ts.type(this.idlType.write(w)),\n      w.token(this.tokens.variadic),\n      w.name_token(this.tokens.name, { data: this }),\n      this.default ? this.default.write(w) : \"\",\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\n/**\n * @param {Argument} arg\n */\nfunction isLastRequiredArgument(arg) {\n  const list = arg.parent.arguments || arg.parent.list;\n  const index = list.indexOf(arg);\n  const requiredExists = list.slice(index + 1).some((a) => !a.optional);\n  return !requiredExists;\n}\n\n/**\n * @param {Argument} arg\n */\nfunction autofixDictionaryArgumentOptionality(arg) {\n  return () => {\n    const firstToken = getFirstToken(arg.idlType);\n    arg.tokens.optional = {\n      ...firstToken,\n      type: \"optional\",\n      value: \"optional\",\n    };\n    firstToken.trivia = \" \";\n    autofixOptionalDictionaryDefaultValue(arg)();\n  };\n}\n\n/**\n * @param {Argument} arg\n */\nfunction autofixOptionalDictionaryDefaultValue(arg) {\n  return () => {\n    arg.default = Default.parse(new Tokeniser(\" = {}\"));\n  };\n}\n","import { Base } from \"./base.js\";\nimport {\n  return_type,\n  argument_list,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\nexport class Operation extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"../tokeniser.js\").Token} [options.special]\n   * @param {import(\"../tokeniser.js\").Token} [options.regular]\n   */\n  static parse(tokeniser, { special, regular } = {}) {\n    const tokens = { special };\n    const ret = autoParenter(\n      new Operation({ source: tokeniser.source, tokens }),\n    );\n    if (special && special.value === \"stringifier\") {\n      tokens.termination = tokeniser.consume(\";\");\n      if (tokens.termination) {\n        ret.arguments = [];\n        return ret;\n      }\n    }\n    if (!special && !regular) {\n      tokens.special = tokeniser.consume(\"getter\", \"setter\", \"deleter\");\n    }\n    ret.idlType =\n      return_type(tokeniser) || tokeniser.error(\"Missing return type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") || tokeniser.consume(\"includes\");\n    tokens.open =\n      tokeniser.consume(\"(\") || tokeniser.error(\"Invalid operation\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close =\n      tokeniser.consume(\")\") || tokeniser.error(\"Unterminated operation\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated operation, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"operation\";\n  }\n  get name() {\n    const { name } = this.tokens;\n    if (!name) {\n      return \"\";\n    }\n    return unescape(name.value);\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    if (!this.name && [\"\", \"static\"].includes(this.special)) {\n      const message = `Regular or static operations must have both a return type and an identifier.`;\n      yield validationError(this.tokens.open, this, \"incomplete-op\", message);\n    }\n    if (this.idlType) {\n      if (this.idlType.generic === \"async_sequence\") {\n        const message = `async_sequence types cannot be returned by an operation.`;\n        yield validationError(\n          this.idlType.tokens.base,\n          this,\n          \"async-sequence-idl-to-js\",\n          message,\n        );\n      }\n      yield* this.idlType.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    const body = this.idlType\n      ? [\n          w.ts.type(this.idlType.write(w)),\n          w.name_token(this.tokens.name, { data: this, parent }),\n          w.token(this.tokens.open),\n          w.ts.wrap(this.arguments.map((arg) => arg.write(w))),\n          w.token(this.tokens.close),\n        ]\n      : [];\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        this.tokens.name\n          ? w.token(this.tokens.special)\n          : w.token(this.tokens.special, w.ts.nameless, { data: this, parent }),\n        ...body,\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent },\n    );\n  }\n}\n","import { validationError } from \"../error.js\";\nimport {\n  idlTypeIncludesDictionary,\n  idlTypeIncludesEnforceRange,\n} from \"../validators/helpers.js\";\nimport { Base } from \"./base.js\";\nimport {\n  type_with_extended_attributes,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\n\nexport class Attribute extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"../tokeniser.js\").Token} [options.special]\n   * @param {boolean} [options.noInherit]\n   * @param {boolean} [options.readonly]\n   */\n  static parse(\n    tokeniser,\n    { special, noInherit = false, readonly = false } = {},\n  ) {\n    const start_position = tokeniser.position;\n    const tokens = { special };\n    const ret = autoParenter(\n      new Attribute({ source: tokeniser.source, tokens }),\n    );\n    if (!special && !noInherit) {\n      tokens.special = tokeniser.consume(\"inherit\");\n    }\n    if (ret.special === \"inherit\" && tokeniser.probe(\"readonly\")) {\n      tokeniser.error(\"Inherited attributes cannot be read-only\");\n    }\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (readonly && !tokens.readonly && tokeniser.probe(\"attribute\")) {\n      tokeniser.error(\"Attributes must be readonly in this context\");\n    }\n    tokens.base = tokeniser.consume(\"attribute\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n    ret.idlType =\n      type_with_extended_attributes(tokeniser, \"attribute-type\") ||\n      tokeniser.error(\"Attribute lacks a type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.consume(\"async\", \"required\") ||\n      tokeniser.error(\"Attribute lacks a name\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated attribute, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"attribute\";\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    yield* this.idlType.validate(defs);\n\n    if (\n      [\"async_sequence\", \"sequence\", \"record\"].includes(this.idlType.generic)\n    ) {\n      const message = `Attributes cannot accept ${this.idlType.generic} types.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"attr-invalid-type\",\n        message,\n      );\n    }\n\n    {\n      const { reference } = idlTypeIncludesDictionary(this.idlType, defs) || {};\n      if (reference) {\n        const targetToken = (this.idlType.union ? reference : this.idlType)\n          .tokens.base;\n        const message = \"Attributes cannot accept dictionary types.\";\n        yield validationError(targetToken, this, \"attr-invalid-type\", message);\n      }\n    }\n\n    if (this.readonly) {\n      if (idlTypeIncludesEnforceRange(this.idlType, defs)) {\n        const targetToken = this.idlType.tokens.base;\n        const message =\n          \"Readonly attributes cannot accept [EnforceRange] extended attribute.\";\n        yield validationError(targetToken, this, \"attr-invalid-type\", message);\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.special),\n        w.token(this.tokens.readonly),\n        w.token(this.tokens.base),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this, parent }),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent },\n    );\n  }\n}\n","import { Type } from \"./type.js\";\nimport { Argument } from \"./argument.js\";\nimport {\n  ExtendedAttributes,\n  SimpleExtendedAttribute,\n} from \"./extended-attributes.js\";\nimport { Operation } from \"./operation.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Tokeniser } from \"../tokeniser.js\";\n\n/**\n * @param {string} identifier\n */\nexport function unescape(identifier) {\n  return identifier.startsWith(\"_\") ? identifier.slice(1) : identifier;\n}\n\n/**\n * Parses comma-separated list\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {object} args\n * @param {Function} args.parser parser function for each item\n * @param {boolean} [args.allowDangler] whether to allow dangling comma\n * @param {string} [args.listName] the name to be shown on error messages\n */\nexport function list(tokeniser, { parser, allowDangler, listName = \"list\" }) {\n  const first = parser(tokeniser);\n  if (!first) {\n    return [];\n  }\n  first.tokens.separator = tokeniser.consume(\",\");\n  const items = [first];\n  while (first.tokens.separator) {\n    const item = parser(tokeniser);\n    if (!item) {\n      if (!allowDangler) {\n        tokeniser.error(`Trailing comma in ${listName}`);\n      }\n      break;\n    }\n    item.tokens.separator = tokeniser.consume(\",\");\n    items.push(item);\n    if (!item.tokens.separator) break;\n  }\n  return items;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function const_value(tokeniser) {\n  return (\n    tokeniser.consumeKind(\"decimal\", \"integer\") ||\n    tokeniser.consume(\"true\", \"false\", \"Infinity\", \"-Infinity\", \"NaN\")\n  );\n}\n\n/**\n * @param {object} token\n * @param {string} token.type\n * @param {string} token.value\n */\nexport function const_data({ type, value }) {\n  switch (type) {\n    case \"decimal\":\n    case \"integer\":\n      return { type: \"number\", value };\n    case \"string\":\n      return { type: \"string\", value: value.slice(1, -1) };\n  }\n\n  switch (value) {\n    case \"true\":\n    case \"false\":\n      return { type: \"boolean\", value: value === \"true\" };\n    case \"Infinity\":\n    case \"-Infinity\":\n      return { type: \"Infinity\", negative: value.startsWith(\"-\") };\n    case \"[\":\n      return { type: \"sequence\", value: [] };\n    case \"{\":\n      return { type: \"dictionary\" };\n    default:\n      return { type: value };\n  }\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function primitive_type(tokeniser) {\n  function integer_type() {\n    const prefix = tokeniser.consume(\"unsigned\");\n    const base = tokeniser.consume(\"short\", \"long\");\n    if (base) {\n      const postfix = tokeniser.consume(\"long\");\n      return new Type({ source, tokens: { prefix, base, postfix } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse integer type\");\n  }\n\n  function decimal_type() {\n    const prefix = tokeniser.consume(\"unrestricted\");\n    const base = tokeniser.consume(\"float\", \"double\");\n    if (base) {\n      return new Type({ source, tokens: { prefix, base } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse float type\");\n  }\n\n  const { source } = tokeniser;\n  const num_type = integer_type() || decimal_type();\n  if (num_type) return num_type;\n  const base = tokeniser.consume(\n    \"bigint\",\n    \"boolean\",\n    \"byte\",\n    \"octet\",\n    \"undefined\",\n  );\n  if (base) {\n    return new Type({ source, tokens: { base } });\n  }\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function argument_list(tokeniser) {\n  return list(tokeniser, {\n    parser: Argument.parse,\n    listName: \"arguments list\",\n  });\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string=} typeName (TODO: See Type.type for more details)\n */\nexport function type_with_extended_attributes(tokeniser, typeName) {\n  const extAttrs = ExtendedAttributes.parse(tokeniser);\n  const ret = Type.parse(tokeniser, typeName);\n  if (ret) autoParenter(ret).extAttrs = extAttrs;\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {string=} typeName (TODO: See Type.type for more details)\n */\nexport function return_type(tokeniser, typeName) {\n  const typ = Type.parse(tokeniser, typeName || \"return-type\");\n  if (typ) {\n    return typ;\n  }\n  const voidToken = tokeniser.consume(\"void\");\n  if (voidToken) {\n    const ret = new Type({\n      source: tokeniser.source,\n      tokens: { base: voidToken },\n    });\n    ret.type = \"return-type\";\n    return ret;\n  }\n}\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nexport function stringifier(tokeniser) {\n  const special = tokeniser.consume(\"stringifier\");\n  if (!special) return;\n  const member =\n    Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"Unterminated stringifier\");\n  return member;\n}\n\n/**\n * @param {string} str\n */\nexport function getLastIndentation(str) {\n  const lines = str.split(\"\\n\");\n  // the first line visually binds to the preceding token\n  if (lines.length) {\n    const match = lines[lines.length - 1].match(/^\\s+/);\n    if (match) {\n      return match[0];\n    }\n  }\n  return \"\";\n}\n\n/**\n * @param {string} parentTrivia\n */\nexport function getMemberIndentation(parentTrivia) {\n  const indentation = getLastIndentation(parentTrivia);\n  const indentCh = indentation.includes(\"\\t\") ? \"\\t\" : \"  \";\n  return indentation + indentCh;\n}\n\n/**\n * @param {import(\"./interface.js\").Interface} def\n */\nexport function autofixAddExposedWindow(def) {\n  return () => {\n    if (def.extAttrs.length) {\n      const tokeniser = new Tokeniser(\"Exposed=Window,\");\n      const exposed = SimpleExtendedAttribute.parse(tokeniser);\n      exposed.tokens.separator = tokeniser.consume(\",\");\n      const existing = def.extAttrs[0];\n      if (!/^\\s/.test(existing.tokens.name.trivia)) {\n        existing.tokens.name.trivia = ` ${existing.tokens.name.trivia}`;\n      }\n      def.extAttrs.unshift(exposed);\n    } else {\n      autoParenter(def).extAttrs = ExtendedAttributes.parse(\n        new Tokeniser(\"[Exposed=Window]\"),\n      );\n      const trivia = def.tokens.base.trivia;\n      def.extAttrs.tokens.open.trivia = trivia;\n      def.tokens.base.trivia = `\\n${getLastIndentation(trivia)}`;\n    }\n  };\n}\n\n/**\n * Get the first syntax token for the given IDL object.\n * @param {*} data\n */\nexport function getFirstToken(data) {\n  if (data.extAttrs.length) {\n    return data.extAttrs.tokens.open;\n  }\n  if (data.type === \"operation\" && !data.special) {\n    return getFirstToken(data.idlType);\n  }\n  const tokens = Object.values(data.tokens).sort((x, y) => x.index - y.index);\n  return tokens[0];\n}\n\n/**\n * @template T\n * @param {T[]} array\n * @param {(item: T) => boolean} predicate\n */\nexport function findLastIndex(array, predicate) {\n  const index = array.slice().reverse().findIndex(predicate);\n  if (index === -1) {\n    return index;\n  }\n  return array.length - index - 1;\n}\n\n/**\n * Returns a proxy that auto-assign `parent` field.\n * @template {Record<string | symbol, any>} T\n * @param {T} data\n * @param {*} [parent] The object that will be assigned to `parent`.\n *                     If absent, it will be `data` by default.\n * @return {T}\n */\nexport function autoParenter(data, parent) {\n  if (!parent) {\n    // Defaults to `data` unless specified otherwise.\n    parent = data;\n  }\n  if (!data) {\n    // This allows `autoParenter(undefined)` which again allows\n    // `autoParenter(parse())` where the function may return nothing.\n    return data;\n  }\n  const proxy = new Proxy(data, {\n    get(target, p) {\n      const value = target[p];\n      if (Array.isArray(value) && p !== \"source\") {\n        // Wraps the array so that any added items will also automatically\n        // get their `parent` values.\n        return autoParenter(value, target);\n      }\n      return value;\n    },\n    set(target, p, value) {\n      // @ts-ignore https://github.com/microsoft/TypeScript/issues/47357\n      target[p] = value;\n      if (!value) {\n        return true;\n      } else if (Array.isArray(value)) {\n        // Assigning an array will add `parent` to its items.\n        for (const item of value) {\n          if (typeof item.parent !== \"undefined\") {\n            item.parent = parent;\n          }\n        }\n      } else if (typeof value.parent !== \"undefined\") {\n        value.parent = parent;\n      }\n      return true;\n    },\n  });\n  return proxy;\n}\n","import { syntaxError } from \"./error.js\";\nimport { unescape } from \"./productions/helpers.js\";\n\n// These regular expressions use the sticky flag so they will only match at\n// the current location (ie. the offset of lastIndex).\nconst tokenRe = {\n  // This expression uses a lookahead assertion to catch false matches\n  // against integers early.\n  decimal:\n    /-?(?=[0-9]*\\.|[0-9]+[eE])(([0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+)([Ee][-+]?[0-9]+)?|[0-9]+[Ee][-+]?[0-9]+)/y,\n  integer: /-?(0([Xx][0-9A-Fa-f]+|[0-7]*)|[1-9][0-9]*)/y,\n  identifier: /[_-]?[A-Za-z][0-9A-Z_a-z-]*/y,\n  string: /\"[^\"]*\"/y,\n  whitespace: /[\\t\\n\\r ]+/y,\n  comment: /\\/\\/.*|\\/\\*[\\s\\S]*?\\*\\//y,\n  other: /[^\\t\\n\\r 0-9A-Za-z]/y,\n};\n\nexport const typeNameKeywords = [\n  \"ArrayBuffer\",\n  \"SharedArrayBuffer\",\n  \"DataView\",\n  \"Int8Array\",\n  \"Int16Array\",\n  \"Int32Array\",\n  \"Uint8Array\",\n  \"Uint16Array\",\n  \"Uint32Array\",\n  \"Uint8ClampedArray\",\n  \"BigInt64Array\",\n  \"BigUint64Array\",\n  \"Float16Array\",\n  \"Float32Array\",\n  \"Float64Array\",\n  \"any\",\n  \"object\",\n  \"symbol\",\n];\n\nexport const stringTypes = [\"ByteString\", \"DOMString\", \"USVString\"];\n\nexport const argumentNameKeywords = [\n  \"async\",\n  \"attribute\",\n  \"callback\",\n  \"const\",\n  \"constructor\",\n  \"deleter\",\n  \"dictionary\",\n  \"enum\",\n  \"getter\",\n  \"includes\",\n  \"inherit\",\n  \"interface\",\n  \"iterable\",\n  \"maplike\",\n  \"namespace\",\n  \"partial\",\n  \"required\",\n  \"setlike\",\n  \"setter\",\n  \"static\",\n  \"stringifier\",\n  \"typedef\",\n  \"unrestricted\",\n];\n\nconst nonRegexTerminals = [\n  \"-Infinity\",\n  \"FrozenArray\",\n  \"Infinity\",\n  \"NaN\",\n  \"ObservableArray\",\n  \"Promise\",\n  \"async_iterable\",\n  \"async_sequence\",\n  \"bigint\",\n  \"boolean\",\n  \"byte\",\n  \"double\",\n  \"false\",\n  \"float\",\n  \"long\",\n  \"mixin\",\n  \"null\",\n  \"octet\",\n  \"optional\",\n  \"or\",\n  \"readonly\",\n  \"record\",\n  \"sequence\",\n  \"short\",\n  \"true\",\n  \"undefined\",\n  \"unsigned\",\n  \"void\",\n].concat(argumentNameKeywords, stringTypes, typeNameKeywords);\n\nconst punctuations = [\n  \"(\",\n  \")\",\n  \",\",\n  \"...\",\n  \":\",\n  \";\",\n  \"<\",\n  \"=\",\n  \">\",\n  \"?\",\n  \"*\",\n  \"[\",\n  \"]\",\n  \"{\",\n  \"}\",\n];\n\nconst reserved = [\n  // \"constructor\" is now a keyword\n  \"_constructor\",\n  \"toString\",\n  \"_toString\",\n];\n\n/**\n * @typedef {ArrayItemType<ReturnType<typeof tokenise>>} Token\n * @param {string} str\n */\nfunction tokenise(str) {\n  const tokens = [];\n  let lastCharIndex = 0;\n  let trivia = \"\";\n  let line = 1;\n  let index = 0;\n  while (lastCharIndex < str.length) {\n    const nextChar = str.charAt(lastCharIndex);\n    let result = -1;\n\n    if (/[\\t\\n\\r ]/.test(nextChar)) {\n      result = attemptTokenMatch(\"whitespace\", { noFlushTrivia: true });\n    } else if (nextChar === \"/\") {\n      result = attemptTokenMatch(\"comment\", { noFlushTrivia: true });\n    }\n\n    if (result !== -1) {\n      const currentTrivia = tokens.pop().value;\n      line += (currentTrivia.match(/\\n/g) || []).length;\n      trivia += currentTrivia;\n      index -= 1;\n    } else if (/[-0-9.A-Z_a-z]/.test(nextChar)) {\n      result = attemptTokenMatch(\"decimal\");\n      if (result === -1) {\n        result = attemptTokenMatch(\"integer\");\n      }\n      if (result === -1) {\n        result = attemptTokenMatch(\"identifier\");\n        const lastIndex = tokens.length - 1;\n        const token = tokens[lastIndex];\n        if (result !== -1) {\n          if (reserved.includes(token.value)) {\n            const message = `${unescape(\n              token.value,\n            )} is a reserved identifier and must not be used.`;\n            throw new WebIDLParseError(\n              syntaxError(tokens, lastIndex, null, message),\n            );\n          } else if (nonRegexTerminals.includes(token.value)) {\n            token.type = \"inline\";\n          }\n        }\n      }\n    } else if (nextChar === '\"') {\n      result = attemptTokenMatch(\"string\");\n    }\n\n    for (const punctuation of punctuations) {\n      if (str.startsWith(punctuation, lastCharIndex)) {\n        tokens.push({\n          type: \"inline\",\n          value: punctuation,\n          trivia,\n          line,\n          index,\n        });\n        trivia = \"\";\n        lastCharIndex += punctuation.length;\n        result = lastCharIndex;\n        break;\n      }\n    }\n\n    // other as the last try\n    if (result === -1) {\n      result = attemptTokenMatch(\"other\");\n    }\n    if (result === -1) {\n      throw new Error(\"Token stream not progressing\");\n    }\n    lastCharIndex = result;\n    index += 1;\n  }\n\n  // remaining trivia as eof\n  tokens.push({\n    type: \"eof\",\n    value: \"\",\n    trivia,\n    line,\n    index,\n  });\n\n  return tokens;\n\n  /**\n   * @param {keyof typeof tokenRe} type\n   * @param {object} options\n   * @param {boolean} [options.noFlushTrivia]\n   */\n  function attemptTokenMatch(type, { noFlushTrivia } = {}) {\n    const re = tokenRe[type];\n    re.lastIndex = lastCharIndex;\n    const result = re.exec(str);\n    if (result) {\n      tokens.push({ type, value: result[0], trivia, line, index });\n      if (!noFlushTrivia) {\n        trivia = \"\";\n      }\n      return re.lastIndex;\n    }\n    return -1;\n  }\n}\n\nexport class Tokeniser {\n  /**\n   * @param {string} idl\n   */\n  constructor(idl) {\n    this.source = tokenise(idl);\n    this.position = 0;\n  }\n\n  /**\n   * @param {string} message\n   * @return {never}\n   */\n  error(message) {\n    throw new WebIDLParseError(\n      syntaxError(this.source, this.position, this.current, message),\n    );\n  }\n\n  /**\n   * @param {string} type\n   */\n  probeKind(type) {\n    return (\n      this.source.length > this.position &&\n      this.source[this.position].type === type\n    );\n  }\n\n  /**\n   * @param {string} value\n   */\n  probe(value) {\n    return (\n      this.probeKind(\"inline\") && this.source[this.position].value === value\n    );\n  }\n\n  /**\n   * @param {...string} candidates\n   */\n  consumeKind(...candidates) {\n    for (const type of candidates) {\n      if (!this.probeKind(type)) continue;\n      const token = this.source[this.position];\n      this.position++;\n      return token;\n    }\n  }\n\n  /**\n   * @param {...string} candidates\n   */\n  consume(...candidates) {\n    if (!this.probeKind(\"inline\")) return;\n    const token = this.source[this.position];\n    for (const value of candidates) {\n      if (token.value !== value) continue;\n      this.position++;\n      return token;\n    }\n  }\n\n  /**\n   * @param {string} value\n   */\n  consumeIdentifier(value) {\n    if (!this.probeKind(\"identifier\")) {\n      return;\n    }\n    if (this.source[this.position].value !== value) {\n      return;\n    }\n    return this.consumeKind(\"identifier\");\n  }\n\n  /**\n   * @param {number} position\n   */\n  unconsume(position) {\n    this.position = position;\n  }\n}\n\nexport class WebIDLParseError extends Error {\n  /**\n   * @param {object} options\n   * @param {string} options.message\n   * @param {string} options.bareMessage\n   * @param {string} options.context\n   * @param {number} options.line\n   * @param {*} options.sourceName\n   * @param {string} options.input\n   * @param {*[]} options.tokens\n   */\n  constructor({\n    message,\n    bareMessage,\n    context,\n    line,\n    sourceName,\n    input,\n    tokens,\n  }) {\n    super(message);\n\n    this.name = \"WebIDLParseError\"; // not to be mangled\n    this.bareMessage = bareMessage;\n    this.context = context;\n    this.line = line;\n    this.sourceName = sourceName;\n    this.input = input;\n    this.tokens = tokens;\n  }\n}\n","import { list, unescape, autoParenter } from \"./helpers.js\";\nimport { WrappedToken } from \"./token.js\";\nimport { Base } from \"./base.js\";\n\nexport class EnumValue extends WrappedToken {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const value = tokeniser.consumeKind(\"string\");\n    if (value) {\n      return new EnumValue({ source: tokeniser.source, tokens: { value } });\n    }\n  }\n\n  get type() {\n    return \"enum-value\";\n  }\n  get value() {\n    return super.value.slice(1, -1);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.wrap([\n      w.ts.trivia(this.tokens.value.trivia),\n      w.ts.definition(\n        w.ts.wrap(['\"', w.ts.name(this.value, { data: this, parent }), '\"']),\n        { data: this, parent },\n      ),\n      w.token(this.tokens.separator),\n    ]);\n  }\n}\n\nexport class Enum extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"enum\");\n    if (!tokens.base) {\n      return;\n    }\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"No name for enum\");\n    const ret = autoParenter(new Enum({ source: tokeniser.source, tokens }));\n    tokeniser.current = ret.this;\n    tokens.open = tokeniser.consume(\"{\") || tokeniser.error(\"Bodyless enum\");\n    ret.values = list(tokeniser, {\n      parser: EnumValue.parse,\n      allowDangler: true,\n      listName: \"enumeration\",\n    });\n    if (tokeniser.probeKind(\"string\")) {\n      tokeniser.error(\"No comma between enum values\");\n    }\n    tokens.close =\n      tokeniser.consume(\"}\") || tokeniser.error(\"Unexpected value in enum\");\n    if (!ret.values.length) {\n      tokeniser.error(\"No value in enum\");\n    }\n    tokens.termination =\n      tokeniser.consume(\";\") || tokeniser.error(\"No semicolon after enum\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"enum\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.name_token(this.tokens.name, { data: this }),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.values.map((v) => v.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this },\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape } from \"./helpers.js\";\n\nexport class Includes extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const target = tokeniser.consumeKind(\"identifier\");\n    if (!target) {\n      return;\n    }\n    const tokens = { target };\n    tokens.includes = tokeniser.consume(\"includes\");\n    if (!tokens.includes) {\n      tokeniser.unconsume(target.index);\n      return;\n    }\n    tokens.mixin =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Incomplete includes statement\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"No terminating ; for includes statement\");\n    return new Includes({ source: tokeniser.source, tokens });\n  }\n\n  get type() {\n    return \"includes\";\n  }\n  get target() {\n    return unescape(this.tokens.target.value);\n  }\n  get includes() {\n    return unescape(this.tokens.mixin.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.reference_token(this.tokens.target, this),\n        w.token(this.tokens.includes),\n        w.reference_token(this.tokens.mixin, this),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this },\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  type_with_extended_attributes,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\n\nexport class Typedef extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(new Typedef({ source: tokeniser.source, tokens }));\n    tokens.base = tokeniser.consume(\"typedef\");\n    if (!tokens.base) {\n      return;\n    }\n    ret.idlType =\n      type_with_extended_attributes(tokeniser, \"typedef-type\") ||\n      tokeniser.error(\"Typedef lacks a type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Typedef lacks a name\");\n    tokeniser.current = ret.this;\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated typedef, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"typedef\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this }),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this },\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  return_type,\n  argument_list,\n  unescape,\n  autoParenter,\n} from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\nexport class CallbackFunction extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, base) {\n    const tokens = { base };\n    const ret = autoParenter(\n      new CallbackFunction({ source: tokeniser.source, tokens }),\n    );\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Callback lacks a name\");\n    tokeniser.current = ret.this;\n    tokens.assign =\n      tokeniser.consume(\"=\") || tokeniser.error(\"Callback lacks an assignment\");\n    ret.idlType =\n      return_type(tokeniser) || tokeniser.error(\"Callback lacks a return type\");\n    tokens.open =\n      tokeniser.consume(\"(\") ||\n      tokeniser.error(\"Callback lacks parentheses for arguments\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close =\n      tokeniser.consume(\")\") || tokeniser.error(\"Unterminated callback\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated callback, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"callback\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    for (const arg of this.arguments) {\n      yield* arg.validate(defs);\n      if (arg.idlType.generic === \"async_sequence\") {\n        const message = `async_sequence types cannot be returned as a callback argument.`;\n        yield validationError(\n          arg.tokens.name,\n          arg,\n          \"async-sequence-idl-to-js\",\n          message,\n        );\n      }\n    }\n    yield* this.idlType.validate(defs);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.name_token(this.tokens.name, { data: this }),\n        w.token(this.tokens.assign),\n        w.ts.type(this.idlType.write(w)),\n        w.token(this.tokens.open),\n        ...this.arguments.map((arg) => arg.write(w)),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this },\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { unescape, autoParenter } from \"./helpers.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction inheritance(tokeniser) {\n  const colon = tokeniser.consume(\":\");\n  if (!colon) {\n    return {};\n  }\n  const inheritance =\n    tokeniser.consumeKind(\"identifier\") ||\n    tokeniser.error(\"Inheritance lacks a type\");\n  return { colon, inheritance };\n}\n\n/**\n * Parser callback.\n * @callback ParserCallback\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n * @param {...*} args\n */\n\n/**\n * A parser callback and optional option object.\n * @typedef AllowedMember\n * @type {[ParserCallback, object?]}\n */\n\nexport class Container extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {*} instance TODO: This should be {T extends Container}, but see https://github.com/microsoft/TypeScript/issues/4628\n   * @param {*} args\n   */\n  static parse(tokeniser, instance, { inheritable, allowedMembers }) {\n    const { tokens, type } = instance;\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(`Missing name in ${type}`);\n    tokeniser.current = instance;\n    instance = autoParenter(instance);\n    if (inheritable) {\n      Object.assign(tokens, inheritance(tokeniser));\n    }\n    tokens.open = tokeniser.consume(\"{\") || tokeniser.error(`Bodyless ${type}`);\n    instance.members = [];\n    while (true) {\n      tokens.close = tokeniser.consume(\"}\");\n      if (tokens.close) {\n        tokens.termination =\n          tokeniser.consume(\";\") ||\n          tokeniser.error(`Missing semicolon after ${type}`);\n        return instance.this;\n      }\n      const ea = ExtendedAttributes.parse(tokeniser);\n      let mem;\n      for (const [parser, ...args] of allowedMembers) {\n        mem = autoParenter(parser(tokeniser, ...args));\n        if (mem) {\n          break;\n        }\n      }\n      if (!mem) {\n        tokeniser.error(\"Unknown member\");\n      }\n      mem.extAttrs = ea;\n      instance.members.push(mem.this);\n    }\n  }\n\n  get partial() {\n    return !!this.tokens.partial;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get inheritance() {\n    if (!this.tokens.inheritance) {\n      return null;\n    }\n    return unescape(this.tokens.inheritance.value);\n  }\n\n  *validate(defs) {\n    for (const member of this.members) {\n      if (member.validate) {\n        yield* member.validate(defs);\n      }\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const inheritance = () => {\n      if (!this.tokens.inheritance) {\n        return \"\";\n      }\n      return w.ts.wrap([\n        w.token(this.tokens.colon),\n        w.ts.trivia(this.tokens.inheritance.trivia),\n        w.ts.inheritance(\n          w.reference(this.tokens.inheritance.value, { context: this }),\n        ),\n      ]);\n    };\n\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.callback),\n        w.token(this.tokens.partial),\n        w.token(this.tokens.base),\n        w.token(this.tokens.mixin),\n        w.name_token(this.tokens.name, { data: this }),\n        inheritance(),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.members.map((m) => m.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this },\n    );\n  }\n}\n","import { Base } from \"./base.js\";\nimport { Type } from \"./type.js\";\nimport {\n  const_data,\n  const_value,\n  primitive_type,\n  autoParenter,\n  unescape,\n} from \"./helpers.js\";\n\nexport class Constant extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"const\");\n    if (!tokens.base) {\n      return;\n    }\n    let idlType = primitive_type(tokeniser);\n    if (!idlType) {\n      const base =\n        tokeniser.consumeKind(\"identifier\") ||\n        tokeniser.error(\"Const lacks a type\");\n      idlType = new Type({ source: tokeniser.source, tokens: { base } });\n    }\n    if (tokeniser.probe(\"?\")) {\n      tokeniser.error(\"Unexpected nullable constant type\");\n    }\n    idlType.type = \"const-type\";\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Const lacks a name\");\n    tokens.assign =\n      tokeniser.consume(\"=\") || tokeniser.error(\"Const lacks value assignment\");\n    tokens.value =\n      const_value(tokeniser) || tokeniser.error(\"Const lacks a value\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated const, expected `;`\");\n    const ret = new Constant({ source: tokeniser.source, tokens });\n    autoParenter(ret).idlType = idlType;\n    return ret;\n  }\n\n  get type() {\n    return \"const\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get value() {\n    return const_data(this.tokens.value);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this, parent }),\n        w.token(this.tokens.assign),\n        w.token(this.tokens.value),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent },\n    );\n  }\n}\n","import { validationError } from \"../error.js\";\nimport { Base } from \"./base.js\";\nimport {\n  type_with_extended_attributes,\n  autoParenter,\n  argument_list,\n} from \"./helpers.js\";\n\nexport class IterableLike extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    const ret = autoParenter(\n      new IterableLike({ source: tokeniser.source, tokens: {} }),\n    );\n    const { tokens } = ret;\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (!tokens.readonly) {\n      tokens.async = tokeniser.consume(\"async\");\n    }\n    tokens.base = tokens.readonly\n      ? tokeniser.consume(\"maplike\", \"setlike\")\n      : tokens.async\n        ? tokeniser.consume(\"iterable\")\n        : tokeniser.consume(\"iterable\", \"async_iterable\", \"maplike\", \"setlike\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n\n    const { type } = ret;\n    const secondTypeRequired = type === \"maplike\";\n    const secondTypeAllowed =\n      secondTypeRequired || type === \"iterable\" || type === \"async_iterable\";\n    const argumentAllowed =\n      type === \"async_iterable\" || (ret.async && type === \"iterable\");\n\n    tokens.open =\n      tokeniser.consume(\"<\") ||\n      tokeniser.error(`Missing less-than sign \\`<\\` in ${type} declaration`);\n    const first =\n      type_with_extended_attributes(tokeniser) ||\n      tokeniser.error(`Missing a type argument in ${type} declaration`);\n    ret.idlType = [first];\n    ret.arguments = [];\n\n    if (secondTypeAllowed) {\n      first.tokens.separator = tokeniser.consume(\",\");\n      if (first.tokens.separator) {\n        ret.idlType.push(type_with_extended_attributes(tokeniser));\n      } else if (secondTypeRequired) {\n        tokeniser.error(`Missing second type argument in ${type} declaration`);\n      }\n    }\n\n    tokens.close =\n      tokeniser.consume(\">\") ||\n      tokeniser.error(`Missing greater-than sign \\`>\\` in ${type} declaration`);\n\n    if (tokeniser.probe(\"(\")) {\n      if (argumentAllowed) {\n        tokens.argsOpen = tokeniser.consume(\"(\");\n        ret.arguments.push(...argument_list(tokeniser));\n        tokens.argsClose =\n          tokeniser.consume(\")\") ||\n          tokeniser.error(\"Unterminated async iterable argument list\");\n      } else {\n        tokeniser.error(`Arguments are only allowed for \\`async iterable\\``);\n      }\n    }\n\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(`Missing semicolon after ${type} declaration`);\n\n    return ret.this;\n  }\n\n  get type() {\n    return this.tokens.base.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get async() {\n    return !!this.tokens.async;\n  }\n\n  *validate(defs) {\n    if (this.async && this.type === \"iterable\") {\n      const message = \"`async iterable` is now changed to `async_iterable`.\";\n      yield validationError(\n        this.tokens.async,\n        this,\n        \"obsolete-async-iterable-syntax\",\n        message,\n        {\n          autofix: autofixAsyncIterableSyntax(this),\n        },\n      );\n    }\n    for (const type of this.idlType) {\n      yield* type.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.readonly),\n        w.token(this.tokens.async),\n        w.token(this.tokens.base, w.ts.generic),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.idlType.map((t) => t.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.argsOpen),\n        w.ts.wrap(this.arguments.map((arg) => arg.write(w))),\n        w.token(this.tokens.argsClose),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent: this.parent },\n    );\n  }\n}\n\n/**\n * @param {IterableLike} iterableLike\n */\nfunction autofixAsyncIterableSyntax(iterableLike) {\n  return () => {\n    const async = iterableLike.tokens.async;\n    iterableLike.tokens.base = {\n      ...async,\n      type: \"async_iterable\",\n      value: \"async_iterable\",\n    };\n    delete iterableLike.tokens.async;\n  };\n}\n","import { Base } from \"./base.js\";\nimport { argument_list, autoParenter } from \"./helpers.js\";\n\nexport class Constructor extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const base = tokeniser.consume(\"constructor\");\n    if (!base) {\n      return;\n    }\n    /** @type {Base[\"tokens\"]} */\n    const tokens = { base };\n    tokens.open =\n      tokeniser.consume(\"(\") ||\n      tokeniser.error(\"No argument list in constructor\");\n    const args = argument_list(tokeniser);\n    tokens.close =\n      tokeniser.consume(\")\") || tokeniser.error(\"Unterminated constructor\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"No semicolon after constructor\");\n    const ret = new Constructor({ source: tokeniser.source, tokens });\n    autoParenter(ret).arguments = args;\n    return ret;\n  }\n\n  get type() {\n    return \"constructor\";\n  }\n\n  *validate(defs) {\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.base, w.ts.nameless, { data: this, parent }),\n        w.token(this.tokens.open),\n        w.ts.wrap(this.arguments.map((arg) => arg.write(w))),\n        w.token(this.tokens.close),\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent },\n    );\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\nimport { IterableLike } from \"./iterable.js\";\nimport {\n  stringifier,\n  autofixAddExposedWindow,\n  getMemberIndentation,\n  getLastIndentation,\n  getFirstToken,\n  findLastIndex,\n  autoParenter,\n} from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\nimport { checkInterfaceMemberDuplication } from \"../validators/interface.js\";\nimport { Constructor } from \"./constructor.js\";\nimport { Tokeniser } from \"../tokeniser.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction static_member(tokeniser) {\n  const special = tokeniser.consume(\"static\");\n  if (!special) return;\n  const member =\n    Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"No body in static member\");\n  return member;\n}\n\nexport class Interface extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {import(\"../tokeniser.js\").Token} base\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token|null} [options.partial]\n   */\n  static parse(tokeniser, base, { extMembers = [], partial = null } = {}) {\n    const tokens = { partial, base };\n    return Container.parse(\n      tokeniser,\n      new Interface({ source: tokeniser.source, tokens }),\n      {\n        inheritable: !partial,\n        allowedMembers: [\n          ...extMembers,\n          [Constant.parse],\n          [Constructor.parse],\n          [static_member],\n          [stringifier],\n          [IterableLike.parse],\n          [Attribute.parse],\n          [Operation.parse],\n        ],\n      },\n    );\n  }\n\n  get type() {\n    return \"interface\";\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    if (\n      !this.partial &&\n      this.extAttrs.every((extAttr) => extAttr.name !== \"Exposed\")\n    ) {\n      const message = `Interfaces must have \\`[Exposed]\\` extended attribute. \\\nTo fix, add, for example, \\`[Exposed=Window]\\`. Please also consider carefully \\\nif your interface should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"require-exposed\",\n        message,\n        {\n          autofix: autofixAddExposedWindow(this),\n        },\n      );\n    }\n    const oldConstructors = this.extAttrs.filter(\n      (extAttr) => extAttr.name === \"Constructor\",\n    );\n    for (const constructor of oldConstructors) {\n      const message = `Constructors should now be represented as a \\`constructor()\\` operation on the interface \\\ninstead of \\`[Constructor]\\` extended attribute. Refer to the \\\n[WebIDL spec section on constructor operations](https://heycam.github.io/webidl/#idl-constructors) \\\nfor more information.`;\n      yield validationError(\n        constructor.tokens.name,\n        this,\n        \"constructor-member\",\n        message,\n        {\n          autofix: autofixConstructor(this, constructor),\n        },\n      );\n    }\n\n    const isGlobal = this.extAttrs.some((extAttr) => extAttr.name === \"Global\");\n    if (isGlobal) {\n      const factoryFunctions = this.extAttrs.filter(\n        (extAttr) => extAttr.name === \"LegacyFactoryFunction\",\n      );\n      for (const named of factoryFunctions) {\n        const message = `Interfaces marked as \\`[Global]\\` cannot have factory functions.`;\n        yield validationError(\n          named.tokens.name,\n          this,\n          \"no-constructible-global\",\n          message,\n        );\n      }\n\n      const constructors = this.members.filter(\n        (member) => member.type === \"constructor\",\n      );\n      for (const named of constructors) {\n        const message = `Interfaces marked as \\`[Global]\\` cannot have constructors.`;\n        yield validationError(\n          named.tokens.base,\n          this,\n          \"no-constructible-global\",\n          message,\n        );\n      }\n    }\n\n    yield* super.validate(defs);\n    if (!this.partial) {\n      yield* checkInterfaceMemberDuplication(defs, this);\n    }\n  }\n}\n\nfunction autofixConstructor(interfaceDef, constructorExtAttr) {\n  interfaceDef = autoParenter(interfaceDef);\n  return () => {\n    const indentation = getLastIndentation(\n      interfaceDef.extAttrs.tokens.open.trivia,\n    );\n    const memberIndent = interfaceDef.members.length\n      ? getLastIndentation(getFirstToken(interfaceDef.members[0]).trivia)\n      : getMemberIndentation(indentation);\n    const constructorOp = Constructor.parse(\n      new Tokeniser(`\\n${memberIndent}constructor();`),\n    );\n    constructorOp.extAttrs = new ExtendedAttributes({\n      source: interfaceDef.source,\n      tokens: {},\n    });\n    autoParenter(constructorOp).arguments = constructorExtAttr.arguments;\n\n    const existingIndex = findLastIndex(\n      interfaceDef.members,\n      (m) => m.type === \"constructor\",\n    );\n    interfaceDef.members.splice(existingIndex + 1, 0, constructorOp);\n\n    const { close } = interfaceDef.tokens;\n    if (!close.trivia.includes(\"\\n\")) {\n      close.trivia += `\\n${indentation}`;\n    }\n\n    const { extAttrs } = interfaceDef;\n    const index = extAttrs.indexOf(constructorExtAttr);\n    const removed = extAttrs.splice(index, 1);\n    if (!extAttrs.length) {\n      extAttrs.tokens.open = extAttrs.tokens.close = undefined;\n    } else if (extAttrs.length === index) {\n      extAttrs[index - 1].tokens.separator = undefined;\n    } else if (!extAttrs[index].tokens.name.trivia.trim()) {\n      extAttrs[index].tokens.name.trivia = removed[0].tokens.name.trivia;\n    }\n  };\n}\n","import { validationError } from \"../error.js\";\n\n/**\n * @param {import(\"../validator.js\").Definitions} defs\n * @param {import(\"../productions/container.js\").Container} i\n */\nexport function* checkInterfaceMemberDuplication(defs, i) {\n  const opNames = groupOperationNames(i);\n  const partials = defs.partials.get(i.name) || [];\n  const mixins = defs.mixinMap.get(i.name) || [];\n  for (const ext of [...partials, ...mixins]) {\n    const additions = getOperations(ext);\n    const statics = additions.filter((a) => a.special === \"static\");\n    const nonstatics = additions.filter((a) => a.special !== \"static\");\n    yield* checkAdditions(statics, opNames.statics, ext, i);\n    yield* checkAdditions(nonstatics, opNames.nonstatics, ext, i);\n    statics.forEach((op) => opNames.statics.add(op.name));\n    nonstatics.forEach((op) => opNames.nonstatics.add(op.name));\n  }\n\n  /**\n   * @param {import(\"../productions/operation.js\").Operation[]} additions\n   * @param {Set<string>} existings\n   * @param {import(\"../productions/container.js\").Container} ext\n   * @param {import(\"../productions/container.js\").Container} base\n   */\n  function* checkAdditions(additions, existings, ext, base) {\n    for (const addition of additions) {\n      const { name } = addition;\n      if (name && existings.has(name)) {\n        const isStatic = addition.special === \"static\" ? \"static \" : \"\";\n        const message = `The ${isStatic}operation \"${name}\" has already been defined for the base interface \"${base.name}\" either in itself or in a mixin`;\n        yield validationError(\n          addition.tokens.name,\n          ext,\n          \"no-cross-overload\",\n          message,\n        );\n      }\n    }\n  }\n\n  /**\n   * @param {import(\"../productions/container.js\").Container} i\n   * @returns {import(\"../productions/operation.js\").Operation[]}\n   */\n  function getOperations(i) {\n    return i.members.filter(({ type }) => type === \"operation\");\n  }\n\n  /**\n   * @param {import(\"../productions/container.js\").Container} i\n   */\n  function groupOperationNames(i) {\n    const ops = getOperations(i);\n    return {\n      statics: new Set(\n        ops.filter((op) => op.special === \"static\").map((op) => op.name),\n      ),\n      nonstatics: new Set(\n        ops.filter((op) => op.special !== \"static\").map((op) => op.name),\n      ),\n    };\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Constant } from \"./constant.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { stringifier } from \"./helpers.js\";\n\nexport class Mixin extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {import(\"../tokeniser.js\").Token} base\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, base, { extMembers = [], partial } = {}) {\n    const tokens = { partial, base };\n    tokens.mixin = tokeniser.consume(\"mixin\");\n    if (!tokens.mixin) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new Mixin({ source: tokeniser.source, tokens }),\n      {\n        allowedMembers: [\n          ...extMembers,\n          [Constant.parse],\n          [stringifier],\n          [Attribute.parse, { noInherit: true }],\n          [Operation.parse, { regular: true }],\n        ],\n      },\n    );\n  }\n\n  get type() {\n    return \"interface mixin\";\n  }\n}\n","import { Base } from \"./base.js\";\nimport {\n  unescape,\n  type_with_extended_attributes,\n  autoParenter,\n} from \"./helpers.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { Default } from \"./default.js\";\n\nexport class Field extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    /** @type {Base[\"tokens\"]} */\n    const tokens = {};\n    const ret = autoParenter(new Field({ source: tokeniser.source, tokens }));\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.required = tokeniser.consume(\"required\");\n    ret.idlType =\n      type_with_extended_attributes(tokeniser, \"dictionary-type\") ||\n      tokeniser.error(\"Dictionary member lacks a type\");\n    tokens.name =\n      tokeniser.consumeKind(\"identifier\") ||\n      tokeniser.error(\"Dictionary member lacks a name\");\n    ret.default = Default.parse(tokeniser);\n    if (tokens.required && ret.default)\n      tokeniser.error(\"Required member must not have a default\");\n    tokens.termination =\n      tokeniser.consume(\";\") ||\n      tokeniser.error(\"Unterminated dictionary member, expected `;`\");\n    return ret.this;\n  }\n\n  get type() {\n    return \"field\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get required() {\n    return !!this.tokens.required;\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n\n  /** @param {import(\"../writer.js\").Writer} w */\n  write(w) {\n    const { parent } = this;\n    return w.ts.definition(\n      w.ts.wrap([\n        this.extAttrs.write(w),\n        w.token(this.tokens.required),\n        w.ts.type(this.idlType.write(w)),\n        w.name_token(this.tokens.name, { data: this, parent }),\n        this.default ? this.default.write(w) : \"\",\n        w.token(this.tokens.termination),\n      ]),\n      { data: this, parent },\n    );\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Field } from \"./field.js\";\n\nexport class Dictionary extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, { extMembers = [], partial } = {}) {\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"dictionary\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new Dictionary({ source: tokeniser.source, tokens }),\n      {\n        inheritable: !partial,\n        allowedMembers: [...extMembers, [Field.parse]],\n      },\n    );\n  }\n\n  get type() {\n    return \"dictionary\";\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { validationError } from \"../error.js\";\nimport { autofixAddExposedWindow } from \"./helpers.js\";\nimport { Constant } from \"./constant.js\";\n\nexport class Namespace extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   * @param {import(\"../tokeniser.js\").Token} [options.partial]\n   */\n  static parse(tokeniser, { extMembers = [], partial } = {}) {\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"namespace\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new Namespace({ source: tokeniser.source, tokens }),\n      {\n        allowedMembers: [\n          ...extMembers,\n          [Attribute.parse, { noInherit: true, readonly: true }],\n          [Constant.parse],\n          [Operation.parse, { regular: true }],\n        ],\n      },\n    );\n  }\n\n  get type() {\n    return \"namespace\";\n  }\n\n  *validate(defs) {\n    if (\n      !this.partial &&\n      this.extAttrs.every((extAttr) => extAttr.name !== \"Exposed\")\n    ) {\n      const message = `Namespaces must have [Exposed] extended attribute. \\\nTo fix, add, for example, [Exposed=Window]. Please also consider carefully \\\nif your namespace should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(\n        this.tokens.name,\n        this,\n        \"require-exposed\",\n        message,\n        {\n          autofix: autofixAddExposedWindow(this),\n        },\n      );\n    }\n    yield* super.validate(defs);\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\n\nexport class CallbackInterface extends Container {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   * @param {*} callback\n   * @param {object} [options]\n   * @param {import(\"./container.js\").AllowedMember[]} [options.extMembers]\n   */\n  static parse(tokeniser, callback, { extMembers = [] } = {}) {\n    const tokens = { callback };\n    tokens.base = tokeniser.consume(\"interface\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(\n      tokeniser,\n      new CallbackInterface({ source: tokeniser.source, tokens }),\n      {\n        allowedMembers: [\n          ...extMembers,\n          [Constant.parse],\n          [Operation.parse, { regular: true }],\n        ],\n      },\n    );\n  }\n\n  get type() {\n    return \"callback interface\";\n  }\n}\n","import { Tokeniser } from \"./tokeniser.js\";\nimport { Enum } from \"./productions/enum.js\";\nimport { Includes } from \"./productions/includes.js\";\nimport { ExtendedAttributes } from \"./productions/extended-attributes.js\";\nimport { Typedef } from \"./productions/typedef.js\";\nimport { CallbackFunction } from \"./productions/callback.js\";\nimport { Interface } from \"./productions/interface.js\";\nimport { Mixin } from \"./productions/mixin.js\";\nimport { Dictionary } from \"./productions/dictionary.js\";\nimport { Namespace } from \"./productions/namespace.js\";\nimport { CallbackInterface } from \"./productions/callback-interface.js\";\nimport { autoParenter } from \"./productions/helpers.js\";\nimport { Eof } from \"./productions/token.js\";\n\n/** @typedef {'callbackInterface'|'dictionary'|'interface'|'mixin'|'namespace'} ExtendableInterfaces */\n/** @typedef {{ extMembers?: import(\"./productions/container.js\").AllowedMember[]}} Extension */\n/** @typedef {Partial<Record<ExtendableInterfaces, Extension>>} Extensions */\n\n/**\n * Parser options.\n * @typedef {Object} ParserOptions\n * @property {string} [sourceName]\n * @property {boolean} [concrete]\n * @property {Function[]} [productions]\n * @property {Extensions} [extensions]\n */\n\n/**\n * @param {Tokeniser} tokeniser\n * @param {ParserOptions} options\n */\nfunction parseByTokens(tokeniser, options) {\n  const source = tokeniser.source;\n\n  function error(str) {\n    tokeniser.error(str);\n  }\n\n  function consume(...candidates) {\n    return tokeniser.consume(...candidates);\n  }\n\n  function callback() {\n    const callback = consume(\"callback\");\n    if (!callback) return;\n    if (tokeniser.probe(\"interface\")) {\n      return CallbackInterface.parse(tokeniser, callback, {\n        ...options?.extensions?.callbackInterface,\n      });\n    }\n    return CallbackFunction.parse(tokeniser, callback);\n  }\n\n  function interface_(opts) {\n    const base = consume(\"interface\");\n    if (!base) return;\n    return (\n      Mixin.parse(tokeniser, base, {\n        ...opts,\n        ...options?.extensions?.mixin,\n      }) ||\n      Interface.parse(tokeniser, base, {\n        ...opts,\n        ...options?.extensions?.interface,\n      }) ||\n      error(\"Interface has no proper body\")\n    );\n  }\n\n  function partial() {\n    const partial = consume(\"partial\");\n    if (!partial) return;\n    return (\n      Dictionary.parse(tokeniser, {\n        partial,\n        ...options?.extensions?.dictionary,\n      }) ||\n      interface_({ partial }) ||\n      Namespace.parse(tokeniser, {\n        partial,\n        ...options?.extensions?.namespace,\n      }) ||\n      error(\"Partial doesn't apply to anything\")\n    );\n  }\n\n  function definition() {\n    if (options.productions) {\n      for (const production of options.productions) {\n        const result = production(tokeniser);\n        if (result) {\n          return result;\n        }\n      }\n    }\n\n    return (\n      callback() ||\n      interface_() ||\n      partial() ||\n      Dictionary.parse(tokeniser, options?.extensions?.dictionary) ||\n      Enum.parse(tokeniser) ||\n      Typedef.parse(tokeniser) ||\n      Includes.parse(tokeniser) ||\n      Namespace.parse(tokeniser, options?.extensions?.namespace)\n    );\n  }\n\n  function definitions() {\n    if (!source.length) return [];\n    const defs = [];\n    while (true) {\n      const ea = ExtendedAttributes.parse(tokeniser);\n      const def = definition();\n      if (!def) {\n        if (ea.length) error(\"Stray extended attributes\");\n        break;\n      }\n      autoParenter(def).extAttrs = ea;\n      defs.push(def);\n    }\n    const eof = Eof.parse(tokeniser);\n    if (options.concrete) {\n      defs.push(eof);\n    }\n    return defs;\n  }\n\n  const res = definitions();\n  if (tokeniser.position < source.length) error(\"Unrecognised tokens\");\n  return res;\n}\n\n/**\n * @param {string} str\n * @param {ParserOptions} [options]\n */\nexport function parse(str, options = {}) {\n  const tokeniser = new Tokeniser(str);\n  if (typeof options.sourceName !== \"undefined\") {\n    // @ts-ignore (See Tokeniser.source in supplement.d.ts)\n    tokeniser.source.name = options.sourceName;\n  }\n  return parseByTokens(tokeniser, options);\n}\n","function noop(arg) {\n  return arg;\n}\n\nconst templates = {\n  wrap: (items) => items.join(\"\"),\n  trivia: noop,\n  name: noop,\n  reference: noop,\n  type: noop,\n  generic: noop,\n  nameless: noop,\n  inheritance: noop,\n  definition: noop,\n  extendedAttribute: noop,\n  extendedAttributeReference: noop,\n};\n\nexport class Writer {\n  constructor(ts) {\n    this.ts = Object.assign({}, templates, ts);\n  }\n\n  /**\n   * @param {string} raw\n   * @param {object} options\n   * @param {string} [options.unescaped]\n   * @param {import(\"./productions/base.js\").Base} [options.context]\n   * @returns\n   */\n  reference(raw, { unescaped, context }) {\n    if (!unescaped) {\n      unescaped = raw.startsWith(\"_\") ? raw.slice(1) : raw;\n    }\n    return this.ts.reference(raw, unescaped, context);\n  }\n\n  /**\n   * @param {import(\"./tokeniser.js\").Token} t\n   * @param {Function} wrapper\n   * @param {...any} args\n   * @returns\n   */\n  token(t, wrapper = noop, ...args) {\n    if (!t) {\n      return \"\";\n    }\n    const value = wrapper(t.value, ...args);\n    return this.ts.wrap([this.ts.trivia(t.trivia), value]);\n  }\n\n  reference_token(t, context) {\n    return this.token(t, this.reference.bind(this), { context });\n  }\n\n  name_token(t, arg) {\n    return this.token(t, this.ts.name, arg);\n  }\n\n  identifier(id, context) {\n    return this.ts.wrap([\n      this.reference_token(id.tokens.value, context),\n      this.token(id.tokens.separator),\n    ]);\n  }\n}\n\nexport function write(ast, { templates: ts = templates } = {}) {\n  ts = Object.assign({}, templates, ts);\n\n  const w = new Writer(ts);\n\n  return ts.wrap(ast.map((it) => it.write(w)));\n}\n","import { validationError as error } from \"./error.js\";\n\nfunction getMixinMap(all, unique) {\n  const map = new Map();\n  const includes = all.filter((def) => def.type === \"includes\");\n  for (const include of includes) {\n    const mixin = unique.get(include.includes);\n    if (!mixin) {\n      continue;\n    }\n    const array = map.get(include.target);\n    if (array) {\n      array.push(mixin);\n    } else {\n      map.set(include.target, [mixin]);\n    }\n  }\n  return map;\n}\n\n/**\n * @typedef {ReturnType<typeof groupDefinitions>} Definitions\n */\nfunction groupDefinitions(all) {\n  const unique = new Map();\n  const duplicates = new Set();\n  const partials = new Map();\n  for (const def of all) {\n    if (def.partial) {\n      const array = partials.get(def.name);\n      if (array) {\n        array.push(def);\n      } else {\n        partials.set(def.name, [def]);\n      }\n      continue;\n    }\n    if (!def.name) {\n      continue;\n    }\n    if (!unique.has(def.name)) {\n      unique.set(def.name, def);\n    } else {\n      duplicates.add(def);\n    }\n  }\n  return {\n    all,\n    unique,\n    partials,\n    duplicates,\n    mixinMap: getMixinMap(all, unique),\n    cache: {\n      typedefIncludesDictionary: new WeakMap(),\n      dictionaryIncludesRequiredField: new WeakMap(),\n    },\n  };\n}\n\nfunction* checkDuplicatedNames({ unique, duplicates }) {\n  for (const dup of duplicates) {\n    const { name } = dup;\n    const message = `The name \"${name}\" of type \"${\n      unique.get(name).type\n    }\" was already seen`;\n    yield error(dup.tokens.name, dup, \"no-duplicate\", message);\n  }\n}\n\nfunction* validateIterable(ast) {\n  const defs = groupDefinitions(ast);\n  for (const def of defs.all) {\n    if (def.validate) {\n      yield* def.validate(defs);\n    }\n  }\n  yield* checkDuplicatedNames(defs);\n}\n\n// Remove this once all of our support targets expose `.flat()` by default\nfunction flatten(array) {\n  if (array.flat) {\n    return array.flat();\n  }\n  return [].concat(...array);\n}\n\n/**\n * @param {import(\"./productions/base.js\").Base[]} ast\n * @return {import(\"./error.js\").WebIDLErrorData[]} validation errors\n */\nexport function validate(ast) {\n  return [...validateIterable(flatten(ast))];\n}\n"],"names":["root","factory","exports","module","define","amd","globalThis","__webpack_require__","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","error","source","position","current","message","kind","level","autofix","ruleName","sliceTokens","count","slice","Math","max","tokensToText","inputs","precedes","text","map","t","trivia","join","nextToken","type","length","line","precedingLastLine","splitted","split","lastLine","subsequentTokens","subsequentText","sourceContext","repeat","contextType","context","name","partial","node","hierarchy","parent","unshift","n","base","target","result","appendIfExist","contextAsText","bareMessage","sourceName","input","tokens","syntaxError","validationError","token","options","index","Base","constructor","defineProperties","this","writable","toJSON","json","undefined","inheritance","proto","descMap","getOwnPropertyDescriptors","entries","getPrototypeOf","idlTypeIncludesDictionary","idlType","defs","useNullableInner","union","def","unique","typedefIncludesDictionary","cache","has","set","reference","dictionary","nullable","subtype","dictionaryIncludesRequiredField","dict","members","some","field","required","superdict","ArrayBase","Array","super","WrappedToken","parser","tokeniser","consumeKind","write","w","ts","wrap","separator","Eof","parse","tokenName","list","listName","extAttrValueSyntax","renamedLegacies","Map","extAttrListItems","syntax","toks","ExtendedAttributeParameters","assign","consume","ret","autoParenter","asterisk","secondaryName","open","rhsIsList","argument_list","close","rhsType","reference_token","p","identifier","SimpleExtendedAttribute","params","rhs","arguments","validate","extAttr","arg","extendedAttribute","extendedAttributeReference","ExtendedAttributes","push","unconsume","probe","ea","type_suffix","single_type","typeName","Type","return_type","type_with_extended_attributes","keyType","stringTypes","keyIdlType","valueType","generic_type","primitive_type","typeNameKeywords","generic","typ","or","union_type","extAttrs","Boolean","prefix","postfix","filter","replaceAllowShared","typedef","targetToken","firstToken","ref","unescaped","type_body","indexOf","splice","match","Default","const_value","expression","const_data","negative","Argument","start_position","optional","variadic","argumentNameKeywords","default","autofixOptionalDictionaryDefaultValue","requiredExists","a","isLastRequiredArgument","getFirstToken","name_token","data","Tokeniser","Operation","special","regular","termination","includes","argument","body","nameless","Attribute","noInherit","readonly","e","idlTypeIncludesEnforceRange","startsWith","allowDangler","first","items","item","num_type","integer_type","decimal_type","voidToken","stringifier","getLastIndentation","str","lines","autofixAddExposedWindow","exposed","existing","test","values","sort","x","y","Proxy","isArray","tokenRe","decimal","integer","string","whitespace","comment","other","nonRegexTerminals","concat","punctuations","reserved","idl","lastCharIndex","nextChar","charAt","attemptTokenMatch","noFlushTrivia","currentTrivia","pop","lastIndex","WebIDLParseError","punctuation","Error","re","exec","tokenise","probeKind","candidates","consumeIdentifier","EnumValue","Enum","v","Includes","mixin","Typedef","CallbackFunction","Container","instance","inheritable","allowedMembers","colon","mem","args","member","callback","m","Constant","IterableLike","async","secondTypeRequired","secondTypeAllowed","argumentAllowed","argsOpen","argsClose","iterableLike","Constructor","static_member","Interface","extMembers","every","oldConstructors","autofixConstructor","factoryFunctions","named","constructors","i","opNames","ops","getOperations","statics","Set","op","nonstatics","groupOperationNames","partials","mixins","mixinMap","ext","additions","checkAdditions","forEach","add","existings","addition","checkInterfaceMemberDuplication","interfaceDef","constructorExtAttr","indentation","memberIndent","parentTrivia","indentCh","getMemberIndentation","constructorOp","existingIndex","array","predicate","reverse","findIndex","findLastIndex","removed","trim","Mixin","Field","Dictionary","Namespace","CallbackInterface","parseByTokens","interface_","opts","extensions","interface","productions","production","callbackInterface","namespace","res","eof","concrete","definitions","noop","templates","Writer","raw","wrapper","bind","id","ast","it","getMixinMap","all","include","validateIterable","duplicates","WeakMap","groupDefinitions","dup","checkDuplicatedNames","flat"],"sourceRoot":""}